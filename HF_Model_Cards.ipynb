{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef0dd22",
   "metadata": {},
   "source": [
    "## **Hugging Face Model Cards: Collection, Preprocessing and Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df242d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import ModelCard\n",
    "from huggingface_hub import list_models\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import emoji\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a67a32",
   "metadata": {},
   "source": [
    "### **Model Cards Collection:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = list(list_models(sort=\"downloads\", direction=-1, limit=100000, full=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea6f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "model_cards = {}\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def process_model(model):\n",
    "    try:\n",
    "        card = ModelCard.load(model.id)\n",
    "        content = card.content.strip()\n",
    "        if content:\n",
    "            has_card = True\n",
    "            card_length = len(content)\n",
    "            with lock:\n",
    "                model_cards[model.id] = content\n",
    "        else:\n",
    "            has_card = False\n",
    "            card_length = 0\n",
    "\n",
    "        with lock:\n",
    "            data.append({\n",
    "                \"model_id\": model.id,\n",
    "                \"author\": getattr(model, \"author\", None),\n",
    "                \"created_at\": getattr(model, \"created_at\", None).isoformat() if getattr(model, \"created_at\", None) else None,\n",
    "                \"last_modified\": getattr(model, \"last_modified\", None).isoformat() if getattr(model, \"last_modified\", None) else None,\n",
    "                \"downloads\": getattr(model, \"downloads\", None),\n",
    "                \"likes\": getattr(model, \"likes\", None),\n",
    "                \"has_card\": has_card,\n",
    "                \"card_length\": card_length,\n",
    "                \"library_name\": getattr(model, \"library_name\", None),\n",
    "                \"tags\": \", \".join(getattr(model, \"tags\", [])) if getattr(model, \"tags\", None) else None,\n",
    "                \"pipeline_tag\": getattr(model, \"pipeline_tag\", None),\n",
    "            })\n",
    "\n",
    "    except Exception:\n",
    "        with lock:\n",
    "            data.append({\n",
    "            \"model_id\": model.id,\n",
    "            \"author\": getattr(model, \"author\", None),\n",
    "            \"created_at\": getattr(model, \"created_at\", None).isoformat() if getattr(model, \"created_at\", None) else None,\n",
    "            \"last_modified\": getattr(model, \"last_modified\", None).isoformat() if getattr(model, \"last_modified\", None) else None,\n",
    "            \"downloads\": getattr(model, \"downloads\", None),\n",
    "            \"likes\": getattr(model, \"likes\", None),\n",
    "            \"has_card\": False,\n",
    "            \"card_length\": 0,\n",
    "            \"library_name\": getattr(model, \"library_name\", None),\n",
    "            \"tags\": \", \".join(getattr(model, \"tags\", [])) if getattr(model, \"tags\", None) else None,\n",
    "            \"pipeline_tag\": getattr(model, \"pipeline_tag\", None),\n",
    "            })\n",
    "\n",
    "\n",
    "CHECKPOINT_EVERY = 1000\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = {executor.submit(process_model, model): model for model in models}\n",
    "\n",
    "    for i, future in enumerate(as_completed(futures), 1):\n",
    "        model = futures[future]\n",
    "        try:\n",
    "            future.result()\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {model.id}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Periodic saving\n",
    "        if i % CHECKPOINT_EVERY == 0:\n",
    "            with lock:\n",
    "                if data:\n",
    "                    # Save tabular summary to CSV\n",
    "                    with open(\"metadata_checkpoint.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "                        writer = csv.DictWriter(f, fieldnames=data[0].keys())\n",
    "                        writer.writeheader()\n",
    "                        writer.writerows(data)\n",
    "\n",
    "                # Save model cards in a JSON file\n",
    "                with open(\"model_cards_checkpoint.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump(model_cards, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "            print(f\"Checkpoint saved after processing {i} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863a836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>has_card</th>\n",
       "      <th>card_length</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pyannote/speaker-diarization-3.1</td>\n",
       "      <td>pyannote</td>\n",
       "      <td>2023-11-16T08:19:01+00:00</td>\n",
       "      <td>2024-05-10T19:43:23+00:00</td>\n",
       "      <td>16721804</td>\n",
       "      <td>1165</td>\n",
       "      <td>True</td>\n",
       "      <td>10959</td>\n",
       "      <td>pyannote-audio</td>\n",
       "      <td>pyannote-audio, pyannote, pyannote-audio-pipel...</td>\n",
       "      <td>automatic-speech-recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pyannote/segmentation-3.0</td>\n",
       "      <td>pyannote</td>\n",
       "      <td>2023-09-22T12:03:10+00:00</td>\n",
       "      <td>2024-05-10T19:35:46+00:00</td>\n",
       "      <td>18518237</td>\n",
       "      <td>604</td>\n",
       "      <td>True</td>\n",
       "      <td>4645</td>\n",
       "      <td>pyannote-audio</td>\n",
       "      <td>pyannote-audio, pytorch, pyannote, pyannote-au...</td>\n",
       "      <td>voice-activity-detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tech4humans/yolov8s-signature-detector</td>\n",
       "      <td>tech4humans</td>\n",
       "      <td>2025-01-03T17:32:18+00:00</td>\n",
       "      <td>2025-04-05T00:37:03+00:00</td>\n",
       "      <td>41151738</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>19059</td>\n",
       "      <td>ultralytics</td>\n",
       "      <td>ultralytics, tensorboard, onnx, object-detecti...</td>\n",
       "      <td>object-detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>timm/mobilenetv3_small_100.lamb_in1k</td>\n",
       "      <td>timm</td>\n",
       "      <td>2022-12-16T05:38:36+00:00</td>\n",
       "      <td>2025-01-21T18:21:16+00:00</td>\n",
       "      <td>126091014</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>4441</td>\n",
       "      <td>timm</td>\n",
       "      <td>timm, pytorch, safetensors, image-classificati...</td>\n",
       "      <td>image-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>2022-03-02T23:29:05+00:00</td>\n",
       "      <td>2025-03-06T13:37:44+00:00</td>\n",
       "      <td>90137861</td>\n",
       "      <td>3929</td>\n",
       "      <td>True</td>\n",
       "      <td>10454</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>sentence-transformers, pytorch, tf, rust, onnx...</td>\n",
       "      <td>sentence-similarity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model_id                 author  \\\n",
       "0        pyannote/speaker-diarization-3.1               pyannote   \n",
       "1               pyannote/segmentation-3.0               pyannote   \n",
       "2  tech4humans/yolov8s-signature-detector            tech4humans   \n",
       "3    timm/mobilenetv3_small_100.lamb_in1k                   timm   \n",
       "4  sentence-transformers/all-MiniLM-L6-v2  sentence-transformers   \n",
       "\n",
       "                  created_at              last_modified  downloads  likes  \\\n",
       "0  2023-11-16T08:19:01+00:00  2024-05-10T19:43:23+00:00   16721804   1165   \n",
       "1  2023-09-22T12:03:10+00:00  2024-05-10T19:35:46+00:00   18518237    604   \n",
       "2  2025-01-03T17:32:18+00:00  2025-04-05T00:37:03+00:00   41151738     42   \n",
       "3  2022-12-16T05:38:36+00:00  2025-01-21T18:21:16+00:00  126091014     38   \n",
       "4  2022-03-02T23:29:05+00:00  2025-03-06T13:37:44+00:00   90137861   3929   \n",
       "\n",
       "   has_card  card_length           library_name  \\\n",
       "0      True        10959         pyannote-audio   \n",
       "1      True         4645         pyannote-audio   \n",
       "2      True        19059            ultralytics   \n",
       "3      True         4441                   timm   \n",
       "4      True        10454  sentence-transformers   \n",
       "\n",
       "                                                tags  \\\n",
       "0  pyannote-audio, pyannote, pyannote-audio-pipel...   \n",
       "1  pyannote-audio, pytorch, pyannote, pyannote-au...   \n",
       "2  ultralytics, tensorboard, onnx, object-detecti...   \n",
       "3  timm, pytorch, safetensors, image-classificati...   \n",
       "4  sentence-transformers, pytorch, tf, rust, onnx...   \n",
       "\n",
       "                   pipeline_tag  \n",
       "0  automatic-speech-recognition  \n",
       "1      voice-activity-detection  \n",
       "2              object-detection  \n",
       "3          image-classification  \n",
       "4           sentence-similarity  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"metadata_checkpoint.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee265142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c48050a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>has_card</th>\n",
       "      <th>card_length</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>timm/mobilenetv3_small_100.lamb_in1k</td>\n",
       "      <td>timm</td>\n",
       "      <td>2022-12-16T05:38:36+00:00</td>\n",
       "      <td>2025-01-21T18:21:16+00:00</td>\n",
       "      <td>126091014</td>\n",
       "      <td>38</td>\n",
       "      <td>True</td>\n",
       "      <td>4441</td>\n",
       "      <td>timm</td>\n",
       "      <td>timm, pytorch, safetensors, image-classificati...</td>\n",
       "      <td>image-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>Falconsai</td>\n",
       "      <td>2023-10-13T23:50:01+00:00</td>\n",
       "      <td>2025-04-06T13:42:07+00:00</td>\n",
       "      <td>98988953</td>\n",
       "      <td>824</td>\n",
       "      <td>True</td>\n",
       "      <td>9142</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, safetensors, vit, image...</td>\n",
       "      <td>image-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>2022-03-02T23:29:05+00:00</td>\n",
       "      <td>2025-03-06T13:37:44+00:00</td>\n",
       "      <td>90137861</td>\n",
       "      <td>3929</td>\n",
       "      <td>True</td>\n",
       "      <td>10454</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>sentence-transformers, pytorch, tf, rust, onnx...</td>\n",
       "      <td>sentence-similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dima806/fairface_age_image_detection</td>\n",
       "      <td>dima806</td>\n",
       "      <td>2024-12-06T14:59:20+00:00</td>\n",
       "      <td>2024-12-15T19:54:53+00:00</td>\n",
       "      <td>60653441</td>\n",
       "      <td>41</td>\n",
       "      <td>True</td>\n",
       "      <td>1198</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, safetensors, vit, image-classifi...</td>\n",
       "      <td>image-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>2022-03-02T23:29:04+00:00</td>\n",
       "      <td>2024-02-19T11:06:12+00:00</td>\n",
       "      <td>55171860</td>\n",
       "      <td>2417</td>\n",
       "      <td>True</td>\n",
       "      <td>10516</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, tf, jax, rust, coreml, ...</td>\n",
       "      <td>fill-mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tech4humans/yolov8s-signature-detector</td>\n",
       "      <td>tech4humans</td>\n",
       "      <td>2025-01-03T17:32:18+00:00</td>\n",
       "      <td>2025-04-05T00:37:03+00:00</td>\n",
       "      <td>41151738</td>\n",
       "      <td>42</td>\n",
       "      <td>True</td>\n",
       "      <td>19059</td>\n",
       "      <td>ultralytics</td>\n",
       "      <td>ultralytics, tensorboard, onnx, object-detecti...</td>\n",
       "      <td>object-detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pyannote/segmentation-3.0</td>\n",
       "      <td>pyannote</td>\n",
       "      <td>2023-09-22T12:03:10+00:00</td>\n",
       "      <td>2024-05-10T19:35:46+00:00</td>\n",
       "      <td>18518237</td>\n",
       "      <td>604</td>\n",
       "      <td>True</td>\n",
       "      <td>4645</td>\n",
       "      <td>pyannote-audio</td>\n",
       "      <td>pyannote-audio, pytorch, pyannote, pyannote-au...</td>\n",
       "      <td>voice-activity-detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pyannote/wespeaker-voxceleb-resnet34-LM</td>\n",
       "      <td>pyannote</td>\n",
       "      <td>2023-11-13T15:32:31+00:00</td>\n",
       "      <td>2024-05-10T19:36:24+00:00</td>\n",
       "      <td>17865623</td>\n",
       "      <td>75</td>\n",
       "      <td>True</td>\n",
       "      <td>3288</td>\n",
       "      <td>pyannote-audio</td>\n",
       "      <td>pyannote-audio, pytorch, pyannote, pyannote-au...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>2022-03-02T23:29:05+00:00</td>\n",
       "      <td>2025-08-19T10:14:25+00:00</td>\n",
       "      <td>16922032</td>\n",
       "      <td>1161</td>\n",
       "      <td>True</td>\n",
       "      <td>11612</td>\n",
       "      <td>sentence-transformers</td>\n",
       "      <td>sentence-transformers, pytorch, onnx, safetens...</td>\n",
       "      <td>sentence-similarity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pyannote/speaker-diarization-3.1</td>\n",
       "      <td>pyannote</td>\n",
       "      <td>2023-11-16T08:19:01+00:00</td>\n",
       "      <td>2024-05-10T19:43:23+00:00</td>\n",
       "      <td>16721804</td>\n",
       "      <td>1165</td>\n",
       "      <td>True</td>\n",
       "      <td>10959</td>\n",
       "      <td>pyannote-audio</td>\n",
       "      <td>pyannote-audio, pyannote, pyannote-audio-pipel...</td>\n",
       "      <td>automatic-speech-recognition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  model_id                 author  \\\n",
       "3     timm/mobilenetv3_small_100.lamb_in1k                   timm   \n",
       "6           Falconsai/nsfw_image_detection              Falconsai   \n",
       "4   sentence-transformers/all-MiniLM-L6-v2  sentence-transformers   \n",
       "7     dima806/fairface_age_image_detection                dima806   \n",
       "8            google-bert/bert-base-uncased            google-bert   \n",
       "2   tech4humans/yolov8s-signature-detector            tech4humans   \n",
       "1                pyannote/segmentation-3.0               pyannote   \n",
       "9  pyannote/wespeaker-voxceleb-resnet34-LM               pyannote   \n",
       "5  sentence-transformers/all-mpnet-base-v2  sentence-transformers   \n",
       "0         pyannote/speaker-diarization-3.1               pyannote   \n",
       "\n",
       "                  created_at              last_modified  downloads  likes  \\\n",
       "3  2022-12-16T05:38:36+00:00  2025-01-21T18:21:16+00:00  126091014     38   \n",
       "6  2023-10-13T23:50:01+00:00  2025-04-06T13:42:07+00:00   98988953    824   \n",
       "4  2022-03-02T23:29:05+00:00  2025-03-06T13:37:44+00:00   90137861   3929   \n",
       "7  2024-12-06T14:59:20+00:00  2024-12-15T19:54:53+00:00   60653441     41   \n",
       "8  2022-03-02T23:29:04+00:00  2024-02-19T11:06:12+00:00   55171860   2417   \n",
       "2  2025-01-03T17:32:18+00:00  2025-04-05T00:37:03+00:00   41151738     42   \n",
       "1  2023-09-22T12:03:10+00:00  2024-05-10T19:35:46+00:00   18518237    604   \n",
       "9  2023-11-13T15:32:31+00:00  2024-05-10T19:36:24+00:00   17865623     75   \n",
       "5  2022-03-02T23:29:05+00:00  2025-08-19T10:14:25+00:00   16922032   1161   \n",
       "0  2023-11-16T08:19:01+00:00  2024-05-10T19:43:23+00:00   16721804   1165   \n",
       "\n",
       "   has_card  card_length           library_name  \\\n",
       "3      True         4441                   timm   \n",
       "6      True         9142           transformers   \n",
       "4      True        10454  sentence-transformers   \n",
       "7      True         1198           transformers   \n",
       "8      True        10516           transformers   \n",
       "2      True        19059            ultralytics   \n",
       "1      True         4645         pyannote-audio   \n",
       "9      True         3288         pyannote-audio   \n",
       "5      True        11612  sentence-transformers   \n",
       "0      True        10959         pyannote-audio   \n",
       "\n",
       "                                                tags  \\\n",
       "3  timm, pytorch, safetensors, image-classificati...   \n",
       "6  transformers, pytorch, safetensors, vit, image...   \n",
       "4  sentence-transformers, pytorch, tf, rust, onnx...   \n",
       "7  transformers, safetensors, vit, image-classifi...   \n",
       "8  transformers, pytorch, tf, jax, rust, coreml, ...   \n",
       "2  ultralytics, tensorboard, onnx, object-detecti...   \n",
       "1  pyannote-audio, pytorch, pyannote, pyannote-au...   \n",
       "9  pyannote-audio, pytorch, pyannote, pyannote-au...   \n",
       "5  sentence-transformers, pytorch, onnx, safetens...   \n",
       "0  pyannote-audio, pyannote, pyannote-audio-pipel...   \n",
       "\n",
       "                   pipeline_tag  \n",
       "3          image-classification  \n",
       "6          image-classification  \n",
       "4           sentence-similarity  \n",
       "7          image-classification  \n",
       "8                     fill-mask  \n",
       "2              object-detection  \n",
       "1      voice-activity-detection  \n",
       "9                           NaN  \n",
       "5           sentence-similarity  \n",
       "0  automatic-speech-recognition  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sort_values(by=\"downloads\", ascending=False)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69b2f7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_id             0\n",
       "author               0\n",
       "created_at           0\n",
       "last_modified        0\n",
       "downloads            0\n",
       "likes                0\n",
       "has_card             0\n",
       "card_length          0\n",
       "library_name     22544\n",
       "tags                 0\n",
       "pipeline_tag     52494\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebed950d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "has_card\n",
       "True     63065\n",
       "False    36935\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"has_card\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf082058",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACEHOLDER_PATTERNS = [\n",
    "    r\"more information needed\",\n",
    "    r\"this model card has been automatically generated\",\n",
    "    r\"provide a quick summary of what the model is/does\",\n",
    "    r\"<!--.*?-->\",  # HTML comments\n",
    "]\n",
    "\n",
    "\n",
    "# Compute meaningful content length\n",
    "def meaningful_content_length(content: str) -> tuple[int, int]:\n",
    "    lines = content.splitlines()\n",
    "    useful_lines = []\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            continue\n",
    "        # skip the line only when it contains a placeholder and nothing else\n",
    "        if any(re.fullmatch(pat, stripped, flags=re.IGNORECASE | re.DOTALL) for pat in PLACEHOLDER_PATTERNS):\n",
    "            continue\n",
    "        useful_lines.append(stripped)\n",
    "    return len(\" \".join(useful_lines)), len(useful_lines)\n",
    "\n",
    "\n",
    "# Check if a Model Card is valid\n",
    "def has_valid_card(content: str, min_length: int = 100, min_lines: int = 2) -> bool:\n",
    "    total_length, num_lines = meaningful_content_length(content)\n",
    "    return total_length >= min_length and num_lines >= min_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d05d82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model_cards_checkpoint.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    model_cards = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202bc525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all Model Cards to a single .txt file\n",
    "with open(\"all_model_cards.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for model_id, content in model_cards.items():\n",
    "        f.write(f\"@@@MODEL_CARD_START@@@ {model_id}\\n\")\n",
    "        f.write(content)\n",
    "        f.write(\"\\n\\n\")  # separate each Model Card with a blank line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348104e",
   "metadata": {},
   "source": [
    "### **Steps followed in the preprocessing of Model Cards:**\n",
    "\n",
    "1. Extract headers from all Model Cards (lines with Markdown heading symbols: #, ##, ### o ####).\n",
    "2. Normalize headers.\n",
    "3. Remove placeholder or non-informative headers.\n",
    "4. Select most common headers.\n",
    "5. Identify sections of interest using a keyword-based aproach to detect headers related to bias, fairness, and responsible AI.\n",
    "6. Manual review of candidate sections.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84799f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_model_cards.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "# Split the content by individual models\n",
    "model_cards_list = content.split(\"@@@MODEL_CARD_START@@@ \")\n",
    "\n",
    "# Remove empty entries and whitespace\n",
    "model_cards_list = [c.strip() for c in model_cards_list if c.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8cc07d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63065"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_cards_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract model_id and content\n",
    "cards = []\n",
    "no_card_ids = []  # to store models without a valid card\n",
    "\n",
    "for model in model_cards_list:\n",
    "    lines = model.splitlines()\n",
    "    if not lines:\n",
    "        continue\n",
    "    model_id = lines[0].strip()\n",
    "    card_content = \"\\n\".join(lines[1:])\n",
    "\n",
    "\n",
    "    if not has_valid_card(card_content):\n",
    "        no_card_ids.append(model_id)  # store ids of invalid cards\n",
    "        continue  # skip these cards\n",
    "    \n",
    "    cards.append((model_id, card_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f3b82b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(no_card_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e95d78cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61665"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dc6c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tech4humans/yolov8s-signature-detector',\n",
       " '---\\nlicense: agpl-3.0\\nbase_model:\\n- Ultralytics/YOLOv8\\npipeline_tag: object-detection\\ndatasets:\\n- tech4humans/signature-detection\\nmetrics:\\n- f1\\n- precision\\n- recall\\nlibrary_name: ultralytics\\nlibrary_version: 8.0.239\\ninference: false\\ntags:\\n- object-detection\\n- signature-detection\\n- yolo\\n- yolov8\\n- pytorch\\nmodel-index:\\n- name: tech4humans/yolov8s-signature-detector\\n  results:\\n  - task:\\n      type: object-detection\\n    dataset:\\n      name: tech4humans/signature-detection\\n      type: tech4humans/signature-detection\\n      split: test\\n    metrics:\\n    - type: precision\\n      value: 0.94499\\n      name: mAP@0.5\\n    - type: precision\\n      value: 0.6735\\n      name: mAP@0.5:0.95\\n    - type: precision\\n      value: 0.947396\\n      name: precision\\n    - type: recall\\n      value: 0.897216\\n      name: recall\\n    - type: f1\\n      value: 0.921623\\n---\\n\\n# **YOLOv8s - Handwritten Signature Detection**\\n\\nThis repository presents a YOLOv8s-based model, fine-tuned to detect handwritten signatures in document images.\\n\\n| Resource                        | Links / Badges                                                                                                                                                                                                                                                                                                                   | Details                                                                                                                                                                 |\\n|---------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\\n| **Article** | [![Paper page](https://huggingface.co/datasets/huggingface/badges/resolve/main/paper-page-md.svg)](https://huggingface.co/blog/samuellimabraz/signature-detection-model) | A detailed community article covering the full development process of the project |\\n| **Model Files**                 | [![HF Model](https://huggingface.co/datasets/huggingface/badges/resolve/main/model-on-hf-md.svg)](https://huggingface.co/tech4humans/yolov8s-signature-detector)                                                                                                                                                             | **Available formats:** [![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)](https://pytorch.org/) [![ONNX](https://img.shields.io/badge/ONNX-005CED.svg?style=flat&logo=ONNX&logoColor=white)](https://onnx.ai/) [![TensorRT](https://img.shields.io/badge/TensorRT-76B900.svg?style=flat&logo=NVIDIA&logoColor=white)](https://developer.nvidia.com/tensorrt) |\\n| **Dataset ‚Äì Original**          | [![Roboflow](https://app.roboflow.com/images/download-dataset-badge.svg)](https://universe.roboflow.com/tech-ysdkk/signature-detection-hlx8j)                                                                                                                                                                          | 2,819 document images annotated with signature coordinates                                                                                                           |\\n| **Dataset ‚Äì Processed**         | [![HF Dataset](https://huggingface.co/datasets/huggingface/badges/resolve/main/dataset-on-hf-md.svg)](https://huggingface.co/datasets/tech4humans/signature-detection)                                                                                                                                                  | Augmented and pre-processed version (640px) for model training                                                                                                          |\\n| **Notebooks ‚Äì Model Experiments** | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1wSySw_zwyuv6XSaGmkngI4dwbj-hR4ix) [![W&B Training](https://img.shields.io/badge/W%26B_Training-FFBE00?style=flat&logo=WeightsAndBiases&logoColor=white)](https://api.wandb.ai/links/samuel-lima-tech4humans/30cmrkp8) | Complete training and evaluation pipeline with selection among different architectures (yolo, detr, rt-detr, conditional-detr, yolos)                                        |\\n| **Notebooks ‚Äì HP Tuning**       | [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1wSySw_zwyuv6XSaGmkngI4dwbj-hR4ix) [![W&B HP Tuning](https://img.shields.io/badge/W%26B_HP_Tuning-FFBE00?style=flat&logo=WeightsAndBiases&logoColor=white)](https://api.wandb.ai/links/samuel-lima-tech4humans/31a6zhb1) | Optuna trials for optimizing the precision/recall balance                                                                                                               |\\n| **Inference Server**            | [![GitHub](https://img.shields.io/badge/Deploy-ffffff?style=for-the-badge&logo=github&logoColor=black)](https://github.com/tech4ai/t4ai-signature-detect-server)                                                                                                                                         | Complete deployment and inference pipeline with Triton Inference Server<br> [![OpenVINO](https://img.shields.io/badge/OpenVINO-00c7fd?style=flat&logo=intel&logoColor=white)](https://docs.openvino.ai/2025/index.html) [![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=fff)](https://www.docker.com/) [![Triton](https://img.shields.io/badge/Triton-Inference%20Server-76B900?labelColor=black&logo=nvidia)](https://developer.nvidia.com/triton-inference-server) |\\n| **Live Demo**                   | [![HF Space](https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-md.svg)](https://huggingface.co/spaces/tech4humans/signature-detection)                                                                                                                                             | Graphical interface with real-time inference<br> [![Gradio](https://img.shields.io/badge/Gradio-FF5722?style=flat&logo=Gradio&logoColor=white)](https://www.gradio.app/) [![Plotly](https://img.shields.io/badge/PLotly-000000?style=flat&logo=plotly&logoColor=white)](https://plotly.com/python/) |\\n\\n---\\n\\n## **Dataset**\\n\\n<table>\\n  <tr>\\n    <td style=\"text-align: center; padding: 10px;\">\\n      <a href=\"https://universe.roboflow.com/tech-ysdkk/signature-detection-hlx8j\">\\n        <img src=\"https://app.roboflow.com/images/download-dataset-badge.svg\">\\n      </a>\\n    </td>\\n    <td style=\"text-align: center; padding: 10px;\">\\n      <a href=\"https://huggingface.co/datasets/tech4humans/signature-detection\">\\n        <img src=\"https://huggingface.co/datasets/huggingface/badges/resolve/main/dataset-on-hf-md-dark.svg\" alt=\"Dataset on HF\">\\n      </a>\\n    </td>\\n  </tr>\\n</table>\\n\\nThe training utilized a dataset built from two public datasets: [Tobacco800](https://paperswithcode.com/dataset/tobacco-800) and [signatures-xc8up](https://universe.roboflow.com/roboflow-100/signatures-xc8up), unified and processed in [Roboflow](https://roboflow.com/).\\n\\n**Dataset Summary:**\\n- Training: 1,980 images (70%)\\n- Validation: 420 images (15%)\\n- Testing: 419 images (15%)\\n- Format: COCO JSON\\n- Resolution: 640x640 pixels\\n\\n![Roboflow Dataset](./assets/roboflow_ds.png)\\n\\n---\\n\\n## **Training Process**\\n\\nThe training process involved the following steps:\\n\\n### 1. **Model Selection:**\\n\\nVarious object detection models were evaluated to identify the best balance between precision, recall, and inference time.\\n\\n\\n| **Metric**               | [rtdetr-l](https://github.com/ultralytics/assets/releases/download/v8.2.0/rtdetr-l.pt) | [yolos-base](https://huggingface.co/hustvl/yolos-base) | [yolos-tiny](https://huggingface.co/hustvl/yolos-tiny) | [conditional-detr-resnet-50](https://huggingface.co/microsoft/conditional-detr-resnet-50) | [detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50) | [yolov8x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8x.pt) | [yolov8l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt) | [yolov8m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt) | [yolov8s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt) | [yolov8n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt) | [yolo11x](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11x.pt) | [yolo11l](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt) | [yolo11m](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11m.pt) | [yolo11s](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt) | [yolo11n](https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt) | [yolov10x](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10x.pt) | [yolov10l](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10l.pt) | [yolov10b](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10b.pt) | [yolov10m](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10m.pt) | [yolov10s](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10s.pt) | [yolov10n](https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov10n.pt) |\\n|:---------------------|---------:|-----------:|-----------:|---------------------------:|---------------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|---------:|---------:|---------:|---------:|---------:|---------:|\\n| **Inference Time - CPU (ms)**  |  583.608 |   1706.49  |   265.346  |                   476.831  |       425.649  | 1259.47 | 871.329 | 401.183 | 216.6   | 110.442 | 1016.68 | 518.147 | 381.652 | 179.792 | 106.656 |  821.183 |  580.767 |  473.109 |  320.12  |  150.076 | **73.8596** |\\n| **mAP50**               | 0.92709 |   0.901154 |   0.869814 |                   **0.936524** |       0.88885  | 0.794237| 0.800312| 0.875322| 0.874721| 0.816089| 0.667074| 0.707409| 0.809557| 0.835605| 0.813799|  0.681023|  0.726802|  0.789835|  0.787688|  0.663877|  0.734332 |\\n| **mAP50-95**             |  0.622364 |   0.583569 |   0.469064 |                   0.653321 |       0.579428 | 0.552919| 0.593976| **0.665495**| 0.65457 | 0.623963| 0.482289| 0.499126| 0.600797| 0.638849| 0.617496|  0.474535|  0.522654|  0.578874|  0.581259|  0.473857|  0.552704 |\\n\\n\\n![Model Selection](./assets/model_selection.png)\\n\\n#### Highlights:\\n- **Best mAP50:** `conditional-detr-resnet-50` (**0.936524**)\\n- **Best mAP50-95:** `yolov8m` (**0.665495**)\\n- **Fastest Inference Time:** `yolov10n` (**73.8596 ms**)\\n\\nDetailed experiments are available on [**Weights & Biases**](https://api.wandb.ai/links/samuel-lima-tech4humans/30cmrkp8).\\n\\n### 2. **Hyperparameter Tuning:**\\n\\nThe YOLOv8s model, which demonstrated a good balance of inference time, precision, and recall, was selected for hyperparameter tuning.\\n\\n[Optuna](https://optuna.org/) was used for 20 optimization trials.\\nThe hyperparameter tuning used the following parameter configuration:\\n    \\n```python\\n    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.1)\\n    lr0 = trial.suggest_float(\"lr0\", 1e-5, 1e-1, log=True)\\n    box = trial.suggest_float(\"box\", 3.0, 7.0, step=1.0)\\n    cls = trial.suggest_float(\"cls\", 0.5, 1.5, step=0.2)\\n    opt = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"RMSProp\"])\\n```\\n\\nResults can be visualized here: [**Hypertuning Experiment**](https://api.wandb.ai/links/samuel-lima-tech4humans/31a6zhb1).  \\n\\n![Hypertuning Sweep](./assets/sweep.png)\\n\\n### 3. **Evaluation:**\\n\\nThe models were evaluated on the test set at the end of training in ONNX (CPU) and TensorRT (GPU - T4) formats. Performance metrics included precision, recall, mAP50, and mAP50-95.\\n\\n![Trials](./assets/trials.png)\\n\\n#### Results Comparison:\\n\\n| Metric     | Base Model | Best Trial (#10)  | Difference  |\\n|------------|------------|-------------------|-------------|\\n| mAP50      | 87.47%     | **95.75%**        | +8.28%      |\\n| mAP50-95   | 65.46%     | **66.26%**        | +0.81%      |\\n| Precision  | **97.23%**      | 95.61%            | -1.63%     |\\n| Recall     | 76.16%     | **91.21%**        | +15.05%     |\\n| F1-score   | 85.42%     | **93.36%**        | +7.94%      |\\n\\n---\\n\\n## **Results**\\n\\nAfter hyperparameter tuning of the YOLOv8s model, the best model achieved the following results on the test set:\\n\\n- **Precision:** 94.74%\\n- **Recall:** 89.72%\\n- **mAP@50:** 94.50%\\n- **mAP@50-95:** 67.35%\\n- **Inference Time:**\\n  - **ONNX Runtime (CPU):** 171.56 ms\\n  - **TensorRT (GPU - T4):** 7.657 ms  \\n\\n---\\n\\n## **How to Use**\\n\\nThe `YOLOv8s` model can be used via CLI or Python code using the [Ultralytics](https://github.com/ultralytics/ultralytics) library. Alternatively, it can be used directly with ONNX Runtime or TensorRT.\\n\\nThe final weights are available in the main directory of the repository:\\n- [`yolov8s.pt`](yolov8s.pt) (PyTorch format)\\n- [`yolov8s.onnx`](yolov8s.onnx) (ONNX format)\\n- [`yolov8s.engine`](yolov8s.engine) (TensorRT format)\\n\\n### Python Code\\n\\n- Dependencies\\n\\n```bash\\npip install ultralytics supervision huggingface_hub\\n```\\n\\n- Inference \\n\\n```python\\nimport cv2\\nimport supervision as sv\\n\\nfrom huggingface_hub import hf_hub_download\\nfrom ultralytics import YOLO\\n\\nmodel_path = hf_hub_download(\\n  repo_id=\"tech4humans/yolov8s-signature-detector\", \\n  filename=\"yolov8s.pt\"\\n)\\n\\nmodel = YOLO(model_path)\\n\\nimage_path = \"/path/to/your/image.jpg\"\\nimage = cv2.imread(image_path)\\n\\nresults = model(image_path)\\n\\ndetections = sv.Detections.from_ultralytics(results[0])\\n\\nbox_annotator = sv.BoxAnnotator()\\nannotated_image = box_annotator.annotate(scene=image, detections=detections)\\n\\ncv2.imshow(\"Detections\", annotated_image)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n```\\n\\nEnsure the paths to the image and model files are correct.\\n\\n\\n### CLI\\n\\n- Dependencies\\n\\n```bash\\npip install -U ultralytics \"huggingface_hub[cli]\"\\n```\\n\\n- Inference\\n\\n```bash\\nhuggingface-cli download tech4humans/yolov8s-signature-detector yolov8s.pt\\n```\\n\\n```bash\\nyolo predict model=yolov8s.pt source=caminho/para/imagem.jpg\\n```\\n\\n**Parameters**:\\n- `model`: Path to the model weights file.\\n- `source`: Path to the image or directory of images for detection.\\n\\n### ONNX Runtime\\n\\nFor optimized inference, you can find the inference code using [onnxruntime](https://onnxruntime.ai/docs/) and [OpenVINO Execution Provider](https://onnxruntime.ai/docs/execution-providers/OpenVINO-ExecutionProvider.html) in the [handler.py](handler.py) file and on the Hugging Face Space [here](https://huggingface.co/spaces/tech4humans/signature-detection).\\n\\n--- \\n\\n## **Demo**\\n\\nYou can explore the model and test real-time inference in the Hugging Face Spaces demo, built with Gradio and ONNXRuntime.\\n\\n[![Open in Spaces](https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-md.svg)](https://huggingface.co/spaces/tech4humans/signature-detection)\\n\\n---\\n\\n## üîó **Inference with Triton Server**\\n\\nIf you want to deploy this signature detection model in a production environment, check out our inference server repository based on the NVIDIA Triton Inference Server.\\n\\n<table>\\n  <tr>\\n    <td>\\n      <a href=\"https://github.com/triton-inference-server/server\"><img src=\"https://img.shields.io/badge/Triton-Inference%20Server-76B900?style=for-the-badge&labelColor=black&logo=nvidia\" alt=\"Triton Badge\" /></a>\\n    </td>\\n    <td>\\n      <a href=\"https://github.com/tech4ai/t4ai-signature-detect-server\"><img src=\"https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white\" alt=\"GitHub Badge\" /></a>\\n    </td>\\n  </tr>\\n</table>\\n\\n---\\n\\n## **Infrastructure**\\n\\n### Software\\n\\nThe model was trained and tuned using a Jupyter Notebook environment.\\n\\n- **Operating System:** Ubuntu 22.04\\n- **Python:** 3.10.12\\n- **PyTorch:** 2.5.1+cu121\\n- **Ultralytics:** 8.3.58\\n- **Roboflow:** 1.1.50\\n- **Optuna:** 4.1.0\\n- **ONNX Runtime:** 1.20.1\\n- **TensorRT:** 10.7.0\\n\\n### Hardware\\n\\nTraining was performed on a Google Cloud Platform n1-standard-8 instance with the following specifications:\\n\\n- **CPU:** 8 vCPUs\\n- **GPU:** NVIDIA Tesla T4\\n\\n---\\n\\n## **License**\\n\\n### Model Weights (Fine-Tuned Model) ‚Äì **AGPL-3.0**\\n- **License:** GNU Affero General Public License v3.0 (AGPL-3.0)\\n- **Usage:** The fine-tuned model weights, derived from the YOLOv8 model by Ultralytics, are licensed under AGPL-3.0. This requires that any modifications or derivative works of these model weights also be distributed under AGPL-3.0, and if the model is used as part of a network service, the corresponding source must be made available.\\n\\n### Code, Training, Deployment, and Data ‚Äì **Apache 2.0**\\n- **License:** Apache License 2.0\\n- **Usage:** All additional materials‚Äîincluding training scripts, deployment code, usage instructions, and associated data‚Äîare licensed under the Apache 2.0 license.\\n\\nFor more details, please refer to the full license texts:\\n- [GNU AGPL-3.0 License](https://www.gnu.org/licenses/agpl-3.0.html)\\n- [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0)\\n\\n---\\n\\n## **Contact and Information**\\n\\nFor further information, questions, or contributions, contact us at **iag@tech4h.com.br**.\\n\\n<div align=\"center\">\\n  <p>\\n    üìß <b>Email:</b> <a href=\"mailto:iag@tech4h.com.br\">iag@tech4h.com.br</a><br>\\n    üåê <b>Website:</b> <a href=\"https://www.tech4.ai/\">www.tech4.ai</a><br>\\n    üíº <b>LinkedIn:</b> <a href=\"https://www.linkedin.com/company/tech4humans-hyperautomation/\">Tech4Humans</a>\\n  </p>\\n</div>\\n\\n## **Author**\\n\\n<div align=\"center\">\\n  <table>\\n    <tr>\\n      <td align=\"center\" width=\"140\">\\n        <a href=\"https://huggingface.co/samuellimabraz\">\\n          <img src=\"https://avatars.githubusercontent.com/u/115582014?s=400&u=c149baf46c51fdee45ad5344cf1b360236d90d09&v=4\" width=\"120\" alt=\"Samuel Lima\"/>\\n          <h3>Samuel Lima</h3>\\n        </a>\\n        <p><i>AI Research Engineer</i></p>\\n        <p>\\n          <a href=\"https://huggingface.co/samuellimabraz\">\\n            <img src=\"https://img.shields.io/badge/ü§ó_HuggingFace-samuellimabraz-orange\" alt=\"HuggingFace\"/>\\n          </a>\\n        </p>\\n      </td>\\n      <td width=\"500\">\\n        <h4>Responsibilities in this Project</h4>\\n        <ul>\\n          <li>üî¨ Model development and training</li>\\n          <li>üìä Dataset analysis and processing</li>\\n          <li>‚öôÔ∏è Hyperparameter optimization and performance evaluation</li>\\n          <li>üìù Technical documentation and model card</li>\\n        </ul>\\n      </td>\\n    </tr>\\n  </table>\\n</div>\\n\\n---\\n\\n<div align=\"center\">\\n  <p>Developed with üíú by <a href=\"https://www.tech4.ai/\">Tech4Humans</a></p>\\n</div>')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards[2] # Each entry in cards is a tuple: (model_id, card_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7322d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>has_card</th>\n",
       "      <th>card_length</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>unslothai/1</td>\n",
       "      <td>unslothai</td>\n",
       "      <td>2024-07-14T03:05:31+00:00</td>\n",
       "      <td>2024-07-14T03:07:01+00:00</td>\n",
       "      <td>3673072</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, safetensors, llama, feature-extr...</td>\n",
       "      <td>feature-extraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>ggml-org/models-moved</td>\n",
       "      <td>ggml-org</td>\n",
       "      <td>2023-12-18T17:40:16+00:00</td>\n",
       "      <td>2025-04-03T13:38:51+00:00</td>\n",
       "      <td>3443917</td>\n",
       "      <td>11</td>\n",
       "      <td>False</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gguf, endpoints_compatible, region:us</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>unslothai/aws</td>\n",
       "      <td>unslothai</td>\n",
       "      <td>2024-03-31T16:44:21+00:00</td>\n",
       "      <td>2024-07-06T22:41:24+00:00</td>\n",
       "      <td>1977175</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, safetensors, llama, feature-extr...</td>\n",
       "      <td>feature-extraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>unslothai/repeat</td>\n",
       "      <td>unslothai</td>\n",
       "      <td>2024-07-07T16:55:01+00:00</td>\n",
       "      <td>2024-07-07T16:55:04+00:00</td>\n",
       "      <td>1939325</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, safetensors, llama, feature-extr...</td>\n",
       "      <td>feature-extraction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>unslothai/vram-24</td>\n",
       "      <td>unslothai</td>\n",
       "      <td>2024-07-07T17:02:11+00:00</td>\n",
       "      <td>2024-07-07T17:02:52+00:00</td>\n",
       "      <td>1539044</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, safetensors, llama, feature-extr...</td>\n",
       "      <td>feature-extraction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model_id     author                 created_at  \\\n",
       "71             unslothai/1  unslothai  2024-07-14T03:05:31+00:00   \n",
       "81   ggml-org/models-moved   ggml-org  2023-12-18T17:40:16+00:00   \n",
       "140          unslothai/aws  unslothai  2024-03-31T16:44:21+00:00   \n",
       "141       unslothai/repeat  unslothai  2024-07-07T16:55:01+00:00   \n",
       "163      unslothai/vram-24  unslothai  2024-07-07T17:02:11+00:00   \n",
       "\n",
       "                 last_modified  downloads  likes  has_card  card_length  \\\n",
       "71   2024-07-14T03:07:01+00:00    3673072      1     False           43   \n",
       "81   2025-04-03T13:38:51+00:00    3443917     11     False           92   \n",
       "140  2024-07-06T22:41:24+00:00    1977175      1     False           60   \n",
       "141  2024-07-07T16:55:04+00:00    1939325      0     False           43   \n",
       "163  2024-07-07T17:02:52+00:00    1539044      0     False           43   \n",
       "\n",
       "     library_name                                               tags  \\\n",
       "71   transformers  transformers, safetensors, llama, feature-extr...   \n",
       "81            NaN              gguf, endpoints_compatible, region:us   \n",
       "140  transformers  transformers, safetensors, llama, feature-extr...   \n",
       "141  transformers  transformers, safetensors, llama, feature-extr...   \n",
       "163  transformers  transformers, safetensors, llama, feature-extr...   \n",
       "\n",
       "           pipeline_tag  \n",
       "71   feature-extraction  \n",
       "81                  NaN  \n",
       "140  feature-extraction  \n",
       "141  feature-extraction  \n",
       "163  feature-extraction  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data[\"model_id\"].isin(no_card_ids), \"has_card\"] = False\n",
    "\n",
    "data[data[\"has_card\"] == False].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d11f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract headers from Model Cards\n",
    "headers_list = []\n",
    "\n",
    "for model_id, card_content in cards:\n",
    "    header = re.findall(r'^\\s*#+\\s+(.*)', card_content, flags=re.MULTILINE)\n",
    "    headers_list.extend(header)\n",
    "\n",
    "\n",
    "# Normalize headers (remove emojis, punctuation, etc.)\n",
    "def normalize_header(header):\n",
    "    # remove '#' and leading spaces\n",
    "    header_clean = re.sub(r'^#+\\s*', '', header)\n",
    "    # remove leading numbers\n",
    "    header_clean = re.sub(r'^\\d+\\s*', '', header_clean)\n",
    "    # remove parentheses and brackets\n",
    "    header_clean = re.sub(r'[\\(\\)\\[\\]]', '', header_clean)\n",
    "    # remove punctuation and emojis\n",
    "    header_clean = re.sub(r'[^\\w\\s&]', '', header_clean)\n",
    "    # replace '&' with 'and'\n",
    "    header_clean = re.sub(r'&', 'and', header_clean)\n",
    "    # replace multiple spaces with a single space\n",
    "    header_clean = re.sub(r'\\s+', ' ', header_clean)\n",
    "    # remove line breaks\n",
    "    header_clean = re.sub(r'\\n', ' ', header_clean)\n",
    "\n",
    "    header_clean = header_clean.lower().strip()\n",
    "    \n",
    "    # ignore headers that are placeholders\n",
    "    if header_clean.endswith('optional') or header_clean == 'more information needed' or header_clean == 'model card for model id':\n",
    "        return None\n",
    "    \n",
    "    return header_clean\n",
    "\n",
    "\n",
    "# normalized_h = []\n",
    "# for header in headers_list:\n",
    "#     nh = normalize_header(header)\n",
    "#     if nh:\n",
    "#         normalized_h.append(nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1116a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sections from a Model Card\n",
    "def extract_sections(card_content):\n",
    "    lines = card_content.splitlines()\n",
    "    sections = []\n",
    "    current_header = None\n",
    "    section_lines = []\n",
    "\n",
    "    for line in lines:\n",
    "        header_match = re.match(r'^\\s*#+\\s+(.*)', line)\n",
    "        if header_match:\n",
    "            if section_lines:\n",
    "                sections.append((current_header, \"\\n\".join(section_lines)))\n",
    "            current_header = normalize_header(header_match.group(1))\n",
    "            section_lines = []\n",
    "        else:\n",
    "            section_lines.append(line.strip())  # ‚Üê limpio\n",
    "    if section_lines:\n",
    "        sections.append((current_header, \"\\n\".join(section_lines)))\n",
    "    return sections\n",
    "\n",
    "\n",
    "# Build a DataFrame of sections from all Model Cards\n",
    "records = []\n",
    "for model_id, card_content in cards:\n",
    "    sections = extract_sections(card_content)\n",
    "    for header, text in sections:\n",
    "        if header:\n",
    "            word_count = len(re.findall(r'\\w+', text))\n",
    "            records.append({\n",
    "                \"model_id\": model_id,\n",
    "                \"header\": header,\n",
    "                \"section_text\": text,\n",
    "                \"word_count\": word_count\n",
    "            })\n",
    "\n",
    "df_sections = pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdad35b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63224"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sections[\"header\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93701098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('usage', 21988),\n",
       " ('about', 16611),\n",
       " ('thanks', 16550),\n",
       " ('provided quants', 16536),\n",
       " ('faq model request', 16517),\n",
       " ('model description', 9486),\n",
       " ('citation', 8296),\n",
       " ('model details', 7790),\n",
       " ('training procedure', 6216),\n",
       " ('evaluation', 5595),\n",
       " ('training hyperparameters', 5432),\n",
       " ('training data', 4887),\n",
       " ('training details', 4679),\n",
       " ('bias risks and limitations', 3682),\n",
       " ('uses', 3668),\n",
       " ('license', 3499),\n",
       " ('outofscope use', 3446),\n",
       " ('framework versions', 3423),\n",
       " ('how to get started with the model', 3366),\n",
       " ('results', 3219),\n",
       " ('direct use', 3208),\n",
       " ('model card contact', 3192),\n",
       " ('software', 3188),\n",
       " ('hardware', 3173),\n",
       " ('recommendations', 3096),\n",
       " ('how to use', 3060),\n",
       " ('metrics', 3035),\n",
       " ('intended uses and limitations', 2878),\n",
       " ('environmental impact', 2871),\n",
       " ('description', 2777),\n",
       " ('summary', 2773),\n",
       " ('compute infrastructure', 2755),\n",
       " ('model architecture and objective', 2737),\n",
       " ('testing data', 2737),\n",
       " ('testing data factors and metrics', 2724),\n",
       " ('get model specific transforms normalization resize', 2649),\n",
       " ('factors', 2647),\n",
       " ('prompt template', 2496),\n",
       " ('training results', 2229),\n",
       " ('command line', 2121),\n",
       " ('downloading instruction', 2115),\n",
       " ('model file specification', 2115),\n",
       " ('our projects', 2112),\n",
       " ('training and evaluation data', 2040),\n",
       " ('introduction', 1814),\n",
       " ('about gguf', 1709),\n",
       " ('limitations', 1640),\n",
       " ('prompt format', 1611),\n",
       " ('evaluation results', 1469),\n",
       " ('training', 1389),\n",
       " ('key features', 1379),\n",
       " ('quick start', 1373),\n",
       " ('intended use', 1352),\n",
       " ('model overview', 1339),\n",
       " ('first install the package', 1316),\n",
       " ('how to download gguf files', 1310),\n",
       " ('set gpu_layers to the number of layers to offload to gpu set to 0 if no gpu acceleration is available on your system',\n",
       "  1306),\n",
       " ('base ctransformers with no gpu acceleration', 1303),\n",
       " ('in textgenerationwebui', 1300),\n",
       " ('explanation of quantisation methods', 1293),\n",
       " ('example llamacpp command', 1287),\n",
       " ('how to run from python code', 1284),\n",
       " ('how to run in textgenerationwebui', 1280),\n",
       " ('how to use with langchain', 1272),\n",
       " ('on the command line including multiple files at once', 1270),\n",
       " ('response', 1243),\n",
       " ('model architecture', 1229),\n",
       " ('downloading using huggingfacecli', 1207),\n",
       " ('installation', 1191),\n",
       " ('credits', 1169),\n",
       " ('or with amd rocm gpu acceleration linux only', 1140),\n",
       " ('or with metal gpu acceleration for macos systems only', 1140),\n",
       " ('download a file not the whole branch from below', 1112),\n",
       " ('instruction', 1098),\n",
       " ('which file should i choose', 1095),\n",
       " ('contact', 1063),\n",
       " ('model sources', 1057),\n",
       " ('quickstart', 1040),\n",
       " ('example usage', 1032),\n",
       " ('compatibility', 1024),\n",
       " ('inference', 1022),\n",
       " ('discord', 1013),\n",
       " ('thanks and how to contribute', 1011),\n",
       " ('performance', 1006),\n",
       " ('repositories available', 989),\n",
       " ('download model', 986),\n",
       " ('image embeddings', 973),\n",
       " ('image classification', 973),\n",
       " ('overview', 956),\n",
       " ('or equivalently without needing to set num_classes0', 954),\n",
       " ('embedoutput weights', 934),\n",
       " ('trigger words', 932),\n",
       " ('output is a 1 num_features shaped tensor', 907),\n",
       " ('provided files', 906),\n",
       " ('use with mlx', 887),\n",
       " ('special thanks', 870),\n",
       " ('configuration', 865),\n",
       " ('acknowledgements', 831),\n",
       " ('dataset', 826),\n",
       " ('model summary', 822),\n",
       " ('chat completion api', 795),\n",
       " ('or with openblas acceleration', 792),\n",
       " ('in windows to set the variables cmake_args in powershell follow this format eg for nvidia cuda',\n",
       "  792),\n",
       " ('with nvidia cuda acceleration', 792),\n",
       " ('simple inference example', 790),\n",
       " ('simple llamacpppython example code', 788),\n",
       " ('how to load this model in python code using llamacpppython', 788),\n",
       " ('or with clblast acceleration', 788),\n",
       " ('bibtex entry and citation info', 746),\n",
       " ('open llm leaderboard evaluation resultshttpshuggingfacecospaceshuggingfaceh4open_llm_leaderboard',\n",
       "  736),\n",
       " ('benchmarks', 730),\n",
       " ('feature map extraction', 727),\n",
       " ('model comparison', 719),\n",
       " ('server', 704),\n",
       " ('requirements', 703),\n",
       " ('use with llamacpp', 695),\n",
       " ('cli', 683),\n",
       " ('training dataset', 679),\n",
       " ('disclaimer', 676),\n",
       " ('usage with mlagents', 652),\n",
       " ('watch your agent play', 651),\n",
       " ('resume the training', 650),\n",
       " ('model information', 632),\n",
       " ('ethical considerations', 576),\n",
       " ('armavx information', 565),\n",
       " ('models merged', 558),\n",
       " ('use cases', 555),\n",
       " ('table of contents', 550),\n",
       " ('merge method', 541),\n",
       " ('original model card', 538),\n",
       " ('or with cuda gpu acceleration', 524),\n",
       " ('references', 499),\n",
       " ('uploaded model', 492),\n",
       " ('limitations and bias', 485),\n",
       " ('benchmark results', 484),\n",
       " ('ethical considerations and limitations', 483),\n",
       " ('model card authors', 471),\n",
       " ('available quantizations', 461),\n",
       " ('citations', 450),\n",
       " ('acknowledgments', 439),\n",
       " ('contributing', 437),\n",
       " ('input', 429),\n",
       " ('powered by featherless aihttpsfeatherlessai', 426),\n",
       " ('full model architecture', 422),\n",
       " ('performance metrics', 418),\n",
       " ('preprocessing', 416),\n",
       " ('ppo agent playing huggy', 415),\n",
       " ('deployment', 404),\n",
       " ('run inference', 395),\n",
       " ('hardware and software', 389),\n",
       " ('dataset information', 382),\n",
       " ('batch processing', 382),\n",
       " ('news', 378),\n",
       " ('data', 376),\n",
       " ('create a pipeline', 372),\n",
       " ('process with memoryefficient batching', 371),\n",
       " ('load a medical dataset from hugging face', 371),\n",
       " ('supported entity types', 371),\n",
       " ('load a public medical dataset using a subset for testing', 371),\n",
       " ('process with optimal batching for your hardware', 371),\n",
       " ('for limited gpu memory use smaller batches', 371),\n",
       " ('performance optimization', 371),\n",
       " ('adjust batch_size based on your gpu memory typically 8 16 32 or 64', 371),\n",
       " ('current model performance', 371),\n",
       " ('large dataset processing', 371),\n",
       " ('model', 369),\n",
       " ('pip install accelerate', 368),\n",
       " ('evaluations', 367),\n",
       " ('downstream use', 363),\n",
       " ('finetuning', 362),\n",
       " ('technical details', 359),\n",
       " ('bibtex', 353),\n",
       " ('simple ctransformers example code', 348),\n",
       " ('how to load this model in python code using ctransformers', 348),\n",
       " ('pretraining', 334),\n",
       " ('technical specifications', 332),\n",
       " ('load model', 330),\n",
       " ('usage sentencetransformers', 322),\n",
       " ('highlights', 322),\n",
       " ('output', 321),\n",
       " ('assistant', 320),\n",
       " ('inputs and outputs', 318),\n",
       " ('finetune for free', 318),\n",
       " ('download from the hub', 317),\n",
       " ('community', 313),\n",
       " ('use it with the diffusers libraryhttpsgithubcomhuggingfacediffusers', 303),\n",
       " ('implementation information', 299),\n",
       " ('use with transformers', 297),\n",
       " ('compute token embeddings', 296),\n",
       " ('disclaimers', 296),\n",
       " ('evaluation approach', 294),\n",
       " ('prepare the model input', 293),\n",
       " ('intended uses', 293),\n",
       " ('transformers', 293),\n",
       " ('acknowledgement', 292),\n",
       " ('examples', 292),\n",
       " ('original model', 292),\n",
       " ('how to cite', 292),\n",
       " ('load the tokenizer and the model', 292),\n",
       " ('evaluation and performance', 287),\n",
       " ('ethical considerations and risks', 284),\n",
       " ('datasets', 284),\n",
       " ('example', 282),\n",
       " ('tokenize sentences', 281),\n",
       " ('prompt template alpaca', 280),\n",
       " ('intended usage', 279),\n",
       " ('conduct text completion', 278),\n",
       " ('model performance', 277),\n",
       " ('span idtestllm stylecolor 7f7fff if you find these models usefulspan', 276),\n",
       " ('sentences we want sentence embeddings for', 274),\n",
       " ('load model from huggingface hub', 274),\n",
       " ('what im testing', 274),\n",
       " ('final word', 273),\n",
       " ('usage and limitations', 268),\n",
       " ('model data', 264),\n",
       " ('load the model', 262),\n",
       " ('citing and authors', 260),\n",
       " ('usage huggingface transformers', 258),\n",
       " ('hyperparameters', 258),\n",
       " ('limitations and biases', 257),\n",
       " ('benefits', 257),\n",
       " ('reference', 256),\n",
       " ('best practices', 254),\n",
       " ('merge', 254),\n",
       " ('glossary', 254),\n",
       " ('links', 253),\n",
       " ('ethics and safety', 250),\n",
       " ('processing long texts', 248),\n",
       " ('other assistants', 246),\n",
       " ('model usage', 242),\n",
       " ('data preprocessing', 239),\n",
       " ('how to use the model', 239),\n",
       " ('quantization', 238),\n",
       " ('define tools', 237),\n",
       " ('vllm', 235),\n",
       " ('models', 229),\n",
       " ('preparation for inference', 228),\n",
       " ('faq', 226),\n",
       " ('user', 223),\n",
       " ('contact us', 223),\n",
       " ('training datasets', 222),\n",
       " ('span stylecolor 7f7fffmodel generation detailsspan', 220),\n",
       " ('llamacpp', 212),\n",
       " ('open llm leaderboard evaluation resultshttpshuggingfacecospacesopenllmleaderboardopen_llm_leaderboard',\n",
       "  212),\n",
       " ('load model and tokenizer', 210),\n",
       " ('use a custom endpoint compatible with openai api', 210),\n",
       " ('q4_0_x_x', 209),\n",
       " ('define agent', 206),\n",
       " ('streaming generation', 206),\n",
       " ('authors', 205),\n",
       " ('agentic use', 205),\n",
       " ('instruction tuned models', 203),\n",
       " ('licensing', 202),\n",
       " ('define llm', 197),\n",
       " ('rindex finding 151668 think', 186),\n",
       " ('parsing thinking content', 185),\n",
       " ('sentence transformers', 183),\n",
       " ('responsibility and safety', 182),\n",
       " ('files', 182),\n",
       " ('system', 180),\n",
       " ('how to load this model from python using ctransformers', 179),\n",
       " ('simple example code to load one of these gguf models', 178),\n",
       " ('or with metal gpu acceleration for macos systems', 176),\n",
       " ('or with rocm gpu acceleration', 176),\n",
       " ('quantized gguf models', 175),\n",
       " ('model optimizations', 171),\n",
       " ('accuracy', 169),\n",
       " ('model card', 169),\n",
       " ('method', 169),\n",
       " ('direct usage sentence transformers', 168),\n",
       " ('please set tp2 for the 38b version and tp8 for the 241ba28b version', 168),\n",
       " ('tokenizer', 167),\n",
       " ('get the similarity scores for the embeddings', 166),\n",
       " ('evaluation dataset', 166),\n",
       " ('run with llamaedge', 165),\n",
       " ('base pretrained models', 165),\n",
       " ('bias', 165),\n",
       " ('features', 165),\n",
       " ('qwen3 highlights', 164),\n",
       " ('diffusers', 163),\n",
       " ('more information', 163),\n",
       " ('safety', 162),\n",
       " ('creation', 162),\n",
       " ('note', 162),\n",
       " ('example commands you could test', 162),\n",
       " ('abstract', 160),\n",
       " ('software integration', 159),\n",
       " ('chat template', 158),\n",
       " ('model downloads', 158),\n",
       " ('contributors', 156),\n",
       " ('ollama', 154),\n",
       " ('load the model and tokenizer', 153),\n",
       " ('pip install bitsandbytes accelerate', 153),\n",
       " ('prompting', 152),\n",
       " ('how to run locally', 151),\n",
       " ('demo', 149),\n",
       " ('switching between thinking and nonthinking mode', 149),\n",
       " ('training configuration', 148),\n",
       " ('generation', 147),\n",
       " ('tldr', 147),\n",
       " ('multilingual', 146),\n",
       " ('prompt template chatml', 144),\n",
       " ('inference with transformers', 144),\n",
       " ('usage transformersjs', 143),\n",
       " ('direct usage transformers', 143),\n",
       " ('architecture', 143),\n",
       " ('downstream usage sentence transformers', 142),\n",
       " ('inference generation of the output', 141),\n",
       " ('model versions', 140),\n",
       " ('citation information', 139),\n",
       " ('critical risks', 137),\n",
       " ('update history', 137),\n",
       " ('enable_thinkingtrue', 136),\n",
       " ('enable_thinkingfalse', 136),\n",
       " ('second input with no_think', 135),\n",
       " ('third input with think', 135),\n",
       " ('first input without think or no_think tags thinking mode is enabled by default',\n",
       "  135),\n",
       " ('api_key osgetenvdashscope_api_key', 134),\n",
       " ('supported models', 134),\n",
       " ('perform pooling in this case mean pooling', 134),\n",
       " ('advanced usage switching between thinking and nonthinking modes via user input',\n",
       "  134),\n",
       " ('details', 134),\n",
       " ('install the necessary packages', 131),\n",
       " ('reasoning and factuality', 131),\n",
       " ('stem and code', 130),\n",
       " ('f16 float 16 more widely supported than bf16', 129),\n",
       " ('quantized models q4_k q6_k q8 etc for cpu and lowvram inference', 129),\n",
       " ('choosing the right model format', 129),\n",
       " ('bf16 brain float 16 use if bf16 acceleration is available', 129),\n",
       " ('summary table model format selection', 129),\n",
       " ('download', 128),\n",
       " ('uploaded finetuned model', 128),\n",
       " ('notes', 128),\n",
       " ('nondefault hyperparameters', 126),\n",
       " ('deepseekr1 models', 126),\n",
       " ('deepseekr1distill models', 126),\n",
       " ('see faq for merging ggufs', 125),\n",
       " ('use', 125),\n",
       " ('why is the imatrix not applied everywhere', 125),\n",
       " ('all quants', 125),\n",
       " ('common quants', 125),\n",
       " ('how do i merge a split gguf', 125),\n",
       " ('all hyperparameters', 124),\n",
       " ('very lowbit quantization iq3_xs iq3_s iq3_m q4_k q4_0', 124),\n",
       " ('whats in this repository', 124),\n",
       " ('usage example', 124),\n",
       " ('how do i get started', 123),\n",
       " ('obtain ik_llamas thireus version windows builds available at httpsgithubcomthireusik_llamacppreleases',\n",
       "  123),\n",
       " ('download model quant mix from recipe file', 123),\n",
       " ('build ik_llamacpp', 123),\n",
       " ('why does this tool suite exist', 123),\n",
       " ('obtain thireus gguftoolsuite', 123),\n",
       " ('pro tips', 123),\n",
       " ('how does it compare to other ggufs', 123),\n",
       " ('make sure to install all ik_llamacpp compilation dependencies', 123),\n",
       " ('lmdeploy', 122),\n",
       " ('normalize embeddings', 122),\n",
       " ('imatrix', 121),\n",
       " ('load model and processor', 121),\n",
       " ('use with vllm', 120),\n",
       " ('responsible deployment', 120),\n",
       " ('getting started', 120),\n",
       " ('risks and limitations', 119),\n",
       " ('launch ik_llamas llamacli', 119),\n",
       " ('chat', 118),\n",
       " ('generate output tokens', 117),\n",
       " ('gemma 3 model card', 117),\n",
       " ('tokenize the text', 117),\n",
       " ('multilingual benchmarks', 116),\n",
       " ('licenseterms of use', 116),\n",
       " ('speeds sizes times', 114),\n",
       " ('multiturn conversation', 114),\n",
       " ('documentation', 114),\n",
       " ('model introduction', 113),\n",
       " ('finetune', 113),\n",
       " ('3 3', 113),\n",
       " ('input format', 113),\n",
       " ('span stylecolor 7fff7fquantization beyond the imatrixspan', 113),\n",
       " ('id love your feedbackhave you tried this how does it perform for you', 113),\n",
       " ('use with llama', 113),\n",
       " ('multimodal', 112),\n",
       " ('tokenization', 111),\n",
       " ('whats new', 111),\n",
       " ('benchmark', 110),\n",
       " ('resize the image', 110),\n",
       " ('included files and details', 109),\n",
       " ('how to easily download and use this model in textgenerationwebuihttpsgithubcomoobaboogatextgenerationwebui',\n",
       "  109),\n",
       " ('training logs', 109),\n",
       " ('model use', 108),\n",
       " ('drop device_map if running on cpu', 108),\n",
       " ('decode output tokens into text', 108),\n",
       " ('calculate the target width and height', 107),\n",
       " ('calculate the existing image aspect ratio', 107),\n",
       " ('split the image', 107),\n",
       " ('find the closest aspect ratio to the target', 107),\n",
       " ('modify openais api key and api base to use vllms api server', 106),\n",
       " ('running the model on a single multi gpu', 106),\n",
       " ('change input text as desired', 105),\n",
       " ('licence', 104),\n",
       " ('the mistral ai team', 104),\n",
       " ('will i release baked dynamic quant ggufs', 103),\n",
       " ('inference can also be done using transformers pipeline', 103),\n",
       " ('other recipe examples can be found at httpsgithubcomthireusgguftoolsuitetreemainrecipe_examples',\n",
       "  103),\n",
       " ('by top1', 102),\n",
       " ('model files', 102),\n",
       " ('system prompt', 101),\n",
       " ('supervised finetuning', 101),\n",
       " ('service', 100),\n",
       " ('author', 100),\n",
       " ('support', 100),\n",
       " ('model loading', 99),\n",
       " ('setup', 98),\n",
       " ('setting up', 98),\n",
       " ('deployment geography', 97),\n",
       " ('model predicts one of the 1000 imagenet classes', 97),\n",
       " ('example outputs', 97),\n",
       " ('simple chat template', 97),\n",
       " ('numbering images improves multiimage conversations', 96),\n",
       " ('training set metrics', 96),\n",
       " ('direct use for inference', 96),\n",
       " ('debugging and issues', 96),\n",
       " ('additional information', 96),\n",
       " ('model labels', 95),\n",
       " ('batch prompts inference', 95),\n",
       " ('multiimages inference', 95),\n",
       " ('generate response', 95),\n",
       " ('resources', 95),\n",
       " ('multiple gpus', 95),\n",
       " ('a hello world example', 95),\n",
       " ('example output', 95),\n",
       " ('bit bf16 fp16', 94),\n",
       " ('bnb 8bit quantization', 94),\n",
       " ('cite', 94),\n",
       " ('load model directly', 94),\n",
       " ('ppo agent playing snowballtarget', 93),\n",
       " ('prohibited usesnwe want everyone to use llama 32 safely and responsibly',\n",
       "  92),\n",
       " ('use and limitations', 92),\n",
       " ('model training', 92),\n",
       " ('q8_0', 92),\n",
       " ('set the max number of tiles in max_num', 91),\n",
       " ('using the model', 91),\n",
       " ('responsible ai considerations', 90),\n",
       " ('evaluation datasets', 90),\n",
       " ('q6_k', 90),\n",
       " ('updates', 89),\n",
       " ('generate text', 89),\n",
       " ('q6_k and q8_0 files are split and require joining', 89),\n",
       " ('running with the pipeline api', 89),\n",
       " ('information retrieval', 88),\n",
       " ('singleimage singleround conversation ÂçïÂõæÂçïËΩÆÂØπËØù', 88),\n",
       " ('since the first gpu will be used for vit treat it as half a gpu', 88),\n",
       " ('quants', 88),\n",
       " ('singleimage multiround conversation ÂçïÂõæÂ§öËΩÆÂØπËØù', 88),\n",
       " ('finetune llama 31 gemma 2 mistral 25x faster with 70 less memory via unsloth',\n",
       "  88),\n",
       " ('tokenize the input texts', 88),\n",
       " ('load a model', 88),\n",
       " ('puretext conversation Á∫ØÊñáÊú¨ÂØπËØù', 87),\n",
       " ('define the generation configuration', 87),\n",
       " ('start the model chat in a separate thread', 87),\n",
       " ('initialize an empty string to store the generated text', 87),\n",
       " ('loop through the streamer to get the new text as it is generated', 87),\n",
       " ('multiimage multiround conversation separate images Â§öÂõæÂ§öËΩÆÂØπËØùÁã¨Á´ãÂõæÂÉè', 87),\n",
       " ('chat website and api platform', 87),\n",
       " ('streaming output', 87),\n",
       " ('initialize the streamer', 87),\n",
       " ('multiimage multiround conversation combined images Â§öÂõæÂ§öËΩÆÂØπËØùÊãºÊé•ÂõæÂÉè', 87),\n",
       " ('batch inference single image per sample ÂçïÂõæÊâπÂ§ÑÁêÜ', 87),\n",
       " ('frame1 imagenframe2 imagennframe8 imagenquestion', 87),\n",
       " ('batch inference', 86),\n",
       " ('models over differences in data in scale', 86),\n",
       " ('prompt template none', 86),\n",
       " ('conclusion', 86),\n",
       " ('applications', 85),\n",
       " ('print the outputs', 85),\n",
       " ('video multiround conversation ËßÜÈ¢ëÂ§öËΩÆÂØπËØù', 85),\n",
       " ('evaluation on multimodal capability', 85),\n",
       " ('model download', 85),\n",
       " ('gated access', 85),\n",
       " ('default load the model on the available devices', 84),\n",
       " ('decoupled visionlanguage deployment', 84),\n",
       " ('cascade reinforcement learning', 84),\n",
       " ('your donation helps us continue our further development and improvement a cup of coffee can do it',\n",
       "  83),\n",
       " ('bibtex citation', 83),\n",
       " ('chat template with system prompt', 83),\n",
       " ('cooperation', 82),\n",
       " ('video understanding', 82),\n",
       " ('generate output', 81),\n",
       " ('we need to read the aduio files as arrays', 81),\n",
       " ('inference platform', 80),\n",
       " ('evaluation metrics', 80),\n",
       " ('visual grounding', 80),\n",
       " ('quantized versions through bitsandbytes', 79),\n",
       " ('ocr chart and document understanding', 79),\n",
       " ('multimodal reasoning and mathematics', 79),\n",
       " ('multimodal multilingual understanding', 79),\n",
       " ('evaluation on language capability', 79),\n",
       " ('license agreement', 79),\n",
       " ('poca agent playing soccertwos', 78),\n",
       " ('misuse malicious use and outofscope use', 78),\n",
       " ('install', 78),\n",
       " ('run with gaianet', 78),\n",
       " ('licence and usage restrictions', 78),\n",
       " ('default processer', 78),\n",
       " ('generate', 78),\n",
       " ('eval results', 78),\n",
       " ('coding', 78),\n",
       " ('when to use these models', 77),\n",
       " ('benchmark context', 77),\n",
       " ('system info', 77),\n",
       " ('from original readme', 77),\n",
       " ('quantization performance comparison llama38b', 77),\n",
       " ('function calling', 77),\n",
       " ('prepare inputs', 77),\n",
       " ('tips', 77),\n",
       " ('loading the model', 77),\n",
       " ('training parameters', 77),\n",
       " ('hardware requirements', 77),\n",
       " ('run the model', 76),\n",
       " ('no parameters necessary for base model', 76),\n",
       " ('what is a gguf', 76),\n",
       " ('usage examples', 75),\n",
       " ('output is unpooled a 1 2048 7 7 shaped tensor', 75),\n",
       " ('setfit with mini1013master_domain', 75),\n",
       " ('usage recommendations', 75),\n",
       " ('ablation study', 75),\n",
       " ('pretraining data', 75),\n",
       " ('basic usage', 75),\n",
       " ('reporting issues', 75),\n",
       " ('parameters', 74),\n",
       " ('we use the tokenizers chat template to format each message see httpshuggingfacecodocstransformersmainenchat_templating',\n",
       "  74),\n",
       " ('model info', 74),\n",
       " ('troubleshooting', 74),\n",
       " ('trademarks', 74),\n",
       " ('python api', 74),\n",
       " ('mmlu', 74),\n",
       " ('span stylecolor 7fff7fultralowbit quantization with iqdynamicgate 12 bitspan',\n",
       "  74),\n",
       " ('testtime scaling', 74),\n",
       " ('context obedient question answering', 74),\n",
       " ('base model', 74),\n",
       " ('prohibited usesnwe want everyone to use meta llama 3 safely and responsibly',\n",
       "  73),\n",
       " ('key enhancements', 73),\n",
       " ('instruction format', 73),\n",
       " ('load the tokenizer and model', 73),\n",
       " ('benchmark scores', 73),\n",
       " ('citation instructions', 72),\n",
       " ('release date br', 72),\n",
       " ('use case', 72),\n",
       " ('misuse and malicious use', 72),\n",
       " ('rest server', 71),\n",
       " ('notice', 71),\n",
       " ('terms of use', 71),\n",
       " ('chat format', 71),\n",
       " ('create engine', 71),\n",
       " ('run chat completion in openai api', 71),\n",
       " ('provided files and gptq parameters', 71),\n",
       " ('code', 70),\n",
       " ('use in transformers', 70),\n",
       " ('use a pipeline as a highlevel helper', 70),\n",
       " ('using huggingface transformers', 70),\n",
       " ('how to use the models', 70),\n",
       " ('semantic similarity', 69),\n",
       " ('intended use cases', 69),\n",
       " ('llama 2', 69),\n",
       " ('motivation', 69),\n",
       " ('model list', 68),\n",
       " ('forward pass', 68),\n",
       " ('mixed preference optimization', 68),\n",
       " ('quantized models', 68),\n",
       " ('finetune mistral gemma llama 25x faster with 70 less memory via unsloth',\n",
       "  68),\n",
       " ('how to use this model', 68),\n",
       " ('supported languages', 68),\n",
       " ('gguf', 68),\n",
       " ('unnamed dataset', 68),\n",
       " ('llama model index', 68),\n",
       " ('run', 68),\n",
       " ('q4_0_x_x information', 67),\n",
       " ('combine messages for batch processing', 67),\n",
       " ('perform pooling in this case max pooling', 67),\n",
       " ('3 768', 67),\n",
       " ('uses and limitations', 66),\n",
       " ('model license', 66),\n",
       " ('mtbench', 66),\n",
       " ('download model and use it with comfyui automatic1111 sdnext invoke ai etc',\n",
       "  66),\n",
       " ('limitation', 66),\n",
       " ('prompt template unknown', 66),\n",
       " ('truthfulqa', 66),\n",
       " ('use case br', 65),\n",
       " ('torchsize1 2048 7 7', 65),\n",
       " ('preparation for batch inference', 65),\n",
       " ('changelog', 65),\n",
       " ('prohibited usesnwe want everyone to use llama 31 safely and responsibly',\n",
       "  65),\n",
       " ('deepseekr1evaluation', 65),\n",
       " ('distilled model evaluation', 65),\n",
       " ('model version', 65),\n",
       " ('recipe', 65),\n",
       " ('model zoo', 65),\n",
       " ('contribute', 65),\n",
       " ('quants usage', 64),\n",
       " ('recommended settings', 64),\n",
       " ('license and use', 64),\n",
       " ('device', 64),\n",
       " ('finetuning procedure', 64),\n",
       " ('running the model on a gpu using different precisions', 64),\n",
       " ('infrastructure', 64),\n",
       " ('release date', 64),\n",
       " ('about awq', 64),\n",
       " ('others', 64),\n",
       " ('privacy', 64),\n",
       " ('code llama', 63),\n",
       " ('sample messages for batch inference', 63),\n",
       " ('inference code', 63),\n",
       " ('transformers usage', 63),\n",
       " ('perform inference', 63),\n",
       " ('api', 63),\n",
       " ('english', 62),\n",
       " ('critical and other risks', 62),\n",
       " ('we need to read the audio files as arrays', 62),\n",
       " ('new capabilities', 62),\n",
       " ('install dependencies', 62),\n",
       " ('future plans', 62),\n",
       " ('how to use this gptq model from python code', 62),\n",
       " ('ÂÖçË¥£Â£∞Êòé', 62),\n",
       " ('native multimodal pretraining', 62),\n",
       " ('donation', 61),\n",
       " ('finetuning details', 61),\n",
       " ('use with ollama', 61),\n",
       " ('todo list', 61),\n",
       " ('responsible release', 61),\n",
       " ('torchsize1 768 7 7', 61),\n",
       " ('model date', 61),\n",
       " ('download the model', 61),\n",
       " ('multiplenegativesrankingloss', 61),\n",
       " ('image url', 60),\n",
       " ('model architecture updates', 60),\n",
       " ('model configuration', 60),\n",
       " ('using flagembedding', 60),\n",
       " ('attention', 60),\n",
       " ('pretrained models', 60),\n",
       " ('sglang', 60),\n",
       " ('prompt', 59),\n",
       " ('use with llama3', 59),\n",
       " ('input formats', 59),\n",
       " ('print output', 59),\n",
       " ('explainability', 59),\n",
       " ('human', 59),\n",
       " ('resized_height and resized_width', 58),\n",
       " ('image resolution for performance boost', 58),\n",
       " ('min_pixels and max_pixels', 58),\n",
       " ('en', 58),\n",
       " ('download links', 58),\n",
       " ('running the model on a cpu', 58),\n",
       " ('base64 encoded image', 58),\n",
       " ('merge details', 58),\n",
       " ('more usage tips', 58),\n",
       " ('local file path', 58),\n",
       " ('agentfunction calling', 57),\n",
       " ('rewoo style execution planning', 57),\n",
       " ('main results', 57),\n",
       " ('deploying compiled model to android', 57),\n",
       " ('view on qualcomm ai hub', 57),\n",
       " ('paper', 57),\n",
       " ('training settings', 57),\n",
       " ('configure qualcomm ai hub to run this model on a cloudhosted device', 57),\n",
       " ('run model on a cloudhosted device', 57),\n",
       " ('primary use cases', 57),\n",
       " ('open llm leaderboard evaluation scores', 57),\n",
       " ('evals', 57),\n",
       " ('how does this work', 57),\n",
       " ('performance and limitations', 57),\n",
       " ('llama 31 instruct', 57),\n",
       " ('load tokenizer and model', 57),\n",
       " ('trace model', 56),\n",
       " ('gpt4all', 56),\n",
       " ('get target model to run ondevice', 56),\n",
       " ('demo off target', 56),\n",
       " ('llama 31 systems', 56),\n",
       " ('compile model on a specific device', 56),\n",
       " ('release notes', 56),\n",
       " ('prerequisites', 55),\n",
       " ('implementation code', 55),\n",
       " ('helpful usage tips', 55),\n",
       " ('chainofthought', 55),\n",
       " ('benchmarks english text', 55),\n",
       " ('messages containing a images list as a video and a text query', 55),\n",
       " ('span styletextdecorationunderlinechild safetyspan', 54),\n",
       " ('provided files and awq parameters', 54),\n",
       " ('model file and inference workflow', 54),\n",
       " ('llama 32 instruct', 54),\n",
       " ('new capabilities and use cases', 54),\n",
       " ('llama 32 systems', 54),\n",
       " ('llama 3instruct', 54),\n",
       " ('pip install q transformers', 54),\n",
       " ('vllm recommended', 54),\n",
       " ('deepseekr10528', 54),\n",
       " ('intended use and limitations', 54),\n",
       " ('todo', 54),\n",
       " ('span styletextdecorationunderlinecyber security span', 54),\n",
       " ('load image', 53),\n",
       " ('latest news', 53),\n",
       " ('messages containing multiple images and a text query', 53),\n",
       " ('useful links', 53),\n",
       " ('about us', 53),\n",
       " ('known limitations', 53),\n",
       " ('misuse and outofscope use', 53),\n",
       " ('training strategy', 53),\n",
       " ('how it works', 53),\n",
       " ('safety evaluation and redteaming', 53),\n",
       " ('nonrepeating layers', 52),\n",
       " ('you can then use the following code', 52),\n",
       " ('use it with uis such as automatic1111 comfy ui sdnext invoke', 52),\n",
       " ('openbuddy open multilingual chatbot', 52),\n",
       " ('for multiple gpus install accelerate and do model automodelforcausallmfrom_pretrainedcheckpoint device_mapauto',\n",
       "  51),\n",
       " ('lm studio', 51),\n",
       " ('dataset details', 51),\n",
       " ('benchmark performance', 51),\n",
       " ('ÂºïÁî®', 51),\n",
       " ('pipeline usage', 51),\n",
       " ('performance evaluation', 51),\n",
       " ('model quality', 51),\n",
       " ('prompt template vicuna', 50),\n",
       " ('validation settings', 50),\n",
       " ('agieval', 50),\n",
       " ('training process', 50),\n",
       " ('copyright notice', 50),\n",
       " ('ÂºïÁî® citation', 50),\n",
       " ('reproduction', 50),\n",
       " ('caveats and recommendations', 50),\n",
       " ('output is batch_size num_features tensor', 50),\n",
       " ('hugging face transformers', 50),\n",
       " ('update', 50),\n",
       " ('ru', 49),\n",
       " ('loop over the batch to print in this example the batch size is 1', 49),\n",
       " ('gptoss120b', 49),\n",
       " ('outofscope uses', 49),\n",
       " ('torchsize1 1024 7 7', 49),\n",
       " ('download model and use it with comfyui automatic1111 sdnext invoke ai forge etc',\n",
       "  49),\n",
       " ('best dimensions', 49),\n",
       " ('funding', 49),\n",
       " ('tinyllama11b', 49),\n",
       " ('inference performance', 49),\n",
       " ('example commands to you could test', 49),\n",
       " ('pip install transformers', 49),\n",
       " ('quantized versions', 49),\n",
       " ('quantization details', 49),\n",
       " ('instruction tuning', 49),\n",
       " ('output is unpooled a 1 512 7 7 shaped tensor', 48),\n",
       " ('gui tasks', 48),\n",
       " ('deepseekr1', 48),\n",
       " ('model variants', 48),\n",
       " ('inference examples', 48),\n",
       " ('torchsize1 512 7 7', 48),\n",
       " ('source', 48),\n",
       " ('base model performance', 48),\n",
       " ('model examination', 48),\n",
       " ('apply quantization', 48),\n",
       " ('running the model', 48),\n",
       " ('for cuda118', 47),\n",
       " ('for cuda126', 47),\n",
       " ('questions', 47),\n",
       " ('backyard ai', 47),\n",
       " ('automatically instantiate the model', 47),\n",
       " ('comfyui', 47),\n",
       " ('usage guidelines', 47),\n",
       " ('for cpu', 47),\n",
       " ('modelscope', 47),\n",
       " ('quantization variants', 47),\n",
       " ('clone the repository', 46),\n",
       " ('plus plus promise', 46),\n",
       " ('open source license', 46),\n",
       " ('acknowledgment', 46),\n",
       " ('about gguf format', 46),\n",
       " ('ppo agent playing pyramids', 46),\n",
       " ('kquants', 46),\n",
       " ('each query must come with a onesentence instruction that describes the task',\n",
       "  46),\n",
       " ('gptoss20b', 46),\n",
       " ('legacy quants', 46),\n",
       " ('please consider to support my work', 46),\n",
       " ('save to disk in compressedtensors format', 46),\n",
       " ('model capabilities', 45),\n",
       " ('transfer tokenized inputs to the device', 45),\n",
       " ('base models', 45),\n",
       " ('contact information', 45),\n",
       " ('model benchmark', 45),\n",
       " ('background', 45),\n",
       " ('„É©„Ç§„Çª„É≥„Çπ', 45),\n",
       " ('extract and print the content', 45),\n",
       " ('first define a tool', 45),\n",
       " ('next create a chat and apply the chat template', 45),\n",
       " ('prepare input', 45),\n",
       " ('model in action', 44),\n",
       " ('gsm8k', 44),\n",
       " ('train from scratch', 44),\n",
       " ('thinking mode', 44),\n",
       " ('training infrastructure', 44),\n",
       " ('how to download from branches', 44),\n",
       " ('configure the quantization algorithm and scheme', 44),\n",
       " ('about this lora', 44),\n",
       " ('contribute your own examples', 44),\n",
       " ('train', 44),\n",
       " ('multiturn', 43),\n",
       " ('initialize the model', 43),\n",
       " ('statement', 43),\n",
       " ('run this lora with an api using replicate', 43),\n",
       " ('copyright', 43),\n",
       " ('run demo on a cloudhosted device', 43),\n",
       " ('compute', 43),\n",
       " ('image', 43),\n",
       " ('how to run', 43),\n",
       " ('inference with vllm', 43),\n",
       " ('code example', 42),\n",
       " ('github format', 42),\n",
       " ('internvl35 family', 42),\n",
       " ('svg tasks', 42),\n",
       " ('license disclaimer', 42),\n",
       " ('embodied tasks', 42),\n",
       " ('conversion details', 42),\n",
       " ('intro', 42),\n",
       " ('deepseekv31', 42),\n",
       " ('benchmarking', 42),\n",
       " ('multiimage understanding and realworld comprehension', 42),\n",
       " ('usage instructions', 42),\n",
       " ('training and deployment strategy', 42),\n",
       " ('comprehensive multimodal understanding and multimodal hallucination evaluation',\n",
       "  42),\n",
       " ('huggingface format', 42),\n",
       " ('available models', 42),\n",
       " ('evaluation benchmarks', 42),\n",
       " ('contacts', 42),\n",
       " ('install speechbrain', 42),\n",
       " ('prepare image for the model', 42),\n",
       " ('credits and license', 42),\n",
       " ('visual consistency learning', 42),\n",
       " ('inputoutput specifications', 41),\n",
       " ('sample usage', 41),\n",
       " ('inference on gpu', 41),\n",
       " ('transcribing using python', 41),\n",
       " ('run texttovideo generation', 41),\n",
       " ('gratitude', 41),\n",
       " ('video demos', 41),\n",
       " ('simply make ai models cheaper smaller faster and greener', 41),\n",
       " ('want to compress other models', 41),\n",
       " ('configurations', 41),\n",
       " ('warning', 41),\n",
       " ('chat completion', 41),\n",
       " ('this model', 41),\n",
       " ('gpu', 41),\n",
       " ('example code', 41),\n",
       " ('use case considerations', 41),\n",
       " ('computational efficiency on different gpus', 40),\n",
       " ('evaluate the policyrun inference', 40),\n",
       " ('vllm inference', 40),\n",
       " ('no need to add instruction for retrieval documents', 40),\n",
       " ('get started', 40),\n",
       " ('pytorch', 40),\n",
       " ('risks limitations and biases', 40),\n",
       " ('transcribing many audio files', 40),\n",
       " ('swallow model index', 40),\n",
       " ('rvc model', 40),\n",
       " ('routed experts', 40),\n",
       " ('models and loras used', 40),\n",
       " ('docker image', 39),\n",
       " ('perform pooling', 39),\n",
       " ('sample code', 39),\n",
       " ('composition', 39),\n",
       " ('training testing and evaluation datasets', 39),\n",
       " ('dependencies', 39),\n",
       " ('using transformers to chat', 39),\n",
       " ('prompt format for function calling', 39),\n",
       " ('training and evaluation', 39),\n",
       " ('how to use with transformers', 39),\n",
       " ('advanced usage', 39),\n",
       " ('training at falai', 38),\n",
       " ('serving', 38),\n",
       " ('tools', 38),\n",
       " ('second turn', 38),\n",
       " ('send questions to', 38),\n",
       " ('required libraries and their versions', 38),\n",
       " ('open llm leaderboard', 38),\n",
       " ('check the content is reasoning_content or content', 38),\n",
       " ('decode', 38),\n",
       " ('community and support', 38),\n",
       " ('char', 38),\n",
       " ('model type', 38),\n",
       " ('output br', 38),\n",
       " ('input br', 38),\n",
       " ('token embedding and output tensors gpu', 38),\n",
       " ('balance of attn tensors', 38),\n",
       " ('usage warnings', 38),\n",
       " ('example ai commands to test', 38),\n",
       " ('technical report', 38),\n",
       " ('compile', 38),\n",
       " ('checkpoints', 38),\n",
       " ('infer', 38),\n",
       " ('model family', 38),\n",
       " ('reproducing our results', 37),\n",
       " ('broader implications', 37),\n",
       " ('load pipeline', 37),\n",
       " ('inference time', 37),\n",
       " ('inference example', 37),\n",
       " ('client start streaming chat completions', 37),\n",
       " ('usage with transformers', 37),\n",
       " ('with transformers', 37),\n",
       " ('models used', 37),\n",
       " ('for codellama models only you must use transformers 4330 or later', 37),\n",
       " ('multiimage and realworld comprehension', 37),\n",
       " ('translation', 37),\n",
       " ('comprehensive multimodal and hallucination evaluation', 37),\n",
       " ('licenses', 37),\n",
       " ('naming convention and parameter count', 36),\n",
       " ('english tasks', 36),\n",
       " ('tool use', 36),\n",
       " ('by throughput samples sec', 36),\n",
       " ('japanese tasks', 36),\n",
       " ('loading with huggingface', 36),\n",
       " ('samples', 36),\n",
       " ('‰Ωø„ÅÑÊñπ', 36),\n",
       " ('prepare model', 36),\n",
       " ('model variants in maxxvitpyhttpsgithubcomhuggingfacepytorchimagemodelsblobmaintimmmodelsmaxxvitpy',\n",
       "  36),\n",
       " ('citiation', 36),\n",
       " ('3 1024', 36),\n",
       " ('vision', 36),\n",
       " ('requires pytorch transformers bitsandbytes sentencepiece protobuf and flashattn packages',\n",
       "  36),\n",
       " ('about this model', 36),\n",
       " ('define conversation input', 36),\n",
       " ('licensing information', 36),\n",
       " ('instruct the model to create a caption in spanish', 36),\n",
       " ('evaluation information', 36),\n",
       " ('bigbench', 36),\n",
       " ('prompt format for json mode structured outputs', 36),\n",
       " ('licenseterms of use br', 36),\n",
       " ('the methodology used to determine training energy use and greenhouse gas emissions can be found herehttpsarxivorgpdf220405149 since meta is openly releasing these models the training energy use and greenhouse gas emissions will not be incurred by others',\n",
       "  36),\n",
       " ('eval', 35),\n",
       " ('model_name', 35),\n",
       " ('desktop applications', 35),\n",
       " ('key highlights', 35),\n",
       " ('capabilities', 35),\n",
       " ('transformers pipeline', 35),\n",
       " ('variants', 35),\n",
       " ('attention 060 gpu', 35),\n",
       " ('model optimization', 35),\n",
       " ('use flashattention 2 to further speedup generation', 35),\n",
       " ('question', 35),\n",
       " ('online demo', 35),\n",
       " ('software integration br', 35),\n",
       " ('japanese evaluation benchmarks', 35),\n",
       " ('performance highlights', 35),\n",
       " ('credit', 35),\n",
       " ('other optimizations', 35),\n",
       " ('inference code for function calling', 35),\n",
       " ('todo add an example code snippet for running this diffusion pipeline', 35),\n",
       " ('english evaluation benchmarks', 35),\n",
       " ('its highly recommanded to use decord feature for faster video loading', 35),\n",
       " ('about speechbrain', 35),\n",
       " ('expected output', 35),\n",
       " ('training methodology', 34),\n",
       " ('gui grounding', 34),\n",
       " ('load the model and processor', 34),\n",
       " ('install huggingface', 34),\n",
       " ('load tokenizer', 34),\n",
       " ('first turn', 34),\n",
       " ('your tool implementation', 34),\n",
       " ('version', 34),\n",
       " ('or', 34),\n",
       " ('call the server using curl', 34),\n",
       " ('model architecture br', 34),\n",
       " ('collaborators', 34),\n",
       " ('languages', 34),\n",
       " ('how to run model in gguf format', 34),\n",
       " ('ÁÆÄ‰ªã', 34),\n",
       " ('downloading and running the models', 34),\n",
       " ('init', 34),\n",
       " ('additional benchmarks', 34),\n",
       " ('text', 34),\n",
       " ('tokenize', 34),\n",
       " ('each value in content has to be a list of dicts with types text image', 34),\n",
       " ('sdk download', 33),\n",
       " ('clone mnn source', 33),\n",
       " ('git clone', 33),\n",
       " ('collection process', 33),\n",
       " ('model series', 33),\n",
       " ('generate image', 33),\n",
       " ('about llamafile', 33),\n",
       " ('it has a slightly soft natural feel likely captured in daylight', 33),\n",
       " ('prompt templates', 33),\n",
       " ('how to download including from branches', 33),\n",
       " ('ensure torch 240', 33),\n",
       " ('with git not recommended', 33),\n",
       " ('from the command line', 33),\n",
       " ('awq', 33),\n",
       " ('shell download', 33),\n",
       " ('document', 33),\n",
       " ('contents', 33),\n",
       " ('transformersjs', 33),\n",
       " ('generate the output', 33),\n",
       " ('ratings', 33),\n",
       " ('correspondence to', 33),\n",
       " ('legal information', 33),\n",
       " ('direct use and downstream use', 33),\n",
       " ('usage and license notices', 33),\n",
       " ('model specifications', 33),\n",
       " ('lora', 33)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the most frequent headers\n",
    "header_counts = df_sections[\"header\"].value_counts()\n",
    "\n",
    "# Display the most common headers (top 1000)\n",
    "list(header_counts.items())[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords used for detecting relevant sections\n",
    "keywords = [\n",
    "    \"responsible\", \"responsibility\",\n",
    "    \"ethical\", \"ethics\", \"ethic\",\n",
    "    \"bias\", \"biases\",\n",
    "    \"limitation\", \"limitations\",\n",
    "    \"risk\", \"risks\",\n",
    "    \"safety\"\n",
    "]\n",
    "\n",
    "# Create a regex pattern to match any of the keywords\n",
    "pattern = \"|\".join([re.escape(k) for k in keywords])\n",
    "\n",
    "# Filter rows where the header contains any of the keywords\n",
    "df_bias = df_sections[df_sections[\"header\"].str.contains(pattern, case=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "03bba311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>header</th>\n",
       "      <th>section_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>limitations</td>\n",
       "      <td>- **Specialized Task Fine-Tuning**: While the ...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td>\\nYou can use the raw model for either masked ...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>limitations and bias</td>\n",
       "      <td>\\nEven if the training data used for this mode...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>FacebookAI/roberta-large</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td>\\n\\n\\nYou can use the raw model for masked lan...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533455</th>\n",
       "      <td>CodeAtCMU/Llama-3.2-1B_full_sft_Rust_data_12K</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533482</th>\n",
       "      <td>CodeAtCMU/SmolLM2-1.7B_full_sft_Rust_data_12K</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533503</th>\n",
       "      <td>Mirmix/textual_inversion_scan24_full_8tokens</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533506</th>\n",
       "      <td>Mirmix/textual_inversion_scan24_full_8tokens</td>\n",
       "      <td>limitations and bias</td>\n",
       "      <td>\\n[TODO: provide examples of latent issues and...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533518</th>\n",
       "      <td>CodeAtCMU/Llama-3.2-1B_full_sft_JavaScript_dat...</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13722 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model_id  \\\n",
       "101                        Falconsai/nsfw_image_detection   \n",
       "119                        Falconsai/nsfw_image_detection   \n",
       "126                         google-bert/bert-base-uncased   \n",
       "128                         google-bert/bert-base-uncased   \n",
       "161                              FacebookAI/roberta-large   \n",
       "...                                                   ...   \n",
       "533455      CodeAtCMU/Llama-3.2-1B_full_sft_Rust_data_12K   \n",
       "533482      CodeAtCMU/SmolLM2-1.7B_full_sft_Rust_data_12K   \n",
       "533503       Mirmix/textual_inversion_scan24_full_8tokens   \n",
       "533506       Mirmix/textual_inversion_scan24_full_8tokens   \n",
       "533518  CodeAtCMU/Llama-3.2-1B_full_sft_JavaScript_dat...   \n",
       "\n",
       "                               header  \\\n",
       "101     intended uses and limitations   \n",
       "119                       limitations   \n",
       "126     intended uses and limitations   \n",
       "128              limitations and bias   \n",
       "161     intended uses and limitations   \n",
       "...                               ...   \n",
       "533455     bias risks and limitations   \n",
       "533482     bias risks and limitations   \n",
       "533503  intended uses and limitations   \n",
       "533506           limitations and bias   \n",
       "533518     bias risks and limitations   \n",
       "\n",
       "                                             section_text  word_count  \n",
       "101                                                                 0  \n",
       "119     - **Specialized Task Fine-Tuning**: While the ...          44  \n",
       "126     \\nYou can use the raw model for either masked ...          95  \n",
       "128     \\nEven if the training data used for this mode...         220  \n",
       "161     \\n\\n\\nYou can use the raw model for masked lan...          90  \n",
       "...                                                   ...         ...  \n",
       "533455  \\n<!-- This section is meant to convey both te...          14  \n",
       "533482  \\n<!-- This section is meant to convey both te...          14  \n",
       "533503                                                              0  \n",
       "533506  \\n[TODO: provide examples of latent issues and...           9  \n",
       "533518  \\n<!-- This section is meant to convey both te...          14  \n",
       "\n",
       "[13722 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a24d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "header\n",
       "bias risks and limitations                                                                            3682\n",
       "intended uses and limitations                                                                         2878\n",
       "limitations                                                                                           1640\n",
       "ethical considerations                                                                                 576\n",
       "limitations and bias                                                                                   485\n",
       "                                                                                                      ... \n",
       "model response quantum mechanics introduces complexity but the goal remains ethical decisionmaking       1\n",
       "no responsibility for outcomes                                                                           1\n",
       "ethical and cultural considerations                                                                      1\n",
       "„Éê„Ç§„Ç¢„Çπ„É™„Çπ„ÇØÂà∂Á¥Ñ bias risks and limitations                                                                     1\n",
       "c limitations                                                                                            1\n",
       "Name: count, Length: 442, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check most frequent headers after filtering\n",
    "df_bias[\"header\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21abe9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bias[\"header\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449a4758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of headers to remove manually\n",
    "headers_to_remove = [\n",
    "    'span styletextdecorationunderlinechild safetyspan',\n",
    "    'safety evaluation and redteaming',\n",
    "    'we spend additional focus on the following critical risk areas',\n",
    "    'cons there is always a small risk of pikachu fainting especially if pidgey has a powerful move or a status effect that could hinder pikachu however given the large level difference this risk is minimal',\n",
    "    'responsible for model quantization',\n",
    "    'responsible for training the model',\n",
    "    'please note that the default risk definition is of harm if a config is not specified this behavior will be applied',\n",
    "    'usage 2 example for hallucination risks in rag risk_namegroundedness passed through guardian_config',\n",
    "    'usage 1 example for specific risk in assistant message risk_nameharm passed through guardian_config',\n",
    "    'we specifically focused our efforts on mitigating the following critical risk areas',\n",
    "    'cons even though pikachu is stronger theres always a risk of pidgey landing a lucky hit or using a powerful move however given the level difference this is less likely',\n",
    "    'cons small risk of pikachu getting damaged',\n",
    "    'cons theres always a small risk that pidgey could land a lucky hit but this is unlikely given the level difference',\n",
    "    'limitations of phi2',\n",
    "    'unintended bias in toxicicity challenge',\n",
    "    'handle mlp down projection bias',\n",
    "    'create an content safety client',\n",
    "    '7 limitation of liabilitynin no event and under no legal theory whether',\n",
    "    'for more information httpslearnmicrosoftcomenusazureaiservicescontentsafety',\n",
    "    'limitations of phi1',\n",
    "    'usage 3 example for hallucination risk in function call risk_namefunction_call passed through guardian_config',\n",
    "    'multiturn conversational risk',\n",
    "    'warning about security risks',\n",
    "    'lewdiculouss superb gguf version thank you for your conscientious and responsible dedication',\n",
    "    'handle mlp gate and up projection biases',\n",
    "    'extract gate and up projection bias parts',\n",
    "    'jigsaw unintended bias in toxicity classification',\n",
    "    'limitations of phi15',\n",
    "    'mradermachers superb gguf version thank you for your conscientious and responsible dedication',\n",
    "    'to get the final bias metric',\n",
    "    'intended uses and limitationstodo',\n",
    "    'sample2business_ethics',\n",
    "    'usage and limitations taken from gemma 2',\n",
    "    'critic_prompt given an image and a corresponding question please serve as an unbiased and fair judge to evaluate the quality of answer answers provided by a large multimodal model lmm score the response out of 100 and explain your reasoning with specific details your task is provided as followsnquestion what this image presentsnthe lmm response this is a handwritten number sevennassistantn',\n",
    "    'safety exception intrinsic',\n",
    "    'safety check on query',\n",
    "    'llm safety evaluation hub',\n",
    "    'faroyi9b gpt4 does not have a publicly disclosed parameter count due to the competitive landscape and safety implications of largescale models like gpt4',\n",
    "    'systemlevel safety',\n",
    "    'span stylecolor466f00safetyspan',\n",
    "    'builtin perth watermarking for responsible ai',\n",
    "    'vision safety evaluation',\n",
    "    'audio safety evaluation',\n",
    "    'span stylecolor466f00biasspan',\n",
    "    'span stylecolor466f00ethical considerationsspan',\n",
    "    'realworld prompt attack risk reduction compared to competitor models',\n",
    "    'polyguard a multilingual safety moderation tool for 17 languages',\n",
    "    'warning this model is uncensored and has not been fully tested for toxicity this is a research artifact intended for responsible use may generate offensive and misleading content do not treat language sythesized by this research artifact as advice or as factual in any domain calderaai strictly does not condone use of this release outside the domain of research or entertainment',\n",
    "    'safety taxonomy',\n",
    "    'biasframes_intent',\n",
    "    'specialty bias',\n",
    "    'limitations vs original v4 model',\n",
    "    'biasframes_offensive',\n",
    "    'biasframes_sex',\n",
    "    'the llamaguard safety taxonomy and risk guidelines',\n",
    "    'results on simple safety tests benchmark',\n",
    "    'about aymurai its uses and limitations',\n",
    "    'automated safety refusal evaluator for sorrybench 202406',\n",
    "    'we swap order to mitigate position bias',\n",
    "    'limitations of chat model',\n",
    "    'weight decay to apply to all layers except biaslayernorm weights',\n",
    "    'use outofscope use limitations risks recommendations et al',\n",
    "    'use outofscope use other limitations risks recommendations et al',\n",
    "    'ethical synergy engine',\n",
    "    'llama 33 responsibility and safety',\n",
    "    'limitation of liability',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbbb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove unwanted headers\n",
    "df_bias = df_bias[~df_bias[\"header\"].isin(headers_to_remove)].copy()\n",
    "\n",
    "# Keep only headers that appear more than once\n",
    "bias_headers_counts = df_bias[\"header\"].value_counts()\n",
    "bias_headers = bias_headers_counts[bias_headers_counts > 1].index.tolist()\n",
    "df_bias = df_bias[df_bias[\"header\"].isin(bias_headers)]\n",
    "\n",
    "# Keep only ASCII headers\n",
    "df_bias_final = df_bias[df_bias[\"header\"].apply(lambda x: bool(re.match(r'^[\\x00-\\x7F]+$', x)))].copy()\n",
    "\n",
    "# Check the number of unique headers\n",
    "df_bias_final[\"header\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c658b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bias risks and limitations', 3682),\n",
       " ('intended uses and limitations', 2878),\n",
       " ('limitations', 1640),\n",
       " ('ethical considerations', 576),\n",
       " ('limitations and bias', 485),\n",
       " ('ethical considerations and limitations', 483),\n",
       " ('ethical considerations and risks', 284),\n",
       " ('usage and limitations', 268),\n",
       " ('limitations and biases', 257),\n",
       " ('ethics and safety', 250),\n",
       " ('responsibility and safety', 182),\n",
       " ('bias', 165),\n",
       " ('safety', 162),\n",
       " ('critical risks', 137),\n",
       " ('responsible deployment', 120),\n",
       " ('risks and limitations', 119),\n",
       " ('use and limitations', 92),\n",
       " ('responsible ai considerations', 90),\n",
       " ('uses and limitations', 66),\n",
       " ('limitation', 66),\n",
       " ('critical and other risks', 62),\n",
       " ('responsible release', 61),\n",
       " ('performance and limitations', 57),\n",
       " ('intended use and limitations', 54),\n",
       " ('known limitations', 53),\n",
       " ('risks limitations and biases', 40),\n",
       " ('safety module', 32),\n",
       " ('limitations and ethical considerations', 32),\n",
       " ('considerations and limitations', 29),\n",
       " ('data responsibility filtering', 26),\n",
       " ('risks', 24),\n",
       " ('limitations and considerations', 21),\n",
       " ('ethics and safety evaluation', 19),\n",
       " ('limitations and risks', 18),\n",
       " ('risks identified and mitigations', 16),\n",
       " ('bias and fairness', 16),\n",
       " ('data limitations and recommendations', 15),\n",
       " ('bias risks limitations and ethical considerations', 14),\n",
       " ('risk definitions', 13),\n",
       " ('ethical consideration', 12),\n",
       " ('gender bias', 11),\n",
       " ('biases', 11),\n",
       " ('recommendations for safe and ethical usage', 10),\n",
       " ('risks and ethical considerations', 10),\n",
       " ('model usage and limitations', 10),\n",
       " ('limitations and known biases', 10),\n",
       " ('model limitations', 9),\n",
       " ('limitations and future work', 9),\n",
       " ('performance limitations', 9),\n",
       " ('limitations and disclaimer', 9),\n",
       " ('technical limitations', 9),\n",
       " ('risk bias ethical considerations', 9),\n",
       " ('2 child safety', 9),\n",
       " ('current limitations', 9),\n",
       " ('limitations risks bias and ethical considerations', 8),\n",
       " ('ethics statement', 8),\n",
       " ('intended uses limitations and biases', 8),\n",
       " ('vii limitations and considerations', 8),\n",
       " ('potential biases', 7),\n",
       " ('age bias', 7),\n",
       " ('ethical issues', 7),\n",
       " ('limitations and warnings', 6),\n",
       " ('responsible use', 6),\n",
       " ('ai safety efforts', 6),\n",
       " ('limitations and safe use', 6),\n",
       " ('safety and security', 6),\n",
       " ('ethical use guidelines', 6),\n",
       " ('responsible ai use', 6),\n",
       " ('truthfulness helpfulness risk and bias', 6),\n",
       " ('political bias', 5),\n",
       " ('safety evaluation', 5),\n",
       " ('training dataset limitations', 5),\n",
       " ('dataset limitations', 5),\n",
       " ('potential known risks for usage', 5),\n",
       " ('uses limitations and risks', 4),\n",
       " ('model bias', 4),\n",
       " ('model and hardware safety', 4),\n",
       " ('liability and responsibility', 4),\n",
       " ('risk categories', 4),\n",
       " ('religion bias', 4),\n",
       " ('limitations and recommendations', 4),\n",
       " ('commitment to ethical ai', 4),\n",
       " ('safety and responsible use', 4),\n",
       " ('model limitations and biases', 4),\n",
       " ('risk management', 4),\n",
       " ('systemic biases', 4),\n",
       " ('bias and ethics', 3),\n",
       " ('associated risks', 3),\n",
       " ('bias and limitations', 3),\n",
       " ('ethnicity bias', 3),\n",
       " ('biases and limitations', 3),\n",
       " ('ethical and legal considerations', 3),\n",
       " ('key guidelines for responsible use', 3),\n",
       " ('safety measures', 3),\n",
       " ('intended uses and potential bias', 3),\n",
       " ('current limitations and future work', 3),\n",
       " ('capabilities limitations and biases', 3),\n",
       " ('limitations and bias statement', 3),\n",
       " ('biases risks and limitations', 3),\n",
       " ('responsible and safe use', 3),\n",
       " ('safety exception training data', 3),\n",
       " ('security and responsible use', 3),\n",
       " ('known issues and limitations', 3),\n",
       " ('risk disclaimer', 3),\n",
       " ('limitations and responsible use', 3),\n",
       " ('limitations and caveats', 3),\n",
       " ('responsible use guide', 3),\n",
       " ('limitations bias and fiarness', 2),\n",
       " ('limitations and usage notes', 2),\n",
       " ('associated risks and recommendations', 2),\n",
       " ('safety alignment', 2),\n",
       " ('geographic bias', 2),\n",
       " ('fairness and bias', 2),\n",
       " ('ethics', 2),\n",
       " ('demographic bias', 2),\n",
       " ('safety and bias', 2),\n",
       " ('taxonomy of harms and risk guidelines', 2),\n",
       " ('known limitations and potential biases', 2),\n",
       " ('limitations and critical considerations', 2),\n",
       " ('ethical statement', 2),\n",
       " ('safety and toxicity', 2),\n",
       " ('bias risks limitations and recommendations', 2),\n",
       " ('risks and biases', 2),\n",
       " ('safety policy', 2),\n",
       " ('biases and risks', 2),\n",
       " ('legal and ethical considerations', 2),\n",
       " ('ethics and safety evaluations', 2),\n",
       " ('responsible usage', 2),\n",
       " ('safety and faq', 2),\n",
       " ('model output disclaimer and limitation of liability', 2),\n",
       " ('what are capabilities and limitations', 2),\n",
       " ('unethical or harmful applications', 2),\n",
       " ('safety considerations', 2),\n",
       " ('model limitations and considerations', 2),\n",
       " ('risk management and quantitative analysis', 2),\n",
       " ('key features and limitations', 2),\n",
       " ('safety and alignment', 2),\n",
       " ('bias evaluation', 2),\n",
       " ('potential limitations and edge cases', 2),\n",
       " ('security and ethical use statement', 2),\n",
       " ('potential risks', 2),\n",
       " ('safety mechanisms', 2),\n",
       " ('safety and control', 2),\n",
       " ('potential biases and mitigation', 2),\n",
       " ('bias analysis', 2),\n",
       " ('model limitations and bias', 2),\n",
       " ('ethical singularity', 2),\n",
       " ('limitations and capabilities', 2),\n",
       " ('governance and responsible use', 2)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_counts = df_bias_final[\"header\"].value_counts()\n",
    "list(final_counts.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04eb4d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>header</th>\n",
       "      <th>section_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>limitations</td>\n",
       "      <td>- **Specialized Task Fine-Tuning**: While the ...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td>\\nYou can use the raw model for either masked ...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>limitations and bias</td>\n",
       "      <td>\\nEven if the training data used for this mode...</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>FacebookAI/roberta-large</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td>\\n\\n\\nYou can use the raw model for masked lan...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533455</th>\n",
       "      <td>CodeAtCMU/Llama-3.2-1B_full_sft_Rust_data_12K</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533482</th>\n",
       "      <td>CodeAtCMU/SmolLM2-1.7B_full_sft_Rust_data_12K</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533503</th>\n",
       "      <td>Mirmix/textual_inversion_scan24_full_8tokens</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533506</th>\n",
       "      <td>Mirmix/textual_inversion_scan24_full_8tokens</td>\n",
       "      <td>limitations and bias</td>\n",
       "      <td>\\n[TODO: provide examples of latent issues and...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533518</th>\n",
       "      <td>CodeAtCMU/Llama-3.2-1B_full_sft_JavaScript_dat...</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13071 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 model_id  \\\n",
       "101                        Falconsai/nsfw_image_detection   \n",
       "119                        Falconsai/nsfw_image_detection   \n",
       "126                         google-bert/bert-base-uncased   \n",
       "128                         google-bert/bert-base-uncased   \n",
       "161                              FacebookAI/roberta-large   \n",
       "...                                                   ...   \n",
       "533455      CodeAtCMU/Llama-3.2-1B_full_sft_Rust_data_12K   \n",
       "533482      CodeAtCMU/SmolLM2-1.7B_full_sft_Rust_data_12K   \n",
       "533503       Mirmix/textual_inversion_scan24_full_8tokens   \n",
       "533506       Mirmix/textual_inversion_scan24_full_8tokens   \n",
       "533518  CodeAtCMU/Llama-3.2-1B_full_sft_JavaScript_dat...   \n",
       "\n",
       "                               header  \\\n",
       "101     intended uses and limitations   \n",
       "119                       limitations   \n",
       "126     intended uses and limitations   \n",
       "128              limitations and bias   \n",
       "161     intended uses and limitations   \n",
       "...                               ...   \n",
       "533455     bias risks and limitations   \n",
       "533482     bias risks and limitations   \n",
       "533503  intended uses and limitations   \n",
       "533506           limitations and bias   \n",
       "533518     bias risks and limitations   \n",
       "\n",
       "                                             section_text  word_count  \n",
       "101                                                                 0  \n",
       "119     - **Specialized Task Fine-Tuning**: While the ...          44  \n",
       "126     \\nYou can use the raw model for either masked ...          95  \n",
       "128     \\nEven if the training data used for this mode...         220  \n",
       "161     \\n\\n\\nYou can use the raw model for masked lan...          90  \n",
       "...                                                   ...         ...  \n",
       "533455  \\n<!-- This section is meant to convey both te...          14  \n",
       "533482  \\n<!-- This section is meant to convey both te...          14  \n",
       "533503                                                              0  \n",
       "533506  \\n[TODO: provide examples of latent issues and...           9  \n",
       "533518  \\n<!-- This section is meant to convey both te...          14  \n",
       "\n",
       "[13071 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bias_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c403f335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_id\n",
       "01-ai/Yi-VL-34B                                         148\n",
       "01-ai/Yi-VL-6B                                          148\n",
       "0k9d0h1/nq_grpo_multi_turn_300_steps                     14\n",
       "0k9d0h1/reranker3b-sft                                   14\n",
       "0x1202/0fa06e19-bb47-4f8b-9cc3-fa3e8c3c0982               3\n",
       "                                                       ... \n",
       "zwhe99/Qwen2.5-3B-orz                                    14\n",
       "zxhezexin/openlrm-mix-base-1.1                           48\n",
       "zxhezexin/openlrm-obj-small-1.1                          48\n",
       "zyh3826/20231206094523-pretrain-Llama-2-13b-hf-76000    111\n",
       "zyh3826/llama2-13b-ft-openllm-leaderboard-v1            111\n",
       "Name: word_count, Length: 10329, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words_per_model = df_bias_final.groupby(\"model_id\")[\"word_count\"].sum()\n",
    "total_words_per_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4534225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(82.5093426275535)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_words = total_words_per_model.mean()\n",
    "mean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68e1186b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10329"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_mc_with_section = df_bias_final['model_id'].nunique()\n",
    "num_mc_with_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c577589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Cards con al menos una secci√≥n de inter√©s: 10329/61665 (16.8%)\n"
     ]
    }
   ],
   "source": [
    "# Statistics\n",
    "total_mc = len(cards)\n",
    "pct = num_mc_with_section / total_mc * 100\n",
    "\n",
    "print(f\"Model Cards with at least one relevant section: {num_mc_with_section}/{total_mc} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db81a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bias_final = pd.merge(df_bias_final, data, on=\"model_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ac52abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>header</th>\n",
       "      <th>section_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>has_card</th>\n",
       "      <th>card_length</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Falconsai</td>\n",
       "      <td>2023-10-13T23:50:01+00:00</td>\n",
       "      <td>2025-04-06T13:42:07+00:00</td>\n",
       "      <td>98988953</td>\n",
       "      <td>824</td>\n",
       "      <td>True</td>\n",
       "      <td>9142</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, safetensors, vit, image...</td>\n",
       "      <td>image-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>limitations</td>\n",
       "      <td>- **Specialized Task Fine-Tuning**: While the ...</td>\n",
       "      <td>44</td>\n",
       "      <td>Falconsai</td>\n",
       "      <td>2023-10-13T23:50:01+00:00</td>\n",
       "      <td>2025-04-06T13:42:07+00:00</td>\n",
       "      <td>98988953</td>\n",
       "      <td>824</td>\n",
       "      <td>True</td>\n",
       "      <td>9142</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, safetensors, vit, image...</td>\n",
       "      <td>image-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td>\\nYou can use the raw model for either masked ...</td>\n",
       "      <td>95</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>2022-03-02T23:29:04+00:00</td>\n",
       "      <td>2024-02-19T11:06:12+00:00</td>\n",
       "      <td>55171860</td>\n",
       "      <td>2417</td>\n",
       "      <td>True</td>\n",
       "      <td>10516</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, tf, jax, rust, coreml, ...</td>\n",
       "      <td>fill-mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>limitations and bias</td>\n",
       "      <td>\\nEven if the training data used for this mode...</td>\n",
       "      <td>220</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>2022-03-02T23:29:04+00:00</td>\n",
       "      <td>2024-02-19T11:06:12+00:00</td>\n",
       "      <td>55171860</td>\n",
       "      <td>2417</td>\n",
       "      <td>True</td>\n",
       "      <td>10516</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, tf, jax, rust, coreml, ...</td>\n",
       "      <td>fill-mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FacebookAI/roberta-large</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td>\\n\\n\\nYou can use the raw model for masked lan...</td>\n",
       "      <td>90</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>2022-03-02T23:29:04+00:00</td>\n",
       "      <td>2024-02-19T12:47:04+00:00</td>\n",
       "      <td>13086830</td>\n",
       "      <td>247</td>\n",
       "      <td>True</td>\n",
       "      <td>9278</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, tf, jax, onnx, safetens...</td>\n",
       "      <td>fill-mask</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13066</th>\n",
       "      <td>CodeAtCMU/Llama-3.2-1B_full_sft_Rust_data_12K</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "      <td>CodeAtCMU</td>\n",
       "      <td>2025-06-02T00:10:12+00:00</td>\n",
       "      <td>2025-06-02T00:11:08+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>5171</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, safetensors, llama, text-generat...</td>\n",
       "      <td>text-generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13067</th>\n",
       "      <td>CodeAtCMU/SmolLM2-1.7B_full_sft_Rust_data_12K</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "      <td>CodeAtCMU</td>\n",
       "      <td>2025-06-02T01:30:46+00:00</td>\n",
       "      <td>2025-06-02T01:32:07+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>5171</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, safetensors, llama, text-generat...</td>\n",
       "      <td>text-generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13068</th>\n",
       "      <td>Mirmix/textual_inversion_scan24_full_8tokens</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Mirmix</td>\n",
       "      <td>2025-06-04T06:39:40+00:00</td>\n",
       "      <td>2025-06-04T09:28:43+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>999</td>\n",
       "      <td>diffusers</td>\n",
       "      <td>diffusers, tensorboard, safetensors, stable-di...</td>\n",
       "      <td>text-to-image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13069</th>\n",
       "      <td>Mirmix/textual_inversion_scan24_full_8tokens</td>\n",
       "      <td>limitations and bias</td>\n",
       "      <td>\\n[TODO: provide examples of latent issues and...</td>\n",
       "      <td>9</td>\n",
       "      <td>Mirmix</td>\n",
       "      <td>2025-06-04T06:39:40+00:00</td>\n",
       "      <td>2025-06-04T09:28:43+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>999</td>\n",
       "      <td>diffusers</td>\n",
       "      <td>diffusers, tensorboard, safetensors, stable-di...</td>\n",
       "      <td>text-to-image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13070</th>\n",
       "      <td>CodeAtCMU/Llama-3.2-1B_full_sft_JavaScript_dat...</td>\n",
       "      <td>bias risks and limitations</td>\n",
       "      <td>\\n&lt;!-- This section is meant to convey both te...</td>\n",
       "      <td>14</td>\n",
       "      <td>CodeAtCMU</td>\n",
       "      <td>2025-06-02T00:05:53+00:00</td>\n",
       "      <td>2025-06-02T00:06:52+00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>5171</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, safetensors, llama, text-generat...</td>\n",
       "      <td>text-generation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13071 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model_id  \\\n",
       "0                         Falconsai/nsfw_image_detection   \n",
       "1                         Falconsai/nsfw_image_detection   \n",
       "2                          google-bert/bert-base-uncased   \n",
       "3                          google-bert/bert-base-uncased   \n",
       "4                               FacebookAI/roberta-large   \n",
       "...                                                  ...   \n",
       "13066      CodeAtCMU/Llama-3.2-1B_full_sft_Rust_data_12K   \n",
       "13067      CodeAtCMU/SmolLM2-1.7B_full_sft_Rust_data_12K   \n",
       "13068       Mirmix/textual_inversion_scan24_full_8tokens   \n",
       "13069       Mirmix/textual_inversion_scan24_full_8tokens   \n",
       "13070  CodeAtCMU/Llama-3.2-1B_full_sft_JavaScript_dat...   \n",
       "\n",
       "                              header  \\\n",
       "0      intended uses and limitations   \n",
       "1                        limitations   \n",
       "2      intended uses and limitations   \n",
       "3               limitations and bias   \n",
       "4      intended uses and limitations   \n",
       "...                              ...   \n",
       "13066     bias risks and limitations   \n",
       "13067     bias risks and limitations   \n",
       "13068  intended uses and limitations   \n",
       "13069           limitations and bias   \n",
       "13070     bias risks and limitations   \n",
       "\n",
       "                                            section_text  word_count  \\\n",
       "0                                                                  0   \n",
       "1      - **Specialized Task Fine-Tuning**: While the ...          44   \n",
       "2      \\nYou can use the raw model for either masked ...          95   \n",
       "3      \\nEven if the training data used for this mode...         220   \n",
       "4      \\n\\n\\nYou can use the raw model for masked lan...          90   \n",
       "...                                                  ...         ...   \n",
       "13066  \\n<!-- This section is meant to convey both te...          14   \n",
       "13067  \\n<!-- This section is meant to convey both te...          14   \n",
       "13068                                                              0   \n",
       "13069  \\n[TODO: provide examples of latent issues and...           9   \n",
       "13070  \\n<!-- This section is meant to convey both te...          14   \n",
       "\n",
       "            author                 created_at              last_modified  \\\n",
       "0        Falconsai  2023-10-13T23:50:01+00:00  2025-04-06T13:42:07+00:00   \n",
       "1        Falconsai  2023-10-13T23:50:01+00:00  2025-04-06T13:42:07+00:00   \n",
       "2      google-bert  2022-03-02T23:29:04+00:00  2024-02-19T11:06:12+00:00   \n",
       "3      google-bert  2022-03-02T23:29:04+00:00  2024-02-19T11:06:12+00:00   \n",
       "4       FacebookAI  2022-03-02T23:29:04+00:00  2024-02-19T12:47:04+00:00   \n",
       "...            ...                        ...                        ...   \n",
       "13066    CodeAtCMU  2025-06-02T00:10:12+00:00  2025-06-02T00:11:08+00:00   \n",
       "13067    CodeAtCMU  2025-06-02T01:30:46+00:00  2025-06-02T01:32:07+00:00   \n",
       "13068       Mirmix  2025-06-04T06:39:40+00:00  2025-06-04T09:28:43+00:00   \n",
       "13069       Mirmix  2025-06-04T06:39:40+00:00  2025-06-04T09:28:43+00:00   \n",
       "13070    CodeAtCMU  2025-06-02T00:05:53+00:00  2025-06-02T00:06:52+00:00   \n",
       "\n",
       "       downloads  likes  has_card  card_length  library_name  \\\n",
       "0       98988953    824      True         9142  transformers   \n",
       "1       98988953    824      True         9142  transformers   \n",
       "2       55171860   2417      True        10516  transformers   \n",
       "3       55171860   2417      True        10516  transformers   \n",
       "4       13086830    247      True         9278  transformers   \n",
       "...          ...    ...       ...          ...           ...   \n",
       "13066         50      0      True         5171  transformers   \n",
       "13067         50      0      True         5171  transformers   \n",
       "13068         50      0      True          999     diffusers   \n",
       "13069         50      0      True          999     diffusers   \n",
       "13070         50      0      True         5171  transformers   \n",
       "\n",
       "                                                    tags          pipeline_tag  \n",
       "0      transformers, pytorch, safetensors, vit, image...  image-classification  \n",
       "1      transformers, pytorch, safetensors, vit, image...  image-classification  \n",
       "2      transformers, pytorch, tf, jax, rust, coreml, ...             fill-mask  \n",
       "3      transformers, pytorch, tf, jax, rust, coreml, ...             fill-mask  \n",
       "4      transformers, pytorch, tf, jax, onnx, safetens...             fill-mask  \n",
       "...                                                  ...                   ...  \n",
       "13066  transformers, safetensors, llama, text-generat...       text-generation  \n",
       "13067  transformers, safetensors, llama, text-generat...       text-generation  \n",
       "13068  diffusers, tensorboard, safetensors, stable-di...         text-to-image  \n",
       "13069  diffusers, tensorboard, safetensors, stable-di...         text-to-image  \n",
       "13070  transformers, safetensors, llama, text-generat...       text-generation  \n",
       "\n",
       "[13071 rows x 14 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42067c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(475)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final[\"card_length\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd4595ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_id', 'header', 'section_text', 'word_count', 'author',\n",
       "       'created_at', 'last_modified', 'downloads', 'likes', 'has_card',\n",
       "       'card_length', 'library_name', 'tags', 'pipeline_tag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e1e3a",
   "metadata": {},
   "source": [
    "###  **Temporal Evolution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6985b9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2022     984\n",
       "2023    1402\n",
       "2024    3334\n",
       "2025    4609\n",
       "Name: model_id, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Cards with Ethical Sections\n",
    "data_bias_final[\"year\"] = pd.to_datetime(data_bias_final[\"created_at\"]).dt.year\n",
    "bias_cards_per_year = data_bias_final.groupby(\"year\")[\"model_id\"].nunique()\n",
    "bias_cards_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eceb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2022     5601\n",
       "2023    10134\n",
       "2024    36350\n",
       "2025    47915\n",
       "Name: model_id, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All Model Cards\n",
    "data[\"year\"] = pd.to_datetime(data[\"created_at\"]).dt.year\n",
    "all_cards_per_year = data.groupby(\"year\")[\"model_id\"].nunique()\n",
    "all_cards_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8672b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(bias_cards_per_year.index, bias_cards_per_year.values, label=\"Ethical-related Model Cards\", marker=\"o\", color=\"teal\", linewidth=4)\n",
    "plt.title(\"Growth of Model Cards and Ethical Sections (2022‚Äì2025)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Model Cards\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0c971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAGFCAYAAAAB7hAIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAgbZJREFUeJztnQeY1FTXxw/uwlKWsgtLL9J7FZWmoBQRG6JiQREExfJKE0VsiPhaeAEbqNh7x46UV8QCCAKKFOm99wWWtpT9nv99ufNlhpnZmU0yk2T+v+cJzN7JJPfkniQnJ+eeky8nJydHCCGEEEIIcRlnxbsDhBBCCCGE5AUasoQQQgghxJXQkCWEEEIIIa6EhiwhhBBCCHElNGQJIYQQQogroSFLCCGEEEJcCQ1ZQgghhBDiSpIlwTl16pRs3bpVihYtKvny5Yt3dwghhBBCEpqcnBw5ePCglC9fXs46K7zPNeENWRixlSpVinc3CCGEEEKIgU2bNknFihUlHAlvyMITqw9WsWLF4t0dz3m7cVzxoJDbExUh4aAuEaugLhGroC7Zx4EDB9Rx1TZaOBLekNXhBDBiachaf5JDCXFceZITM1CXiFVQl4hVUJfsJ5KQTx55Yiupqanx7gLxCNQlYhXUJWIV1KX4Q0OW2AaeUEuVKsUnVWIa6hKxCuoSCcbbb7+tvH9ff/21+vv888+XJk2aqKVBgwbqu0WLFqnvVq1aJR07dpSmTZtK27Zt5fPPP/dtZ9KkSXLOOedISkqKDBw40G8fjz/+uGRkZPi226NHjxhL6U0SPrSA2PvaZe/evZKens6bBjEFdYlYBXWJBLJ+/Xp5/fXXpUWLFr62uXPn+j5/8cUXMmLECGnUqJH6u1evXtK7d2+57bbbZOXKlXLJJZdImzZtpEKFClKzZk156623lHGblZV1xr5gvD7//PMxkiwxoCEbISdPnpTjx4/Huxuuu2Hs379fChcuzBsGMYXXdSl//vySlJQU724kDDAwYMgSgmtL37595aWXXpL77rsv6Dpvvvmm9OnTx/f333//LV26dFGfCxYsqAzcTz/9VAYPHiy1atVS7V999VWMJCCuNmR//vlnueiii2Tfvn1SokQJ23KZbd++XTIzM23ZvpfBscMDAJ52maOXmCERdAnXsLJly3pWPkKcyNixY6V169YqHCAYyErwyy+/yPvvv+9rw7offPCBDBkyRDZu3Ci///67VK1aNaL9wVM7Y8YMKVmypDz66KPKhiEuNmQRLwJ3vZHatWvL8uXL1eejR4+qJ6RPPvlEjh07ptz3L7/8spQpUyZmfdRGbOnSpZU3iDeZ6IwPeLHhbeJxI2bwsi5BtsOHD8vOnTvV3+XKlYt3lwhJCJYsWSITJ06UX3/9NeQ677zzjlx++eUqrlrz7rvvKtukWbNmKub14osvluTk3M2pO++8Ux5++GF1HZs1a5ZcffXVMm/ePKlSpYplMiUicffI1q9fX3788Uff30ZlGDRokAqcxhNM8eLF5V//+pd069ZNKUAsgAdIG7F4eiLR36D1K1OvGR8ktnhdlwoVKqT+hzGL6w3DDOwD+gPvtxf1iETHb7/9pt7yIK5VO67uuOMO2bZtm9x1113quoNJYK+88orf784++2xlAON7hDzdcMMNypbJDbxx0cALjMli8+fPpyHrdkMWhqtxcDVQDsSlfPTRR+ppB0Ch6tatK3PmzPELytbAq3HNNdeoRLowgM2GG+iYWHhiSfTgRhHJUyohuZEIuqSvM7ju0JC135AlBMYqFk27du1UpoGuXbuqv3/66Sc5ceKEylBgZMeOHcoTi3h9TAr7559/5Kabbsp1f5s3b/ZVqULmg4ULF0rDhg0tlyvRiPudAYOJWroImG7ZsqU8/fTTUrlyZVmwYIG6oHfo0MG3bp06ddR3iEcJNGThOb3ssstUTrf//ve/IY1PhChg0cDo1QHfWDRQUPyNJy6g/8dFUH82YkW7nduOVzsuAsEMECf1Mdp2J/UlkWQKpUtulimwHf/r6w7ajdckfV3Cd4HbsbI9cJ/oR7C+WNUea5nweffu3crzHYhbZbKy74kuk14HbW+88YbKUKDb9frffPONjBo1Sj1wIuTg+++/VzYM1pk+fbrKaADbAusi48G4cePkyiuvlIceekj+/PNPdR3DbzHBrEaNGup3HCfxaw/8zrGGLPK0If4EcbFw5SNe9oILLlBxK3DxFyhQ4IwnZ8TH4jsj+Pv6669XrwfgwcXvQgFDOTAuVwd061JoMIahnPAK62wFGDwoHhQQN1TjQdZKifWMg67j+bKzs/32hXYQ2I5+61hAI8hHF9iO7WJ99AP90aCf2D76jSWwPbDvdssEvCaTF8fJDTLhM77z6jjhO+wD10KUZsRvMJHECB7kse2tW7f69R2vJjGnAJ4i47aRDggz9Pfs2eMXxoDrKK5vxkms+rqH1FTGtEG4BmPZtWuXHDlyxNeOcCtcM9Ff47HEtrEPXFONssJh4QSZ0CfIAUPWKzJ5cZziIRPsER1yAplgLwD8zihTp06d1IJ9HDx4UOWZ1TLBDpk5c6ZPJjw04TfYxhNPPOGTCccLMuk+cZzETyYc10jJlxPMRRAncMBwsDGLEELiqcboPQXnnXeemuX37LPP+rIWwFWP9s8++yzXV3LBPLK4aSDzgbFELW5UCFVA/AxmI+JpCyS6Vyzadtyggz1YOKmP0bY7qS+JJFMoXXKzTMZ23GTWrVun4u9w/fOytyWeMuEzbqDB4hLdKpOVfadMkbcbdSnY+e1GmZwyTrDN0tLSlDFttM2C4aiEjLDokYNt9erVKm4WN67AtFd4mgiMqUVIAWYdIk4lN+CNwUExLnpwjItu0wdWLyCwLbf2Uzk58suGDfLJkiXqf/wdbP28bDte7UhHguMDJQu1vhH8jQeCF154Ie59N/6NByFMKoxmO3ndJ44XXkmFWx8Pb4jPisUxMI5hqHWRWQQTEqzaJ2b74uIU7XYCdcmOcUJ8HHQh3jqprzuhrkt6HbvaA9tC9cWqdspEmdwsk/Ec9opMZzlknFwTI2sEruo1a9bILbfcovK0we2NeBNM4AIrVqxQLmfE0hp55plnlMu7ffv2yktbr149cQpfLlsmA6ZMkc2nY3FBxWLF5IXOnaVb3bq27BMxPTAY+vXrJ6+++qrfd/fcc49KYXbrrbeq1yh2E+0EHTyFwduOGaHwhuPhBq9t7r77bpWqJNCocRN4vQIjDmhP/19//aVKFZoB4wgDONhDG7x8AEYa9hNtRRnkSbz33nsllsDARvgPJkKg/3j11apVqzN02er8019++aUvTIF4F1xD8MrTzdcSp7NlyxZJBOCt1K/xE0GfKlSoIE4kroYsbpJXXHGFcstDEYYPH65CA2688UaVbguVNFApAxVY4DnFDRVGbLCMBaNHj1bxZchwgBsVJoZZDTypew4fjnj971eulD7ffiuBLxO3HDgg1372mbx55ZVy+ekqIJFQElWNIjxZEC6B/LvPPfecL7UPjALEECOGJhbgxI5m9jW87yjzBw/hk08+Keeee64yhGHYPPDAA2ps8zLbGBcb6Ea8Z70Hy85hFTg/8KBnxIoLKx4QscQKvFXp3LmzOtdffPFFpbuYEIoHG2DnzYKVnhID6JCeD0GIWV3S91cSP+IaWoBUFDBaMdmre/fu6ikZqbWQ1gLACEMiYnhkL7zwQmUIwGsSCqyP7cDgQf1jq4ERW3r06IiX24IYsSDn9ILvo9leNEY0EjXDmDUeL3yGEYtXxUYQM9y/f381+QGxwDAmkaTZyA8//KDCPnDSwpsFj2IgCHDHZD2sg33DGIHXK9IwbMzoxHaRzgQeY3jWsc/bb79deee0QYUKK82bN1c3I+gE0p7oZPIADzK4wEyePFl59uGZRN8OHTokPXv2VNtB0vkxY8ac0Qd4qxGsj+OAgPRrr702aF8hE/QUM1I18Hgak9ljn9g3Yq0B+vT111+rz7oKjH5tD49p4IMZtoVzAl703MojYxs4FsZFFw6Bhx4PAzqsA4tx/JAhBMcTmT7g+TQaxAgtCPQYo444ciZCNvQR+Z01iG9HOpkiRYooHYAnPVi98VBMmzZN9R0zguGJr169ujJsX3vtNfVQpHUpUNegvxhfo04PHTpUfYd+YmYw0vlBbl1JR4c46FnJOvWOBroLfcF6ODaXXnqpMqqNnnA8WE2dOlWlBYReoa/wvBt1EfH7OB5YF7kjN2zYEPHxINaD+Dt4DKOZFU1IMKBDmPhEXUpgQxYeQ3hicdOBUYu/cePSwJgYP368UhTcpGCIGb1auPHgxmb00sGLg23qeseJzG233aZy7xoNkGCvoOHthMcL4QhIDYKbPqqo4bgDBLOjEAW85zAoUZf6wQcf9NsGQkJwE8dDx6JFi1TdaRSuGDBgQER9xYUA49+jRw81czEQGAnaowqjbuTIkareNQxDGCfaGDGCPiLsZNmyZaoW9v33368MOsSpwmCCkQF5NUhMDYMIM0thzE2ZMkU9QAUDBhC+wza00YP9YMamrkyHfcGrHCwV3B9//KH+RzEQGD7GBw6UL8TxxP8YExhMZsJAYMDiTQYeCLAvPSteg0ozMOohP44x9CYUSAwOwxpJwxcvXizffvut0hcN4ppwDi5dulT1HXkYoV+RgvMb/QtWaUcbscF0DYat0aCGAfrxxx+rvmBcJkyYoHQIcmvvLsYY+8LxCQZ0CscEMiLlH/aP+urGhwo8pOChAw9X6DNCn/CmCeCVI+Kd27Ztq/qJbeC4JcIrSKeT24MhIZFizGZC4oOjYmSJtdx8880ybNgwnwcIhiWMRW18ATwgwDiBoQSPE3j99ddVLl54sGD84Xs8YGgPJjzoMGIQy6pBmhIYodqjBa8mDAQ8bMCIyO31C1KUwBiMJCTEaGhVq1ZNGSswGOH5M74Gh0GqE1njO8iD+tiIpQYwtHRyagAjBJ4zvAWAtxchL4HeayNaNgAjBuvCENOhLfgfRkww9FsHeFwDQw7gAUTeQXggsR1MZkSsOAzRUCAcIzAEAB5LeKURpoPZ/jCog4U3/Pvf//b1E8Y/9ocwFJ2pwwhCPlCa0fiAgmOvMXo0Mfse66MsIzzdkXDdddcpDyf6g74ijAjjhbh53Z9gugYdwG+gqxhHZDCBDus81NCTwBACvIEIFaoCzysMWJwz8FKDDz/8UBnCeHhCP7VBhNhd/QAOYxp6p+O9MS7QJ/09PLeEEEKsw1FZC4i1wFiCUQIjFZ5ZfDbWi9beLdyM8cpTgwkveB0KTxbA/8j5ayRwwh28o9iPjqnUr1nhaUVKodyIJgscXoXDO4wwCRic2ggLzKeH1+VGOZEFwygHDBoY5RoYvTBeYfTAcILhosMCgoH9IqYTufPgfYVhiwUGLI7p7NmzzwgZiAS8tjfGFuP1vTF0Ihg4DvCWGxck844EeKuN+wLB9oc2vO3QDwLBgIcZ32NSAPqE44j8hOGOoxHIDV3FGxqEF2A7Tz31lAoz0K/sg+ka3iBoXYPs2E6oh4hIgM7DO23UFzx0QF/0eQHwcGB8i2QcK+gXvLroG/QVD3bGsANCCCHmoUc2CjDZaufp14a5cfLUKTnntddkW1ZW0DhZvFwsV7SoLLj9dkmKMM0E9h8t8F7qV64I07ALeDyRJQGv5jU6B10kdaRhdMM7pl/LhwIeZBgGWGBo4ncwYPF3YEJ8eFejAYYXQg1giCL04LHHHlMxoogXDua5QywojBUYsVjg2YQXEZ5q/AbGrPbmRUPgzHm8is4tBguv9I2v+PO6P/3aO9j+cvOqI8QD3keUfMSxwLHBK39M2sTYRFPqGQYsjGAsCCNBqBBCY5DNIJiuafBwg/R9sSLYWBkfymCUo58IU0EIxCOPPKI8xcEmrJLYgDFC/DhDPIhZoEN440Vdii/0yEYBMgZkFCkS0VK2aFF5qUsX9btAFdd/v3TppWq9SLcZacYCI/CK6qpBMPYCgTcJr53xClWDdWGI6TRmeB2qYzo1mJQXOLkM3kkYU3rBK18YIJhskxswxG644QZlnBorkmhgvCDmEIYuPHyIfcWrc7x6z81bqeWE0YGJZBqEMgROCoQXDq+j4Q1EXCOMM8R5BgMXL/QBMbeICcUkOXg3EfONkAN4hEMZ0zqxf6ziq7A/s/uCoY9wAYQ5hPKUwwBGCAoMNYx9sLGMFoRawNMJry6OeTBd0wvkxAMG+oGHi7wee+g89M2oL9A7xNVGm94PIScI8YGHHp5lZA4h8Z9pTuODmAU6hOsJdSm+0JC1EeSJ/aJ7d6kQUJUCeWTRblceWSN4xYpXobjxB0uFBUMLHjTEwsJrhPUQiwmjAZ40gBhHxAxiHdzIcSMOnHyEGeK4UcP7i1e7WB+xhNh2pGED8OIhBhGvc9977z3VF2wHnjgYAzBm4XHDhQM1qteuXaviGOGxyw28foY8kAGGKcog47WvMeky6mUj1hL9R1wx+gCDyBh+EAhCBzCpCDP7sQ9sD5PAYJCHe7WN+EzcTHHMUeRDFyXIKzjGKNUcuGjPKgxQGGUwzBGPnNdZtvBQw1DFccLYwIONsQAwJPEQpMcGE6Cizf2KBwDoDDziCAfBAwJ0C//jQQxyBtM1PEzoNw+QFVkv8DYCOohwA3jZETcLdBUejDfCQoJlVcBD2FVXXaXOBXiVEc6AmHN4itEeCdgvDFhM8oI+QSb0lXGy8QW6j/HgTHNiFuiQmespsQYasjYDY3X9gAEy49Zb5aNu3dT/6wYMiIkRqzFWMAsGvJuYAY7XuPB24dUsJtzo5P0wHjHTG0ZB48aNlXGCuEUj8ETCAwYPJ7yUMDyRF9iYjio38Coanl4YDJgkhG1gWzAU//Of/6hXOAglgBH9+eefK88Y+o5Z45GAbWB7iFeE1xUeVKTn0iB8ANkDkL4NxgbkxL4RsxoKGKvw7BljYfE5sC0QeH5hDMJwQ5aGSI2jUGBiEY514KK91ZhJjwcZHDMdjpEXYCCiqAImb+G4IJRAp6SCbiD9FkIr4HmEMa9rlUcKYrNhWOLhCdvH8YVOfPXVV74MEsF0DWEgxmwXmPSF1GlI/wWvPQxSnZ4LxihCFDCxDa+YjdkOjCAsAPoBGRETDiMaaegiLZqAUAq8QcC5Be80MhYg4wPCIkh8cVBlduJyqEvxJ19Ogo8CDAAYSMHq+era58j5GWwGNwkPVAthDXz1QsySCLrE603kdOrUSb1xwBsQhLzgoRAPNAjrQVYNPIjjGOLhCplKAn+DhxE8qOoHWXjxEQKl48DhSb/++uvVZzyo4QEOnjfcK/AgHe7hliROZS94YhFyhImg0ZRUdSsVYljZK5xtFggnexFCCHEVCBPREzDhrUeYEMI/4GXHgw689fgfhmvgb2B8IMUgQk/wGw0m4wUrFw0POrzp2AcKoOD/wIIxhJD4QUOW2Apr1xOroC4RjTGLCDw2MFoROoJc0Ujdpr32xrzJ+je6dHYknn2E5qAoBuKbAcJEEIqC8Ku8Zgkh3gE6pCsEkvhBQ/Y0eEo3BmzjNQH+1imkdARGYHodjRXtdm47Xu36BPeSrE7qSyLJpMvrekkmY7te9HUnWNo1XJeM1yM72gP3qY+7Xe157Tuqt+niLpi4h8mBiLPHpFFk1kCYAGKnkR9a7xMhAvo3iHc29gXbw3YRp405AIglx6QwxJrribL4HnMGMGkS+aatlskr44TfBms3nsNWtMdL9xJVplOnxzUWuhfNBLqENWSRUxWLTsGDMqyItQKYfY7CAXjSx/eYiY3Bw8UMk3SQlsd4kNGG77CecdDhQcKgBOY31Z6lwHbE/+H3geUTEbsV2K7TfqAf6I9Gx3+h38b0Qro9sO92y6S/85JMXhwnN8iEz+iPV8cJ32EfuoQwfhM4KQ9GFLZtTGuG3yMTA2JskQHDuG3EtGHyHOL4NDDwMMkN17fMzExfu77uoTS1MZMDPJlYkOEBJZg1iAvENRP9NR5LbBv7wDXVKCsm41kpk85WgomogwcPVpM5YXgiIwhCAJDpAin9dMYW/Rv0CZM4UToZ8a6QCRMTsV3E4mGy4o033qiypSA0AbKhH1omxOHCUws5rJbJK+N08OBB9VCBdmMfISv6iKw4xiIpiGdGH7EufmOcMInMOjgGxr7jGKDvOC7G81JXMcSxMcoErynOWePx1ccG5ylSMRplwvHF/ozZZKBDgTJhH/gbFSJxzL0gU7hxQv9ipXvQoUjhZK/TAcUYdGNAMRQEA4gnb+Pki0T3ikXbrifoOKEvVrU7qS+JJFMoXXKzTMZ2PdkLE490nlN6+iJrh2GAazVuhDiO2oOKVH7InIFMJBrsHzdQZPDADRM3W2MfYbwiywRu+DBY8RnGgn6ggdGJktQILaBHNng7JnslgvcS24NRB+Mu8Px2q0zh+gjdj5XuwTaDsc7JXlGAwQmcdYi/9YHFojF+NmJFu53bjnV74InhxD7mtd1JfbGq3Ul9iVaXQrU7oe+RtutFX3dAsJnQgdcjq9tDzb62sz2aPsJjBSeDTreGtIAwRuGJRXlkVE7r0qWLeijAglR6uCkaf4N18BsYIGiHt0jH0MJbiwwI6CdibJGSEB5bTPLCxDJ432DcWimT18ZJ/9YNx8BsX/RnL8mU27jGQveiyQJBQ5YQQohrgIfmuuuuU68wcbNDLCtiZHHDRUotFD5B0Qx8hzzN8CIh5MD4G7zuRDEV/AavxDGJC95WPDAh9hXFUDTYBoxYxM3CM4T8woQQ58DQAuaRtRWoVygvFCHR4HVd4vUmduhJK8QeEiWPbKLpUgWH5pFNjKNPzgAzd2EU6EkEmPRgTGljBTq+JppnJXg+unbtmmc5nABi9dAnlE8l8dMlQoIBHcKkJeoSMYsxywiJHwwtcMETZ16fglDjHWVYO3fuLJMmTTLdD+0Nw3ZbtGjha8csXsSeIeh9xowZfqVZEXsWaoJOLPnrr7/Uq0FM0sATHmaFo5/333//GfFuxJk4RZeIu4HRgZn3mIXvZQ8/iY0uYaI44q2pS/GDhqyHQXLwe++9V/2PC7exFn1egQGIGDGjIYsJEEgdAkPWiSB+DjFwl1xyiZq0Ub16dTUb+fPPP5dHH31UVfTJC+Fm0RPiNhLldTA8aHiDg8wGifBKOJavgwmJB94/ixMU5HiDgXbXXXfJZZddpkIHrAAJxT/55BO/XHHIt4j2QBYvXqyMR+TNwxMryjwac89hcgXyPyKkAd8jr2PgKxrcdJA+B3GDSEmE2unIERkpmJHcu3dvNYsZkzs6dOigtoW0PKNHj1YTOXRfMElE76d27drywgsvBA17QMJ1PBRgHfDHH3+oWc6Ia2zevLny/hrBE3uPHj3UpBRsu2bNmpwwQgghhFgADVmPgrriderUUcbWzTffrIxNK+J4zjnnHJXnEknIAfIw4nX9Lbfc4rceykUipAF54GDowfv5448/qvKOmjFjxigDG32bOXOm8ujCu2sERixmEGM2MhKcDxo0SMnzyy+/RNTfqVOnyu7du5WRHAwdFwyDGWl10E8kUEdFoIceekgdRyOoGLRixQqVvgeeXhjml19+ucpJuWDBAnn88cdlyJAhfr+B1xfbnDx5sixbtkxeeeUVlfaHEBIf+BqYWAV1Kf4wtMCjIJwABh+AQYm4UBh/xvjVvHLbbbcp4xPbhyEKbye8jUY++ugjNQv7gw8+UMnKwbhx4+SKK65QlXNQ2eP555+XYcOGSbdu3dT3MFZheBpjbxHXCgO4ZcuWqg2pcWD0wpPatm3bXPu6atUq9T+M+nAg2fmIESN8f8Mzi1hgGLLdu3f3tUOWN954wxdS8NprrykjGMcbHtn69eurWu/whGtg7MNjC28twIMAif5mgYpchJgF4QR8kCRWQF1yBvTIehB4DOEFRZlFgJJv119/vTK2rAAGLIy8tWvXKkMWhm0g8DwiDACv0rUnuHXr1sroQ/9gWKNsHV7xa9BPbeyB1atXq9AA1EpHDK5e4KFFXfVIiMYLjZLF8DjDKMd+YKQGlmls2LChX1ws5GzUqJFfuiRtdGtg1CIco0mTJsozPHv27Ij7RP4HZwcTq4AOIb6dukTMQl1yBvTIehAYrEgvY5zchRMNHi14RZGbzQyIZ8XrdMSUwut66aWXhqyLbGamuY6nRcaFwAkLkXrndEaC5cuXn2FgGoGhiZAAhDtgPSRMR+32uXPn+q2nvcvRgOODhOw//PCDCklA9aF77rlHxeiSyGHWAmIFuBbiQZozzYlZqEvOgB5ZjwEDFh5LGGTIY6qXv//+Wxm2KL9oBfDCIodrz549fXXNjaAsJPaJWFnNrFmz1KsYxO3CmC5XrpyfoYi+I85Ug7hTGKzwiqKuuXFB9oRI6NSpk3r1M2rUqKDf6/yz6FurVq3k7rvvVmEA2EckXl/IuWjRImXQa+bMmXPGevDyYkIcQi0QUgFvLyGEEELMQY+sx8AEJMySh7c00POKFFTw1t55552m94O42127doWsuIFZ+sOHD5e+ffuq2FNMuEIqMEwKQ3wsGDBggDzzzDNqFj9iWMeOHetX2ABeUXhJMcELr5WRExdPvzA6sd9gmRIC0TGtKE955ZVXSv/+/ZWRiv4g/hVGMryx6AMeABCji/jY999/X+bNm6c+h+Omm26Shx9+WG6//XYV74tiCIGeVkwcQ8gC4mcR94sxggFMCCGEEHPQkPVYbj4YqkgxFSx8AIYsPJPwIJoFr1HCBbkj5daUKVOUsXreeeepv7F/GKua++67T8XJwiCFpxZe3quvvloZq5qRI0cqbyayFyAmF1kGmjVrpjIKRMpVV12l4lKxDRieKH0Hj+7FF18sTz75pFqnX79+Km0WYokhG+KL4Z1FpoFwIJb2u+++Uw8H8OTCi4zJbJBVg9fh2shFzPAFF1ygjGcSHXx1R6wi2FskQvICdSn+5MtJ8CjlcPV8WfucEBIr4n29SZSCCIlGPJwu1CVvUiGGuhTONjPtkcWrUcQ1YvIKZpTDWwZPVG6vYEnizjSHt5XeNGIG6hKxUpfw0ICHBeoSMQN1yRlEbMgiLhGVjvAaFbOHYSnjNSmS2MO4RX5PVG7CK1bENhKiJ3BxpjmxAuoSscr4QEYUTCSl8UHMQF1yUdYCTJJB7CASuU+bNk2lWtqzZ49K/A6vLJLOP/LII6rqEdIdIcUQIYQQQgghcffIXnbZZaokKaofBQPeWCyYtINSnJjAQwghhBBCSNwNWczojhTM2sbiNhB/h0WDWDxdSchYUQivD4LNj7Oi3c5tx6sdxxF4SVYn9SWRZAqlS26WydgeeL1Bu/GapI8Bvgt2bMy2630GtqMtXHtgH6Ntt6LvufXR2I7/UUXQSzKFaw+lS3bKpOPZ7ZLJKeMUiS65TaZwfdTjaraPkbQHfmd5+i3k+vziiy9Uwvj7779f0tPT5c8//1T5QZ2alipYOVIsJ0+eVH9v2rTJF9uLlEpILYXYF8TlYfYcUmxggdKizXiQ0YbvEDtsHHR4sDEoKGFnRHu2A9sR/4ffYztGEH8T2I7tYn30A/3RQMmwfcilZTO2B/adMlEmt8mEmHyvyYS+4zqD3+3YsUNdR/GbwBLJlStXVuts3brVr+9VqlRRk07wW+O2sR1cxxAKpsHcBlyrMRvYmLcZv8c1EOsbC3wgdR7yMWN94zHDdRLbwjaMxwbzJ3AsMX/CKGtaWpo6bsa+AFRFwrFC/mujTLgGY3/GdHw4hrjfoH+68p+WFan5EOqGRYNJOKFkwj7Qdy/JFGycsA2sjzelxnboAGTFvc8oEwrnmNU9hB/aKZPTxgm/QfEfL8lUIsg4oX/YDvpiXB/rYkFu+SNHjvj1Ja+6F6paqCXpt5CDVOcpRV7MFStWqLACxMhi50gq7yZ0igcMujHFg37q2L59uxp4ZGeAAuqnl0T1ikXbjhMyWJ49J/Ux2nYn9SWRZAqlS26WSYObIG4CuBaVLVvWVm9LqHYYKF7zIAVrx/+42epy016QKVx7xYoVYy4T0m8likc2N11ym0zh+ogH41h5ZGGbwVi3Jf3W4MGDpVevXiqxvjE7QZcuXVSyebeCwdGvLo1tKKOKA4ubDIkOnADa+MAxJCSvJIIuwaOhjVhN4DXJeLG3ul1/jnY7wfoYbbtdMgVrx00Sxod2THhBpnDt+nMsZdK/tVvWeI9TJLrkNpkiGVcr+phbe6jvLDFkUbZzwoQJZ7TDUof30mtgEGHMli5d+oxXlCQ8OMnxSgHHLxqlJCTRdAmv8lghiBBCoidqQxbxZXD5BrJy5Ur1+t2r6BhZEp3xgWOGWCEvGh8kdlCXCCGEBCPqOwJyyj7xxBM+7yQ8loiNHTp0qF99eUJ0ADshVkBdIlaAexYrMREroC651JAdM2aMmq2GV+2IDWnbtq3UqFFDxcv++9//tqeXxJXAc4YZjvSgEbNQl4hVwOjA/YrGBzELdcmloQWYVYvKXTNnzlQZDGDUNmvWTGUyICTwdTDSdCC9Bw0QYgbqErFy4iDuW/Dw0wAhZqAuOYM85ZEFbdq0UQsh4cBJDuODELNQl4hVxgfyZiJlEo0PYgbqkosM2RdffDHiDfbv399MfwghhBBCCLHOkH3uueci2hieSGjIEkIIIYQQxxiy69ats78nxHPgwQZJ3vnKhZiFukSsAjqkS9QSYgbqkstjZAmJ1PggxCzUJWKlLumSooSYgbrkYkN28+bN8u2336r8sdnZ2X7fjR071qq+EQ/MNEdpXxTK4ExzYgbqErFygg7qtyMDDz1pxAzUJZcastOnT1dFEapVqybLly+XBg0ayPr169WAIg0XIUaQa5gQK6AuESvAvQoFffA/jQ9iBuqSM4jatTFs2DAZMmSILF68WFW0mDhxomzatEkVRrjuuuvs6SUhhBBCCCFmDdlly5ZJz5491efk5GTlJUEyYJStffbZZ6PdHCGEEEIIIbExZBHYrONiy5UrJ2vWrPF9t3v37rz1gngSvGopWbIkX7kQ01CXiFVAh1iJiVgBdcmlMbItWrRQ5Wnr1q0rXbp0kfvuu0+FGXz55ZfqO0IC61ATYhbqErFSlwoVKhTvbhAPQF1yqSGLrAQoFQlGjBihPn/66adSs2ZNZiwgZ8w037Ztm/Lcc6Y5MQN1iVipS5mZmSqdG3WJmIG65FJDFtkKjGEGr776qtV9Ih4CMzoJsQLqErGKkydPxrsLxCNQl+JP1I8Q8+bNk7lz557Rjrb58+db1S9CCCGEEEKsNWTvuecelW4rkC1btqjvCCGEEEIIiQVRG7L//PNP0MIHTZs2Vd8RYgyEL1OmDGd0EtNQl4hVQIdYiYlYAXXJpYZsSkqK7Nix44x2TMRAXllCAmd08iQnZqEuEauADhUoUIC6RExDXXKpIdupUydV3Qv1hTWYtffQQw9Jx44dre4fcfmMzg0bNqj/CTEDdYlYBXQIOc+pS8Qs1CVnELULdfTo0XLhhRdKlSpVVDgBWLhwoXrt9/7779vRR+JiUIOaECugLhGroC4Rq6AuudCQrVChgixatEg+/PBD+fvvv9Xrvt69e8uNN94o+fPnt6eXhBBCCCGEBJCnoFbkj73jjjvy8lNCCCGEEELiEyP77rvvyqRJk3x/P/DAA6qqRatWrVQMGyEaBMCXL1+egfDENNQlYhXQobS0NOoSMQ11yaUe2aeeekpeeeUV9fn333+XcePGyfPPPy/ff/+9DBo0SL788ktxIwjWNgZso9xcYAA3lBWLXe3YJ+JtAmNurGyPtUw6k4WdsnKcEkOmpKQkz8nkpHHCZ+wzsF33JVS7E2TKrY+JLJMe11jKhN9ynLwn06nT4xqL6140E+iiNmRRDKFGjRrq89dffy3XXnutCjNo3bq1tGvXTtzC+PHj1aLLy0GuokWLqs+pqalSqlQp2bt3r2RlZfl+A88zll27dsmRI0d87SVLllS/RQoyYxlNTIBDDDG2bVQGeJZg4G3cuNGvT5UrV5YTJ07I1q1bfW0YVEysO3r0qF/aM8QjI14Z/duzZ4+vHfvDfpFVAtkkNPGQSZ8E+G779u2ekMmL4+QGmSADPuPa4xWZnDZO+D36iPXxWVO4cGEVTob1jX3HMcC2sA1jmU7k1URKIhwbo0zwXOEmaOyLPja4ae3bt89PJhxf7M+YIQcPM+np6ap/xuMOWXHcDx8+rBZNwYIFz5AJfcrOzlbH+MCBA56QKdw4YRux1r2DBw/aKpNTxgn7wN8VK1ZU57sXZAo3TuhfrK570KFIyZcT5ZS70qVLy9SpU1XGAiyDBw+WW265RdasWSONGzf2E84N4EIGRcGgFytWzLPelnjIhM+bN2+WSpUqqe+8IJPVfadMkesSLnq4aQbiVpny0m6nTDBQvOZBCtaO/eNGjBuy/s7tMoVrh5EVa5lQ6TMRvJeR6JLbZArXRzwYx+q6B9sMxjoMb6NtZolHFrli+/btq4zYlStXSpcuXVT70qVL5eyzzxa3gsHBEtgWal272vVA2tUeL5nslJXjlBgy6W16Saa8tNslk/4cj2Ng9zhFK6sbZQrVnpfzxqxM+rduOP/idd44WabcxjUW171Q3wVdX6IEr+NbtmypXMgTJ05UrmOwYMEClYKLEEIIIYSQWBB1aIHX0KEFkbivSfTo4HBCzEJdshe8Dk4UEkmX8Do41lCXvEmFGOpSNLZZYhx9EhfwjITJAQn+rEQsgLpErAI6BOODukTMQl1yBjRkiW3g5MYEEp7kxCzUJWIV0CFM7qUuEbNQl5wBDVlCCCGEEOJKaMgSQgghhBBXQkOW2EqwlB6E5AXqErEK6hKxCupS/Ik6jyzyx4bKN4ZKFqi806tXL7nooous6iNxKZjJGSyBPSHRQl0iVuoSEtgTYhbqkks9sp07d5a1a9eqEmswVrGgtBoqe5177rmqFFmHDh3km2++safHxDUgAB7l6hgIT8xCXSJWoUvUUpeIWahLLvXI7t69W+677z559NFH/dqffPJJ2bBhg0ybNk2GDx8uI0eOlKuuusrKvhKXgZMb9bdRo5uvX4gZqEvESl1CbkoU86EuETNQl1zqkf3ss8+CVvC64YYb1HcA369YscKaHhJCCCGEEGKFIYs42NmzZ5/RjjZ8B5AgWH8mhBBCCCHEEaEF9957r9x5552yYMECFRML5s2bJ2+88YY89NBD6u+pU6dKkyZNrO8tcR358+ePdxeIR6AuEatISkqKdxeIR6AuxZ98OXmIUv7www9l3LhxvvCB2rVrKwP3pptuUn9jUobOYuB0oqnnSwghXmXLli3x7gKxgQoVKsR8n9Qlb1IhhroUjW0WtUcW9OjRQy2hKFSoUF42SzwGnpGysrJUVgsGwhMzUJeIlbp09OhR5WihLhEzUJecQZ4MWYDQgmXLlqnP9evXV/llCQk8yffs2aNStfEkJ2agLhGrH4pSUlKoS8QU1CWXGrI7d+5UGQp+/vlnKVGihGrLzMxU+WQ/+eQTycjIsKOfhBBCCCGEmMtagFjYgwcPytKlS2Xv3r1qWbJkiYpn6N+/f7SbI4QQQgghJDYe2SlTpsiPP/4odevW9bXVq1dPxo8fL506dcpbL4hnYbw0sQrqErECvAJGBgy+CiZmoS651JBFjthgaXDQhu8IMdahLlOmTLy7QTwAdYlYBYwOHRZHiBmoSy4NLbj44otlwIABsnXrVr9UG4MGDZL27dtb3T/i8kB4xE+zDjUxC3WJWAV06NChQ9QlYhrqkksNWeSPRTzs2WefLdWrV1dL1apVVdtLL71kTy+JK6HxQayCukSsAjp0+PBh6hIxDXXJpaEFlSpVkj///FPFyS5fvly1IV62Q4cOdvSPEEIIIYQQ6/LIIi6kY8eOaiGEEEIIIcSxhuyLL74Y8QaZgosYQSUmQqyAukSsQJdP50xzYhbqkjPIlxNBcAdiYCPaWL58snbtWnET0dTzJYQQr4JJu8R7VKhQIeb7pC55kwox1KVobLOIPLLr1q2zqm8kgUA6NhTMSE9PV+mTCMkr1CVidVlRePjpSSNmoC45A94RiK3gJCfECqhLxCrj4+jRo5xpTkxDXXKRIfvMM8+oFBORMHfuXJk0aZLZfhFCCCGEEGLekP3nn3+kSpUqcvfdd8vkyZNl165dvu9OnDghixYtkpdffllatWol119/vRQtWjSSzRJCCCGEEJJnIoqRfe+99+Tvv/9WxRBuuukmFYSblJQkKSkpPk9t06ZNpW/fvtKrVy81i48QXb6PsUPELNQlYhXQocKFC1OXiGmoSy7KWhA46QIe2A0bNsiRI0ekVKlS0qRJE/W/G2HWAkII4Uxzr8KsBcQqXJ21wAhmDMNwxUJIbg89CEPJyMjgTHNiCuoSsQr4bnBzxE2SnjRiBuqSM+AdgdgKvPaEWAF1iVhlfBw/fpwzzYlpqEvOgIYsIYQQQghxJTRkCSGEEEKIK6EhS2wDMUMlS5Zk7BAxDXWJWAV0iJWYiBVQlzxiyGJm2ddffy3Lli2zpkfEM+DkRk5hnuTELNQlYhXQoUKFClGXiGmoSy41ZLt3767yyerJF82bN1dtjRo1kokTJ9rRR+LimeZIw4L/Cenfv7+cffbZ6qK/cOFCX/uqVatUMZVatWrJueeeK0uXLg36m2nTpvnpUqdOndR1BxlULrjgAvnrr7/O2Ofbb7+tfouHbUIAdGjv3r28LhHTUJdcasj++uuv6qYBvvrqKzVbLzMzU1588UV58skn7egjcTGY0UkIuPbaa2XmzJmqSqCRfv36yR133CErV66UoUOHqqIqwX6DKoJGPvvsM5XTGkbx4MGD/X4H1q9fL6+//rq0aNHCZsmI2zh58mS8u0A8AnXJhYYscqalp6erz1OmTJFrrrlGVba47LLLlGeFEEKCceGFF0rFihX92nbu3Cnz58+Xm2++Wf2N68mmTZtk9erVIX+jQaUv43XJ+HoPHhJUGnzppZdUBUJCCCHeJOqCCJUqVZLff/9dGbMwZD/55BPVvm/fPpamJYREBYzWcuXKSXLy/y5FMEYrV64sGzdulBo1auT6+549e8qMGTPU5x9++MHXPnbsWGndurWcc845NvaeEEKI6wzZgQMHSo8ePdRMPbzua9eunS/koGHDhnb0kbgUGCVlypRhIDyxBDw8B+rSe++9p/5/9913VVgCjNklS5aoeH1ckwgJBDrESkzECqhLLjVk7777bjnvvPOUJ6Vjx46+cpHVqlVjjCwJOqOTkHBveLZt26biX+GVRcw9vLHwygaCNz6hbhi33nqr3HnnnbJnzx757bffVHxszZo11Xfbt29XMbjYz1133WW7TMTZQIcKFCgQ724QD0BdcnH6LWQquPrqq5VXVoMYWbzKI8QYp7hhwwbO6CQhKV26tDRr1kw++OAD9Tc8qYiJDRZWsHXrVp8uYYIp/tYgKwHyzMJrC2MVRiuMWSyY7PXaa6/RiCUK6NDu3bt5XSKmoS65yCOLGcGRgti0WIGbVNWqVVXaHaTgIc6DNaiJMTvBpEmTlIf0kksuUXlhMalrwoQJKuPAU089JcWKFVMps4L9BvGwmOCF32By13XXXadSAOKtUEZGhnz//fd8xUcigtclYhXUJZcYsoH5Gf/880/1KrB27drqb6TNSUpKinpiBWLY/vOf/8iCBQuUBwXpvLp27eqnIMOHD1cpdOCBgcf3lVde8b0yJIS4BxiswcB1BBNIw/0GHg9jyAHi8//444+I9vvzzz/nuc+EEEI8EFqAWcF6ueKKK6Rt27ayefNmZdBiQbzsRRddpMILouHQoUPSuHFjGT9+fNDvR40apfLTvvrqqzJ37lwpUqSI8uQcPXo0qv0QQgghhBDvkS8nSr94hQoVVIWd+vXr+7VjpjAq7Rjj1qLqSL58fh5ZdKt8+fJy3333yZAhQ1QbXidiFvw777wjN9xwwxmhBUhMfPvtt8vs2bNVH4NNGAlWYhezDrFtvNYk1oExREGE/Pnz85UvMQV1yX5QhS9RdAn3CrxFTARdwj071lCXvEmFGOpSNLZZcl42vmvXrjPa0Xbw4EGxinXr1qm4uA4dOvjaINT555+vXkPCkDVy7NgxufHGG5Vxi1nLiJkLBtbDYpRHv7o0Bmwj7i4wgBuKisWuduwTJ0bgs4WV7bGWSecHtVPWRB4nPDg6RSa9bavaA/uIdXDD8JJModox4S3WuofPdsrkxXFyg0x6XGMpE37LcfKeTKdOj2ss7rnRTKCL2pBFtoLevXvLmDFjVBougNf+999/v3Tr1k2sAkYsgAfWCP7W32mysrJUWAMMVIQ/wOANxdNPPy0jRow4ox3hEZh8ApCNoVSpUqqGMratwUQTLDDaMclEg9nS+C3ifI0lWdFXpJ/Cto3KAE8zDDzE/BmBBxmxx0avNgYV8YAIp9ixY4evHZ4pPB2hf0g5pMH+sF88xSCuWBMPmfRJgO+MY+ZmmZw2TugHtoVtGEsl4hxAWhhsxyhTWlqauhAZ+6KPDS4cKGxilAl9wbFCPzUwJpEdALIa+whZ0cfDhw+rxZg2C8cd6xrDglAREOFC2LZxPHAMAmXSng8cM6/IFG6cIGesdQ+/t1Mmp4wT+pSdna3ObzgyvCBTuHHCNmJ93YNTy0nnk13jhH3gbzx44rrsBZnCjRP6F6t7bjSO0ahDCyAUXvW/9dZbvo5hx3369FETtzBAeSEwtADhAZjchZMGlX803bt3V+t++umnvtACKBGWn376Kde8pcE8sshliUE3uq8T3dNnRTs+I5YaxxffeUEmq/tuVqZE8cjiMy6euIgG4laZnOaR1brkJQ9SsHajLunv3C5TuPZQumSnTAgtcNL5ZNc4RaJLbpMpXB/xYByrey5sMxjrlocW4CkBddH//e9/K6N1zZo1qr169ep5NmBDUbZsWfU/nvKMhiz+Dky11aVLF5WHEiEHF198cdjtou56sNrrGBxd3MHYFgw72/VA2tUeL5nslDWRx0n/1g0ymT0GeZHV6TLlRVa7+qg/x+P8i/V45CarG2UK1R6Pa4T+rVPOJytksvq8cbJMuY1rLO65ob4Lun7Ea552Q2NCF1zfMFwbNWqkFquNWABPK4zZ6dOn+9pgoSOMoWXLln7rItH5M888I1deeaX88ssvlveFEEIIIYQ4j6hjZBs0aCBr165VhqZZEGOB5ObGCV4LFy5UMRuIxxk4cKAqe4u8sdjfo48+qmIojLlmNffee6/yGF9++eUyefJkadOmjen+EXPgiQrjGM2TFSHBgA4h3oq6RMxCXSJWQV1yqSELwxIxsiNHjlQFEAK9sdGksEKYAvLPBlYQQ910pNh64IEHVK5Z1EmHFxjG6ZQpU1QQdTBg+CK2AqEGWK9Vq1bRikcsBLE1mBzAlEnECl3CuR3qFRghkUJdIlZBXXIGUU/2Mj55GAcOm8Hfxtl2boB5ZO3DWI2JT6z2kCj5GqFLmJ2bKN4P5v60D+qS/VCXvEkFr+SRRXorL8I8svZkLTA+tXpBJqv7blYm/QDpBJnszlpgnCnsBZnyMq526p7ep5dmWQdrN+qSV2QK1x6Pa0Si5JGNRJfcJlNC5JFFeVovgLK4WLQHmXlk7csji98zjyzzyFqRRxZ4RaZw48Q8svbnkQVekSncODGPrP15ZIFXZEqIPLIaCIed6QuCBlkM3IR2XzOPrD0eWbxi0nkMvSCT1X03K1Mi5ZHFOYoLYyBulSlcO/PI2uuR1bqkv3O7TOHamUfWXo9sbrrkNpncmEc2akMWFjcqeyEzQDAYI0tI7EiUWLREg3GNxCqoS8TrMbJRRycjMwBc38jnCtcwsgO8++67KkXWt99+a6bfxGPgGQmvGfLo9CfEh34dTF0iZqEuEaugLjmDqA1ZlIEdO3asNG/eXLmYER9z8803y6hRo+Tpp5+2p5fEleDkRtwUT3JiFugQnsypS8Qs1CViFdQllxqyyOtaunRp9RnxCwg1AA0bNpQ///zT+h4SQgghhBBihSFbu3ZtWbFihfrcuHFjmTBhgoqHefXVV6VcuXLRbo4QQgghhJA8EXX6rQEDBqhUCmD48OHSuXNn+fDDD1V6CFTjIsQI0ngQYgVIFUOIFVCXiFVQl1xoyCIeVoMStRs2bJDly5erHHPIL+ZWWBDBnnbMckQ/WBCBBRHMpqFBKJPXZIp2XFkQwZpx0rrkJZlCtcfjGpEoBREi0SU3ypTPywURkA4BSXshiDG5b5MmTfyS47oBFkSwXyZ8j2TLSAytvfhul8lp45RIBRH0drwiU7hxYkEEewsi4NjqHJVekCncOLEggr0FEUBGRoZnZPJ0QYSvvvpKhg4dKgsXLlQDETgBrFmzZjJ69Gi54oorxE2wIIK9BRE2b94slSpVUt95QSar+25WpkQqiICLZ7C3Pm6VKVw7CyLYWxBB65L+zu0yhWtnQQR7CyLkpktuk8mNBREi9si+8sor8sADD5xhxAI8XcDIHTdunOsMWQ0Gx+hp1m2h1rWrXQ+kXe3xkslOWRN5nPRv3SCT2WOQF1mdLlNeZLWrj/pzPM6/WI9HbrK6UaZQ7fG4RujfOuV8skImq88bJ8uU27jG4p4b6rug60e64pIlS6Rdu3Yhv7/wwgtl8eLFEe+YEEIIIYQQM0RsyOLVO+JjQoH4B2NMBiEAcTCEmAVeAcRtBfMaEBIN1CViFdQllxmyZ599tsyfPz/k9/gOQd+EaPBqAEHd0bwiICQYuFFgMgFvGMQs1CViFdQlZxCxhdGtWzd5+OGH/WYmarZv3y6PPPKIXHPNNVb3j7gYBIljBmaE8wkJCQl0CJNKqUvELNQlYhXUJWcQ8WSvBx98UL755hupWbOmyiWLCl8AOWRREAEz07EOIYGGLGYc8omVmNUlpIFBqAp1iZiBukSsgrrkMkMWucBmzZolw4YNk08//dQXDwu3Ogzbf//73748rIQQQgghhNhNVAURkG/15ZdfVoUEdu/erZ5GkAjYC08irOxlTx5ZgH6wshcre5nNI2vM3egFmfIyrnbqnt6nl/JeBms36pJXZArXHo9rRKJU9opEl9wmk+crexl3BgPWzbCyl/0y4XvkGMbvEUftBZmcNk6JVNkLY4E+oe9ekCncOLGyl72VvfQN0ysyhRsnVvayt7IX9o/feEUmT1f28iqs7EWZ3CxTolT2SjSZWNnLHePkBplY2csd4+QGmSq4vbKX1wlWSSIW1SsC0QNpV3ssZYIyIgQFT3x2yprI46R/6waZzBwDXEzhAYDXwisy5XVc7eqj/hyP8y+W42HUJa/IFK49HtcI/VunnE9WyJRXXXKbTJGMayzuuaG+C7p+xGsSkgeMrx8IySu4YeD1V4K/QCIWQF0iVkFdcgY0ZAkhhBBCiCuJKLTgxRdfjHiD/fv3N9MfQgghhBBCrDNkn3vuuYg2hlgKGrLeBqWKU1JS1IxDgLzC119/vRw7dkzuu+8+mTp1qpqt2bhxY3n//ffVTMbVq1dLr169VLwsJta98847Ur9+ffV76Mu3334rGzZskL/++kuaNGkSZwmJE8G1BbN9g8VxERIN1CViFdQlFxmy69ats78nxDWgIEagwYmqbjiZV65cqf5Hui38D0MW5Y3vuOMOZcx+8cUX6v958+ap31177bXywAMPSJs2beIkDXED0CWkrCHELNQlYhXUJZfHyGZnZ8uKFStUXjmS2KDW9Jtvvqmqu+kn07Jly6qsBUuWLJH58+er6m/gmmuuUbnj4KUFF154oUoPQ0g4MJkC+RU5qYKYhbpErIK65FJDFslx+/Tpo9zpeD2skybfe++98swzz9jRR+IwevbsKQ0bNlR6gATIa9asUSm2nnrqKWnevLlccMEFMn36dJ83v1y5cirJMYChi8Tagcm2CQkHbhRIqM0bBjELdYlYBXXJpYYsYiL//vtv+fnnn1UspKZDhw7qlTPxNr/++qssWrRI/vzzT1Xh49Zbb1VeecS41qtXT3lfMTkQcbPGSi+EEEIIIVYTdUGEr7/+WhmsLVq08AtwhncWnjm3EljbN9ErRoVqr1Spkq+0HSZq1alTR4UGYNs9evRQ62OiV9WqVZXBC28sytMhFAVeWfQJ3lh4ZQP7qPcVa5ncPE74rVNksrPCjbGmuVdkysu42ql7ep9eqkQUrN2oS16RKVx7PK4R+K2Tzie7xikSXXKbTOH6qMc1FvfcwO8sNWTxKrl06dJB4yTdNHNv/PjxatE1jRG3iZrAeal3b6aecKzqqFshE8JKUDIOxilkev3116Vu3bqq/aKLLpLJkydLgwYN1Hd4qEFZuZo1a6qJYfDSYmLXDz/8oPSnRo0aan9aJsiNrAYgljK5fZzQD6fX57ai5jhkwHbQJ/TdCzKFGyfoRqx1D7/3Wm34YOOEPuHYYh9ekSncOGEbsb7uHTx40FHnk13jpPeB33hFpnDjhP7F6p4LHYqUfDmB5nkuYHLOddddp2Ji0UF43eB9w9+rVq2SKVOmiJtAPV8oCgbdWM830T19wdrXrl2rxh4nGbaNcX/++edVSi7Ewvbt21cZo9jPI488oiZ24fPy5culd+/e6oTDMcbEMHhtsY1+/fop4xZZDrTSQ49iJZPbxwk3FafI5DVvSzxlwluOWOue1iWOk7dkCqVLdsq0ZcsWjpMHZapQoULM7rmwzWCsw/A22maWGLIzZ86USy+9VM1CRz5QGCL//POPzJ49W3755Rc555xzxI2GbCQHi0QHlBFPYvDgRlM3mUQObhiJokvwVOCpPxF0CTeMWENd8ibUpbyBEErkRn/jjTekc+fOyqAbO3asCq+EhxSeTKwDXYKnetCgQWquCPKsI4MPwi/BwoUL5fHHH/e9tR4+fLi0bt1a3EiFGOpSNLZZ1KEFyPeJgUGGAsxcnzZtmjRr1kx+//139TchRoyvEwgxg/F1GyFmoC6RcOCV90cffaRsGw3eJC5btkxl5IEhu3PnTp8uwR7Cuh9++KGyj/B2EjYRXpPjM4pKIZsP3mrecMMNyumniwoR80RtyILq1aur+EhCCCGEEC957O+//34ZOXKkPPHEE772V199VT777DNlxALM9dCvxr///nv1thpgTghiQOfMmaMmwSOeFEYsqFatmvIuzpgxQ7p06RIX+RLWkIWLN1L4ej4xXrtE8woPAeV8hUcIIcTpvPbaayofeqNGjXxtmHiE+R8owT5p0iTVhmqVl19+uS+0wDgJHtl9cJ+HAYv27777Tq644grlrYVXdvPmzXGRLaENWcQSIbYjEvjKhmigM4hxiVR3CAkFdYlYBXWJhAITkzH5eOLEiX7tMFSxYHY/vK8IPejatat6O41Z/OF46623VMzsuHHjpFatWnLuuecq5w6JsSELN7hm/fr18uCDD0qvXr2kZcuWqg2xIO+++648/fTTFnaNuB3cKPRrGELMQF0iVkFdIqH4448/lLdUhwIgndTQoUPVpC+kzOrWrZvP4wqvLYpD3XTTTcowRcys9srC0NVv6FAoCLGzmnbt2knt2rXjIl9CG7Jt27b1fUbMCGbu3Xjjjb62K6+8Uk30gkselZ4I0aEFiA/C7M5ECC0g9kFdIlZBXSLhyq9j0SD3OSZrIWvBkiVLVEVT2DhI14kwAWRtQsjBZZddJu+//74yeNGOdJI6awHy6yJmFsCgRR5Zt2YtcCpRn8XwvuJJJBC04Wkm1k/WSIVBnEuU2d0ICQl1iVgFdYlEy7Bhw5Qh2759e2Xg3n333WpiF3QJ3y1YsEBldRo8eLAqAISiAtp4hYcX3/34448qnRfDWuKctQAudWQsGDVqlF87BkeXL7UK5F4bMWKEXxtc8ohjIYQQQgixiy+++ML3Gcn53377bb/vddaCjIwMla4rGDBssRAHGbLIh4aKTShHev7556s2eGJRjSkwQNoKkL4CTzEa5GUjhBBCCCEk6tAC5D6D0YpUEogzwoLPK1eutCUvGgzXsmXL+pZwMwRRMQNVpFA2l8QfvD7BUyxfoxCzUJeIVVCXiFVQl5xBntybqN381FNPSSyA0Vy+fHkpWLCgypKAzAiVK1f2WwcxKv3791dpMX777TepUaNGyO0dO3ZMLYE5cvGKwFj31856wuhvItV9BmZkdaJMwfoOzI6fbjerS06qz+20cXKDTHZeI0K1631ynLwlUzyuEfgtx8l7Mp06Pa522UbG9sDvLDdkkQBYl2vTr/9vu+02lZvPShC68M4776i42G3btql4WQRNY/Zg0aJF1TrI7XbzzTfLX3/9pSpr5JaUHoZwYNytTpeht5mamqo8v/A2Z2Vl+eXTxYKUHEeOHPG1lyxZUv0WfTSWZMVMRZShw7YDlQTKsGfPHr8+YDsYPMyINK6LvmC7qDmsQboPzLpFXjtjHxFgjj4ePnxYLRo8CKCPWBe/0WAGJdKKYNvGvuMYoO8Ya2NuYIwxUtfg2BhlwlNpoEz6e/TH2Hc3yxRunBAjjn5glqqx79BJ9NG4HfQD+oE+oj/GPkaje9B/O2VyyjhBBnzGMfOKTOHGCXLibdTGjRv9ZMJDPMZ869atfjJVqVLFtO7h9046n+waJ/QpOztbOUjgyPCCTOHGCduI5v6E42JW91BAwEnnk13jhH3gbzj3cF32gkzhxgn9s9M2MuoedChS8uUEcyuFYf78+XLJJZeoTpx33nmqbd68earz06ZN86tNbDUYYJw0SP/Vp08fNThQoJSUFFUOLrfExKE8sjBAMOjGqmR2PnXgQpAIT4f6ZMKJgu+8IFO4vkOPrPKWmdUlJz3FWzFOOmVSsHPcrTKFa8d1zS6ZQrVrXXLK+WTXOBl1SX/ndpnCtYfSJTtlQlUrJ51PdozTyVOnZM62bbJu1y6pXqaMnF+2rJxluM+5Uabc+ogH41h5ZGGbwViH4Z1bxdioPbKDBg1SeWORuUBPvMJTGnKtDRw4UH799VexC1j8qIyxevVqX1vHjh3l448/VqXjevTokes2YPRiCQSDE5hTMFSOQbPt2qgLtr4eSKe0W3EMsF0nyWqVTE7oYzhdirbd6bqXF1mdLpOTrhH6sxfPp2hldaNModrjcY3Qv3XK+WSFTMb2yevXy/A5c2TboUO+9nJFisiIFi2kS9WqrpQpXxTjapdtZGwP9V3Q9SVK4JFFpQtj9gB8fuCBB9R3dgJX9po1a9SELg2MaqS9gCH9ySef2Lp/QgghhCQuP6xbJ/2mT/czYsH2Q4dUO74nsSVqQxYu3sDYmcAYU6sYMmSI/PLLL6os7uzZs+Xqq69WMR3GqmIA7aiq0bt3b7+8byS+4IkKMTLRPFkREgzqErEK6hKJhhOnTsnqzEyZtG6djFmwQPr//LMEi8fUbY/PmaPCDkjsiDq04Prrr1fxqaNHj5ZWrVqptlmzZsn9999/hoFpFtQ8xjYRzIyEw6iMgVhYfA4ElTYQV3HLLbeoC5SuiUziB2JrMCahXlsQEinUJWIV1CUSDBifGw4elBX79snK0ws+r92/X7IjNExhzG49dEjmbt8urcqXt73PJI+GLAxYnPyoR4zYWD3D7a677pJnnnlGrCS3UIHAoOXu3burhTgDjA8me8H7wRsGMQN1iVgFdSmxOZWTIxsPHvQzVldmZiqv6zFDtgAz7DTM3CcONGSRBuKFF15QaawQrwqqV6+uUkoQQgghhDjBYN2clfX/xurpZVVmphy1yGANRelChWzdPvEnz/VeYbg2bNgwrz8nhBBCCDHtYcfrfL+QgMxMWbVvnxw+/dbYCjIKFZKaJUrIwl27Qm433+nsBUjFRRxoyKLgQSS89dZbZvpDPAZf3RGroC4Rq6AuudNg3Xb4sH9IwGkPa5Yh2b5ZShYsKLXS0tRSGyk/8X9amqQVLOiXtUD1yfA7rVGPt2ghSZxI6ExDFhW2UIygadOmZ8SmEhIMTLqLpEgFIblBXSJWQV1yNrAvEGMaGBKAONYD2dmW7SctJcVnpCrDtUQJ9blkLmEByBM7oX37oHlkHw+SR5Y4yJDFZC4UHli3bp1Kc4WysKjYREi4CxLK0mEyID0gxAzUJWIV1CXnjMNuGKyZmWeEBew3VN80S/ECBXweVm2s4jNCBfI6/jBWL6lSRWUn2HrwoJQvWlSFE9AT63BDdvz48ao07JdffqnCB4YNGyaXXXaZSsXVqVMnXhBI0AsVystxdjAxC3WJWAV1KfbsPXrUz1hdfvr/fRYarEXz5///kIDTRis+lylc2JZxhtHaomxZ2ZM/P/MSu2myF0q7Iq8rlg0bNqhwg7vvvlul4Vq6dKmkpqba11NCCCEkCDfddJPs3LlTGRO4Dz3xxBPSoEGDoO316tVTv0FJ8127dp3xGyOffvqp3HffffLGG29I586d4ySde9h75Igs3blTZq1a5We47j561LJ9FMmfX0260sZq7fR0ZbCWs8lgJR7OWoCTH0qDp9uTNqeyIIQQQkLxyiuvSPHixdXnyZMny6BBg+S///1v0PapU6eqv19++WVJS0s74zfGapUof96sWbO4yORk9h89Kkt37VJG65KdO//3edcu2Z6VZdk+CiUn+7yqxslXFVJTabCSvBuyx44d84UWzJw5Uy6//HIZN26celKlW50EAyWFCbEC6hIJhTZWwcGDB32GTqh26FKo7wAqf6Fa5ciRI5WnNlE5cOyY/HPaYNXGKj5vOXjQsn2kJCUpD6sOCdAxrBVTU+UsFxisvC65yJBFCAEqbVWqVEml4sLELy/N/MSFC4sGhrnxb6BLGppthxc7WDv2ie8Cs0JE0673aVW7WVkxIVCXhPSKTKH6DsyOn243q0tWyeSkcYL3zGsyxeMaEapd79Mp51O04zRw4ECZPXu2+vvdd9/1laENbDfq0oABA/y+08dgwoQJcs455/hCDfS+3Kh7kVwjsrKzZdnu3cq7CsP1n927lcG66cABsdJgrV68uG/Slfa2VkpNleSkpDP7js+n++lk3dO65PT701kW6B72ZadtZGwP/C4c+XIizKWFzleuXFml3wrn1ofH1g1g8hoWhEWsXLlSFi1aJEWLFlXfIV4KRvru3bsly/CqpESJEmrZsWOHHDGUoEOgN367ZcsWNRtWU6ZMGSlUqJCKJw5UEhzPPXv2+PUJ28HgoXyicV30JTs7W01QMD4FwkhEP4x9xExc9PHQoUNy+PBhX3vBggVVH+F5OGqIV0JhiyJFikhmZqZf33EM0Pe9e/f6hY7Ai4Hqbjg2gSdzoEz4HtvG+ti+F2QKN06NGzdWfYd+GPteoUIF1UfjdtAP6Af6aDw20eoe4tPtlMkp4wQZ9HbQdy/IFG6cEMeZnJwsGzdu9JMJ12CM+datW/1kQmpEs7oHOZx0PuV1nOBwmTZtmnpbaBynzz77TLW/9NJL6tiiP9g2ZPr222/Vd5j3gev14MGDVVwsttu3b1+5/fbb1RtIN55PqLyp708HjhyR1fv3q0wBW7OzVRzr39u2qQpYVpH/rLOkSmqq1C9VSqqmpkqllBSpXqyYVChcWAqlpLjiWh7pOOl9ZGRkKHm8IFM43atYsaKttlH58uV91z0ct0aNGqn+FitWTCwxZHv16hXWgNW8/fbb4iYOHDigFAWDbjxYdj514Cbk9Kd4K2TVJxNOlEDdcatM4fqOtxVWecvM6pKTnuKtGCd8xgU+2Fsgt8oUrh03jFh7ZLUuOeV8MjNONWvWlD/++MN37TG2z5kzR32GLunvAL6bN2+efP/99/Lcc8+pyc0AE8JgZGDSF9JOxkumaNqPHD/+P4N13z7ZdvLk/8IDdu2Sdfv2+SXxN0PyWWdJrfR0qV+6tNTLyJB6pUpJ/YwMqZGeLju3b3fU+WTXOBmvS0ZdcrNM4fqIB+NYeWRhm+mHzdwM2agKIngZDE5gnG+ouF+z7dqoC7a+HkintFtxDLBdJ8lqlUxO6GM4XYq23em6lxdZnS6Tk64R+rPbzifc6OAFKlu2rGrDZC7cAOFtgocosB3GLTxB8GzDA4TvpkyZor7D0rNnT7Vorr32WuWVDZe1IF66l33qlKzJzFQeVmMBgQ0HD8opiwoXJeXLJzVLllRGqlpKl1b/o61AiPhQfTyccj6Fa4/XeeNkmUK1633ZZRsZ26OZd5XnrAWEEEJIvMEryH79+qnXt7j54XUm4l3x6jNYO27M+M29994b9Dsnkn3ypKw97WFFwQCd1mr9gQNy0iKDFROrqqel+QzVBqf/r1WypKQk01QgzoXaSWwDNwVWzyFWQF0ioUAYxqRJk4J+F6wdr0oRU4wQgkj06YsvvpBYcfzUKVm/f7+fsQov67r9++WERQYrJK5mMFi1l7VOqVJSkAZrVPC65AyotcQ2cHIjAJwQs1CXiJd06cSpU7LhwIH/hQIYwgLgdYUxaxXICNCoXDmfd1UbrIXz57dsH4mME3SJ0JAlNgLPB2Y8YpYmn1iJGahLxI26dPLUKdl48KCfsaoN1mMWFhJCkQCdzkrnYUVuVlTBwgQdYg+8LrnIkEVlk+nTp6tAeCSHHjJkiBo4QiI5yZFmgyc5MQN1iThZlzCxahMM1oAY1lWZmZYarGULF1YlWWsbK16VKCGpBQpYtg8SObwuuciQXbZsmconBkN2xIgRcuedd9KQJYQQknCGy5asLGWsrti71+dphcF65MQJy/ZTpnBhv/KstU97WIufTglGCInSkG3SpIn07t1b2rRpo07k0aNHq7x6wXjsscci2SQhhBASU/Cqf862bbJm506pnp0tLcqVk6QgaX5wn9t26JAvnRUM1hWnDdZDhsTuZskoVMjnVdUhAVhK0GAlxFpDFjlkhw8f7pvlOXnyZFV9IRB8R0OWGPUB1U34yoWYhbpEzPLDunUyfM4cZaBqyhUpIoOaNpWKqam++FUYrav27ZODFhqs6QULnmGs4jPaiXvhdclFhmzt2rVV2T+AnHuIly1durTdfSMuBye3LvtLiBmoS8SsEdtv+vQzqlrBqH1g5kzL9gNPqjJWA8ICShUqZNk+iHPgdcmlWQsCS4oREgq8nkNScoSh8ImVmIG6RMyEEzwye7ZlpVlBsQIF/LIEaE8rQgWon4kDr0suTr+1Zs0aef7559UkMFCvXj0ZMGCAVK9e3er+EZef5KicU6RIEZ7kxBTUJZIXFu/eLU/+8YfsPHIkT79PzZ8/aAwrsgdQDwmvSy41ZFGv+sorr1QTwFq3bq3aZs2aJfXr15fvvvtOOnbsaEc/CSGEkIhSYc3YtEkmLF4ss7dti/h3VYoWVZO/jJ5WxNDSQCHEY4bsgw8+KIMGDZJnnnnmjPahQ4fSkCWEEBJzjp44IV+uXi2vL1misgtEy38uuEBalS9vS98IIQ4yZBFO8Nlnn53Rftttt6lwA0I08GSw4gmxAuoSCcXeo0fl3X/+Ucvuo0ej/j00Cp7X88uWtaV/xLvwuuRSQzYjI0MWLlwoNWvW9GtHGzMZECM4uRE7RIhZqEskkDWZmcr7+vmqVWGrZ2ECVuty5eSbtWvV38ZJX9r8eLxFi6D5ZAkJB69LLjVkb7/9drnjjjtk7dq10qpVK1+M7LPPPiuDBw+2o4/ExYHw+/fvl+LFi/OJlZiCukS0Hszdvl1eW7xY/rtxY9hMBIhxvaNhQ+lavbqkJCVJl6pVg+aRhRGL7wiJFl6XXGrIPvrooypv2pgxY2TYsGGqrXz58vL4449L//797egjcfFJfvz4cfU/T3JiBupSYnPi1CmVC3bCkiXy965dYde9oHx56deokbStUMFPV2CsXlKlyv9X9ipdOmRlL0IigdcllxqyGCxM9sJy8OBB1caEwIQQQqwmKztbPl6xQt5culQ2Z2WFXC85Xz7pWqOG3NGggdQrWTLkejBaWyIzQYECUrJkSVXghxCSgHlkNV4yYFHowVjsARe4wOIPMOKxmG3XT2+B7dgnvsOS13a9T6vazciqP2O7ZmR1kkzh+q5lNTN+ut2sLlklk1PGCZ/1Ol6RKV7XiFDtep9OOJ+2ZmXJ28uWyUfLl4ctFYvCBD1q15be9etL+dTUM641wfpu1KVYXyPioXvxuEbgt046n+wap0h0yW0yheujHle7bCNjezTFt0wZsm5m/Pjxajl5epLApk2bfIY5qnSUKlVK9u7dq6p2aEqUKKGWXbt2yRFDgm082eO327ZtU68ZNGXKlJFChQqpbQcqCZRhz549fn3CdjB4+/bt81sXfcF2EYujSUpKkvT0dJWM2djH/Pnzqz4ePnxYLRrUg0YfsS5+o8GMSwSrY9vGvuMYoO+ZmZm+YwQQC1SgQAF1bIwypaWlnSETvse2IRO24wWZwo1TpUqVVD927Njh1/cKFSqoPhq3g35AP9BH47GJVvdOnDhhq0xOGSfIoGuao+9ekCncOEE3kpOTZePGjX4yVa5cWY351q1b/WSqUqWKad3D7+N9Pi3PzJT316yRaVu2yIkgD4qaiqmpcuPZZ0vXKlWkcHKy5D9xQrVHMk7oE44tjlusrxHx0D1sI5r7E0IFzeoe3tY66Xyya5z0PvAbr8gUbpzQPzttI6Pu6Tf+kZAvJ5hbKYE4cOCAUhQMerFixXztdj514ELg9Kd4NzwdOk0mGLJWecvM6hLHyd0yVaxY0TaZQrVrXYr1OEm+fBEXMGiakSH9GjZUsa5JhphE6l7o9lC6ZKdMW7ZscdT55IZxcoNMFSpUiJlHFrYZjHUY3kbbLBgJ65ENBIMTGC8VKn7KbDsGKtT6eiCd0m5GVigjntzwpOYkWa0YV6f0MZwuRdvuZN3THoZQuuRGmZx2jdCfY3U+RVrAAHuE4QoDtnmZMkH7kFsfje2BuuTWa0S04xpLmfRvnXI+WSFTXnXJbTJFMq522UbG9mji16MyZOEa7ty5s7z66qtn5JElJBjGVySEmIG6lFgFDAomJcn1tWpJnwYNpFrx4pb2gbpErIK6FH+iMmQRN7Fo0SL7ekMIIcSTrN2/X15fvFgVMDiaSwGD3vXqyS1160pawYIx7SMhxH1EHVpw8803y5tvvinPPPOMPT0ihBDiCRBf98eOHaqAwbQNG8IWMKhVooQqYHB1jRqqgAEhhNhiyGLW4ltvvSU//vijnHPOOWeUZxs7dmy0myQeBbE1rHhCrIC65N0CBm1QwKBhQ2l3elKS3VCXiFVQl1xqyC5ZskSaNWumPq9cudLvOw4mCdQHpA0hxCzUJfcUMPhk5Up5Y8mSXAsYXFW9uvLA1g9TwMAOqEvEKqhLLjVkZ8yYYU9PiOfQWQuQp44VdIgZqEvOZuuhQ/LWkiXy0YoVciA7O2wBg5vr1FEFDMoFvM2LFdQlYhXUJWeQ5/Rbq1evljVr1siFF16oEtsiFooeWRJIgqcpJhZCXXIeS/fsUflfv12zJmwBg0qpqSr7wA21akmqAzxY1CViFdQlFxqyqCLRvXt35ZmF4bpq1SqpVq2a9OnTRyWvHTNmjD09JYQQEndO5eTIjM2b1QSuWYYqT8FokpEhdzZsKJ3PPluS6bEihDjBkB00aJBKw4USYnXr1vW1X3/99TJ48GAasoQQ4kFQwOCrNWuUAZtbAYNOpwsYnJtLAQNCCIm5ITtt2jSZOnWqKntnBAUSNmzYYLpDxDvgBgYvPW9kxCzUpfgWMHhv2TJ5Z+nSuBUwsBLqErEK6pJLDdlDhw5J4cKFz2hHwHNKSopV/SIeACd3qLJ9hEQDdSk+BQyQfeCzlStzLWDQq1496emSAgbUJWIV1CWXGrIXXHCBvPfeezJy5Ej1NwYQM/dGjRolF110kR19JC4FeoGY6pIlS3JGJzEFdcm5BQy6Vq8uBZPzPG845lCXiFVQl5xB1FcfGKzt27eX+fPnS3Z2tjzwwAOydOlS5ZGdNWuWPb0khBBiawGD79aulVcXL46ogAEM2ItiVMCAEEIsNWQbNGigCiGMGzdOihYtKllZWdKtWze55557pFy5ctFujhBCSJw4eOyYvPnXX/L8nDmyYf9+RxYwIISQcOTpfRBKsj388MN5+SkhhJA4s/nAAXlp7lyZsGCB7D92LGwBgx6nCxiUj1MBA0IIsdyQ3bdvn7z55puybNky9Xe9evWkd+/eqroFIRrEDDF2iFgBdckaFm7fLmN+/10+WbJEhROEomJqqvR1UAEDK6EuEaugLrnUkP3111/liiuuUF7Z5s2bq7YXX3xRnnjiCfnuu+9UpS9C9MQRBMMjjo6xdMQM1CVzx27K6tUy+vff5ad163ItYID8r5d6uIABdYlYBXXJpYYsYmFR/OCVV16RpKQk1Xby5Em5++671XeLFy+2o5/EpSc5vPd4YuVJTsxAXcpbAYMPFy2SsXPmyD9hJnDhaF5Vp470rFEjIQoYUJeIVVCXXGrIrl69Wr744gufEQvwGVW9kJaLEEJI/Nhz+LC8Mn++jPvjD9lx6FDI9QolJ0uvJk1kUIsWUrNkSdmyZUtM+0kIIXExZJs1a6ZiY2vXru3XjrbGjRtb0ilCCCHRsWrPHnluzhx5Z+FCOXLiRMj1ShcpIv8691y569xzpVSQ4jaEEOI5Q3bRokW+z/3795cBAwYoz2yLFi1U25w5c2T8+PHyzDPP2NdT4kr4uoVYBXUp+KvNWZs2qQlc3yxfHraAQb2MDBncooX0aNTIVQUM7IC6RKyCuhR/8uXgSpgLugRbbqtiHcTLuokDBw6oiWv79++XYsWKxWSffIXnTSpUqBDzfVKXElOXkHHgy2XLlAH7Ry460L5qVbmvZUu5pEYNOSvMTZe65E14XSJu1KVobLOIHsvX5TLTlZBg4MHn+PHjkj9/fj61ElNQl/6/gMFbKGAwd66sz8wMuR4yDtzQoIEyYJuULRvTPjod6hKxCuqSM4jIkK1SpYr9PSGePMnxNMUZncQsia5LWw4ckBcjKGBQPCVF7jjnHOl//vlSMUZvmNxGousSsQ7qkjPIU6DU1q1bZebMmbJz506VQ80IYmgJIYSY5+/TBQw+zqWAQZXixWVgixbSp2lTKZqSEtM+EkKIqwzZd955R/r16ycFChQ44ykEn2nIEkKIBQUMZs+W6bmEdZ1bvrwMadVKutWt69kCBoQQYqkh++ijj8pjjz0mw4YNY1k2kivGfMOEmMHrunTs5En5avVqeX3JElmxb1/I9eA6uLJ2bRX/2qZyZb7SzANe1yUSO6hLLjRkDx8+LDfccIPnjFiESBjDJCBfYNiELkNnth0el2Dt2Ce+C8wOEU273qdV7WZlTU9P95Xx84pMofoOzI6fbjerS1bJ5KRxSktL85xMaMs8dkze/ecfeXfZMtl15IiEAimzejVurEIIaqanqza9Hytk1brklPPJznHSuuQlmUK1x+Magd+6+VoeTXtuuuRGmfKF6KMeV7tsI2N74HeWGrJ9+vSRzz//XB588EFxM8h7i0WnC9u0aZMULVpUfU5NTZVSpUrJ3r17JSsry/ebEiVKqGXXrl1yxHDDQYgFfrtt2zY1g1FTpkwZKVSokNp2oJJAGfbs2ePXJ2wHg4eSd8Z10RdsF0HlxqdAGIlHjx716yNmT6KPeODAoilYsKDqI9bFbzSFCxeWIkWKqG0b+45jgL5nZmb6pVRDOgyEleDYBJ7MgTLhe2wb62M7XpAp3DhVqlRJ9WPHjh1+fUfKEvTRuB30A/qBPhqPTbS6d+LECVtlcso4QQa9Ha/ItDErSz7fvFm+WL1ajoZJW1iyYEHpWaeO3Fy7tjSpVUuN+caNG/1kwoRcs7qH3zvpfLJrnNCn5ORk1R+vyBRunLCNaO5P5cuXV8fHqGOgcuXKSvcwRyY33Tt48KCrr+WRjpPeR0ZGhmdkCjdO6J+dtpFR96BDluaRNYIDfPnll6vONmzYUAlsZOzYseImdK4yDLoxV5mdTx24EDj9Kd4KWfXJhBMF33lBpnB9hyFrdvx0u1ldctJTvBXjhM+4eOIiGoibZML1c/7OnfLa4sUybePGsAUM6pYqpcrH9mjY0FfAwAqZQrVrXXLK+WTXOBl1SX/ndpnCtVesWDHmMiGPrJuv5ZG2R6JLbpMpXB/xYBwrjyxsM/2waUkeWSNPP/20TJ061Vei1migBBorbgKDExguESp8wmy7Pk7B1tcD6ZR2K44BtuskWa2SyQl9DKdL0bY7XffyIqtTZELGgSnr1smExYvlr127JByty5eXh9q1k84hChjY1Uf92YvnU7SyulGmUO3xuEbo3zrlOmmFTFafN06WKbdxtcs2MrZHE74atSE7ZswYeeutt6RXr17R/pQQQhKKrOxs+WTlSnlzyRLZZHgVF0hyvnxyZfXqckeDBtKgVKm4VGMihBA3ErUhm5KSIq1bt7anN8RT4EmOFU9IIurStkOH5O2lS+WD5cvlQHZ2yPWK5s8vPerUkdsaNJDyRYrEtI+Jitt0iTgX6pJLDdkBAwbISy+9JC+++KI9PSKeASc3AsAJSRRd+mfPHhU+8M2aNXIizPSDiqmp0rdBA7mhVi1JLVAgpn1MdNyiS8T5UJdcasj+8ccf8tNPP8n3338v9evXP2Oy15dffmll/4iLQZA4ZjxiliafWIlXdQl9+3nzZjWB6zfDjO5gNM7IkH4NGkiXqlVZwCBOOFmXiLugLrnUkMXTR7du3ezpDfHkSY40GzzJidd0KZoCBp2qVJE7GjaU88qUcUz/ExUn6hJxJ9Qllxqyb7/9tj09IYQQF7Dv6FF5f9kyeeeff2RnmAIGKUlJ0r1mTbm9YUOpVrx4TPtICCGJAt9tEUJiDkpdt2jRQuW4XLp06Rnff/rpp+q7KVOm+NqQr/GWW26RNm3aSPv27WXOnDm+7wYPHiwXXHCBdOzYUbp27SoLFy60vM/r9u+Xh2fNknM//lhGLVgQ0ogtVbCgDDnnHJl3443ydJs2NGIJIcRJHtmqVauGdaGvXbvWbJ+IR4CeoLoJX7mQQC677DK56667goYpodrLRx99JM2aNfO1QYdQiQ9tH374oTJU+/btK7///ruK0+/cubOMGjVKVYX58ccf5c477/QzdM28Opy/Y4eawDV1w4awBQxqlightzdoIN1q1PAVMCDOg9clYhXUJWcQ9dV24MCBfn+j7Nhff/2lPCf333+/lX0jLgcnty77S4gReGODgYouuI6MHDlSnnjiCT9dwjVm5syZ6u8mTZqoMocwVuGJ7dSpk29dGLvbt29X5TRh2OYFVcBg/fqIChi0KldO+jVqJBdVrBi0gAFxFrwuEaugLrk4/VYw4C2ZP3++FX0iHgHeLNRjRg1pPrGSSHjttdekefPm0qhRI792hBXgoRk1zY0lgVEKM5A333xTLr744jwZsYeOH5dPVqyQN5culY1han2jgMEV1aqpCVwNg5TNJc6F1yViFdQlZ2DZ+69LL71Uhg0bxslgxO8kP3r0qBQpUoQnOcmV5cuXyw8//CATJ0484ztd7xv/h9Ml/Pa7774Luo1IChh8uHy57I+kgEH9+lI+NTWqfRBnwOsSsQrqkscM2S+++ELS09Ot2hwhJMFAjurNmzerUAGwa9cuGTp0qOzcuVNuvvlmSUpKUp/Lli3ri6U1lnL99ttv5bnnnlMTxYye29wKGLy2ZIkqYHD81KmQ61VAAYP69eWG2rWlKAsYEEKIew3Zpk2b+j154IkE8Wi46bz88stW948QkiD07NlTLZprr71WTejCRC7EziIjwQcffCBDhgxRk71w3dGxtvDCYrLXJ5984mfcmi5gUKqU9GvYkAUMCCHEK4YsUtsYOeuss5T3o127dlKnTh0r+0ZcDh54WPGEBAOe1unTp6sH4B49eqhXc7NmzQq5PnTowQcfVAvSbxUoUECVydaVBe+99151Hbrtttt8v4FnNi0tza+Awddr1igDNrcCBh0rV1bxr+eXLUv99Ri8LhGroC45g3w5OvgsQTlw4IAUL15c9u/fL8WKFYvJPoNNUCHuJzdPoB1QlyIrYPDB8uUqBja3AgbXoYBBgwZSPc7106lLxCqoS8SNuhSNbcZkh8Q28IwEJYQy8omVxFqX1h84oMrHfrZypRw5cSLkeiULFpRe9epJz7p1pWShQhb2mjgRXpeIVVCXnEHEhixCCHIbKHyP3I2E6JMcKZNym2lOiJW6hAIGry5alGsBgxrFi6vwARYwSCx4XSJWQV1yBhFfvb/66quQ36G6DuLVMCGDEEJizclTp2Tyhg0q/vXPnTtzL2DQsKFcVKkSCxgQQkiiGLJXXXXVGW0rVqxQky8wYxgTNoyVeAghxG5QwODTlSvljSVLwhYwSDpdwAAGLAsYEEKId8jT+7StW7fK8OHD5d1335VLLrlEpcJp0KCB9b0jrgavWljxhFjhbZ27fbts3r9fKh4/rjIJ7DpyRN7+5x/5YNmyXAsY3FSnjvRhAQNyGl6XiFVQl1xoyCKo+amnnpKXXnpJ1TpH+hydvJyQQHByF+LkGWKCH9atk+Fz5qjKW5pCycmSffKknAyTcIUFDEgoeF0iVkFdcpkhi2Tjzz77rKqq8/HHHwcNNSDECGKmMzMzpUSJEmqyICHRGrH9pk8/Y8JWuAwEKGCACVyXsYABCQGvS8QqqEsuM2QRC4snjxo1aqiQAizB+PLLL63sH3E5J0+ejHcXiEvAzN9NWVmqbOySPXvklUWLwmYdMIICBoh/ZQEDEgm8LhGroC65yJBF6UjeIAghVgCvKqprwWj9Z+9eWbZ3r/p88PjxqLbToVIlefT88+NewIAQQojDDdl33nnH3p4QQjzpZd1++PD/jNXTRisM1rUHDsgpC4oKdq1Rg0YsIYQkMMwCTmwDHnxWPEkcMAFrdWamz1hV/+/dK3uPHrVtn6U50YJECa9LxCqoS86AhiyxDZzcBThj3JPsOXLkDIMVRuxxC4qiFE9JkbppabJ49245FGJiF24b5YoUUTGxhEQDr0vEKqhLzoCGLLF1RufevXslPT2dMzpdyolTp2Td/v0+Y1UbrjsOHza9bRijZxcrJvVKlpR66elS//T/MFBxg9BZC4AxCEH7Ph5v0UKSqFckSnhdIlZBXXIGNGSJ7TGSxB0cyM7+fw/rnj1qAtbyffvkmAWzcovkz6+8rNporVuypPq7cP78IX/TpWpVmdC+/Rl5ZGHowojF94TkBV6XiFVQl+IPDVlCEgxMskI518CMAUh9ZQUVU1N9xmr99HRlvFYuWlTOykMcGYzVS6pUkTnbtsmanTuleunS0qJcOXpiCSGEKGjIEuJhDh8/Lsv27fPLGIC/D0WZ5ioYKUlJUictTeqeNlaV8ZqermJcrQRGa8ty5aRWgQJSsmRJvsIjhBDig4YssQ3EOaalpXFGZ4xeb+H1uzGOdemePbL+wIGIiwqEo0zhwv8zWA2xrFWLF49Z9SzqErEK6hKxCuqSM6AhS2wDJze8ZzzJreXYiROydNcu+Xv7dpm1Zo1vItb+Y8dMbzs5Xz6piVjW00ar9rSWjHOaK+oSsQrqErEK6pIzoCFL8syMGTPkP//5j2RnZ6vyxc8++6zUq1dP/vrrL3nsscdU++HDh+WGG26Qe+65x++3q1atkksvvVR69OghI0aMiJsMTmdHVpb8vWOHMlrx/8Lt22X57t1y0oIJBmkpKT7vqjZYa5QoIQWSksSJs4P37NnD0AJiGuoSsQrqkjOgIUvyRGZmptx7770yceJEqV27tsydO1f9PX36dBk6dKgMGTJEOnToIGvXrpVrrrlGOnbsKLVq1VK/PX78uFqnc+fO8RbDMRw/eVJW7NnjM1i18brDMFs/r2CSVTVDmqu6p/8vW7gwPQmEEEJcDQ1Zkic2bNigYoNgxILzzz9ftmzZIosXL1bG0YEDB1T7kSNHJH/+/FLCUEb0+eefl8suu0wZw3q9RGLfkSN+XlYsS3futCTNVdH8+ZXBquNZ8bl2WpoUSuapTgghxHvw7kbyRNWqVWXfvn0yf/58ad68uUybNk2ysrJk06ZNMnbsWLnttttk1KhR6rXL008/LaVLl1a/+/PPP2XBggXy8ccfq/W8nuZq9d69Z3hZN1lkvFdLS5NaBk8r/q+UmkovKyGEkISBhizJE8WKFZMJEyYoIxVxsM2aNVOhA8nJyTJ+/Hh58MEH5eqrr5Z169ZJ9+7dpUmTJlKpUiV5+OGH1e+8ZmxlZWfL7E2b/GJZF+/cqdJfmQXe1EZlykhjLGXLqv8blikjxVJSlBc8EUD8GePQiBVQl4hVUJecAQ1Zkmdat26tFnDs2DFlzJYpU0amTJkiL7/8skoJBeMV7fPmzZOTJ08qwwuGLUBYAYLl9+/fr8IN3ABk2pyV5ZfmCssGi7ysFYsV+5/BajBaa6SnJ3wBABx36AoegLz2EERiC3WJWAV1yRnQkCV5ZseOHcpwBS+88IK0atVKGjRooDIYzJo1S1q2bKkmeyGLwR133CF169aVRYsW+X4/ZswYZcw6NWvBkRMnZOW+fX5GK6pgoZSrWZAZoH5Ghs9YxQKva8nChS3puxdvGAhlgfeDNwxiBuoSsQrqkjOgIUvyzOjRo+WPP/6QEydOyDnnnKP+TkpKkldffVWefPJJ1X706FHp06eP+t7JF6Mdhw/7vKu6Ctaa/ftVnKtZShcp4udlbVK2rNQuWVLyOzDNFSGEEOImaMiSPIMcssG44IILZPLkyX459oJx3333SazJPnlSVmdm+ryrqH6Fz3uPHjW97aR8+aROqVJ+XlZ8LpuaaknfCSGEEOIPDVliK/F83QLj1BjHis+rMjPl+KlTprddvECB/6W4MmQMuKh+fSnINFe2wVd3xCqoS8QqqEvxh3ddYhuYyVmqVCnb93Py1ClZd+CAz2jVXlaEC5gFl6izjSmuThut5YsUOeMCRiPW/bpEvA91iVgFdckZ8M5LbI09RRUvFESw6qkVE60QEmD0tK7Yu1eOWlBMoHBysl8hASx10tKkSP78lvSdOEuXSGJCXSJWQV1yBq43ZM8++2wZOHCgWojzTnKk1srLjE5Mstp08KB/mqs9e2RTVpYlfauYmupXrhVLlWLFVDlX4i1dIsQIdYlYBXXJGTjekP3111/VpCJUg9q2bZt89dVX0rVr13h3i0Twun/Otm2yZudOqZ6dLS3KlQuZCxVprpYFZAzA31kWFBNISUpSJVrhaa1/2mjF5+IpKaa3TQghhJD44nhD9tChQ9K4cWNV8rRbt27x7g6JgB/WrZPhc+bItkOHfG3lihSRES1aSJPSpZWxquNYsazbv1/MJ7kSKVO4sH9oQHq6VCteXJITvJgAIYQQ4lUcb8heeumlaomUN954Q4YMGSITJ06U9u3b29o3EtyI7Td9+hmGKYzaO6ZPt2QfyfnySY0SJZSxWt9gtJYsVMiS7RNnghzFhFgBdYlYBXUp/jjekI2GUaNGqWXatGly3nnnBV0HpVSxaFBZCiDnKRbjbETj30CXoTPbjriaYO3YJ77Dktd2vU+r2qORFXGtw3//3RLvqiYtJcXnYYW3tW5amjJiETIQ2HfdJytlimacgNnx0+1mdckqmZyke2lpaZ6TKR7XiFDtep92XiOcMk5al7wkU6j2eFwj8FsnnU92jlNuuuRGmfKF6KMeV7tsI2N74HcJYcgOHTpU3n//ffnll1+kfv36Idd7+umng5ZE3bRpkxQtWlR9Tk1NVSk19iJO0zC5qESJEmrZtWuXHDlyxNeOQG/8FjG8mMGoQflWlGvFtgOVBMqAYgFGsB0MHkreGddFX7BdBJUbnwLT09NV5SxjHzF7En08fPiwWjQFCxZUfcS6+I2mcOHCUqRIEbVtY99xDND3zMxMOWnICFC8eHEpUKCAOjaBJ/PcHTtkWx5TXuHlf+XUVGlUurTULFpUqhQqJLWLFZOMggXV/iATwkwgU1ZmpmTFSKZoxqlSpUqqHyjdaxyPChUqqD4at4N+QD/QR/TH2MdodA/V0+yUySm6Bxn0drwiU7hxgm4kJyfLxo0b/WSqXLmyGvOtW7f6yVSlShXTuoffO+l8smuc0CccW/THKzKFGydsI5r7U/ny5U3r3sGDBx11Ptk1TnofGRkZnpEp3Dihf3baRkbdgw5FSr6cYG4lh4LBCJzshawFGHQYOfPnz5dq1aqF3UYwjywMEAx6sWLFfO12PnXgQuD0p/i8yPrN2rXyrxkzJDcKJiVJo1Kl/udhPR3TiglZhZKTHSdTNOMEPbLKW2ZWl5z0FG/FOOEzLp7Bcja6VaZw7RUrVrRNplDtWpeccj7ZNU5GXdLfuV2mcO2hdMlOmbZs2eKo88mucYpEl9wmU7g+4sE4Vh5Z2Gb6YdNom3nWI4uSqJMmTZLPPvtMHnzwwbDrpqSkqCUQDA6WwLZgmG3HQIVaXw+kU9qjkbV0hDGq711yibQqXz7k906SKVS7U/oYTpeibXe67uVFVqfL5KRrhP7sxfMpWlndKFOo9nhcI/RvnXI+WSGT1eeNk2XKbVztso2M7aG+C7q+eADEw06ePFmeeuopGT16dLy7k7CcX7asyk4QKpse2lERC+sRQgghhJjF8R5ZxGGsXr3a9/e6detk4cKFKq4DMTuaVq1ayQ8//KAyHCDGggUSYg/yxCLFFrIWwGg1vsDQxu3jLVqEzCdLSCjgFWD1HGIF1CViFdQlZ+B4iwJxr02bNlULGDx4sPr82GOPnbFumzZtVIjBI488Ii+99FIceku6VK0qE9q3l7JFivi1w1OLdnxPSLTgRoHJBLxhELNQl4hVUJecgeM9su3atTsjONnI+vXr/f6+8MIL/WbTkdgDY/WSKlVk7vbtsmnfPqmUlqbCCeiJJXkF1wDMnsWMX940iBmoS8QqqEvOwPGGbKxgHllrZ1DilD4PqbTy51dhIPg78Pi6Tabc+g5inbUglC5ZJZNTxgmfkZkEKVsC++JWmeJ1jQjVrveZCFkLtC5pud0uU7j2eFwjEiWPbCS65DaZwvWReWQdxvjx49Wi87Uxj6z1Oe309/i9se9ulincODGPrL15ZPVnr8gUbpyYR9bePLLZ2dnqs1dkCjdOzCNrbx5Z3V+vyASYR9ZlIFcZFIV5ZK1/OtQnk/LIBrx2catM4frOPLL2emSZR5Z5ZEO1RzMezCNrv0zMI+temcL1kXlkHQ7zyFqf0w7bw1Mp2rwik9P6GE6Xom13su7hezzBh1rXjTI57RqhP3vxfDK2B+qSF2QK1x6Pa0Si5JGNRJfcJpMb88jSkCW2gRNAh2sQYgbqErEK6hKxCuqSM+A0cmIbeCWBOJcEj14hFkBdIlZBXSJWQV1yBjRkiW3g5EYQOU9yYhbqErEK6hKxCuqSM6AhSwghhBBCXEnCx8jqJynMkIsV0aSVcDOYeYgUHUgdEk3gtluJpQ5pqEvehLpkH9Ql+6EueZMDMdQlva9IvN0Jb8jqEw6pkwghhBBCiHNsNKRIDUfC55HFExXyJ2LmYai0PiTvT1R4QEDS49zywBESDuoSsQrqErEK6pL9E+lQJCE3b3fCe2RxgJAwmtgHTnCe5MQKqEvEKqhLxCqoS/aQmydW4/2gDkIIIYQQ4kloyBJCCCGEEFdCQ5bYRkpKigwfPlz9T4gZqEvEKqhLxCqoS84g4Sd7EUIIIYQQd0KPLCGEEEIIcSU0ZAkhhBBCiCuhIUsIIYQQQlwJDVlCCCGEEOJKaMiSkDz99NNy7rnnqqpnpUuXlq5du8qKFSv81jl69Kjcc889UrJkSUlNTZVrrrlGduzY4fv+77//lhtvvFFVPylUqJDUrVtXXnjhBb9tfPnll9KxY0fJyMhQSaVbtmwpU6dOjZmcxDu6NHPmTGndurXaBtapU6eOPPfcczGTk3hLn4zMmjVLkpOTpUmTJrbKRrypSz///LOqHhq4bN++PWayehUasiQkv/zyizp558yZI//973/l+PHj0qlTJzl06JBvnUGDBsl3330nn3/+uVof5X67devm+37BggXq4vDBBx/I0qVL5eGHH5Zhw4bJuHHjfOv8+uuvypD94Ycf1PoXXXSRXHHFFfLXX3/FXGbibl0qUqSI/Otf/1I6tWzZMnnkkUfU8tprr8VcZuJ+fdJkZmZKz549pX379jGTkXhTl2Akb9u2zbfgd8QkSL9FSCTs3LkTqdpyfvnlF/V3ZmZmTv78+XM+//xz3zrLli1T6/z+++8ht3P33XfnXHTRRWH3Va9evZwRI0ZY2HuSqLp09dVX59x8880W9p4kmj5df/31OY888kjO8OHDcxo3bmyTFMTLujRjxgz1m3379tksQeJBjyyJmP3796v/09PTfU+heHrt0KGDbx28yq1cubL8/vvvYbejtxGMU6dOycGDB8OuQ9xNrHQJXv3Zs2dL27ZtLe0/SRx9evvtt2Xt2rUq8T3xPnZfmxCaUq5cOfUWEuEqxDzJFmyDJAAwLgcOHKjiDxs0aKDaENtToEABKVGihN+6ZcqUCRn3A6Pi008/lUmTJoXc1+jRoyUrK0u6d+9usRQkUXSpYsWKsmvXLjlx4oQ8/vjj0rdvX5ukIV7Wp1WrVsmDDz4ov/32m4qPJd7GTl2C8frqq69K8+bN5dixY/LGG29Iu3btZO7cudKsWTObJfM2PDNJRCCGaMmSJWoyTV7B76+66irl2UAMUjA++ugjGTFihHzzzTeMHfIosdAlGB54GELcGwyRGjVqqMkYxHvYpU8nT56Um266SV2PatWqZWGPSSJem2rXrq0WTatWrWTNmjVqMur7779vuu8JTbxjG4jzueeee3IqVqyYs3btWr/26dOnB435qVy5cs7YsWP92pYuXZpTunTpnIceeijkfj7++OOcQoUK5Xz//fcWS0ASTZeMjBw5MqdWrVoW9J4kkj7ht9hGUlKSb8mXL5+vDfsg3iEe16YhQ4bktGjRwoLeJzY0ZElITp06pU7u8uXL56xcufKM73UQ/BdffOFrW758+RlB8EuWLFEn9/333x9yXx999FFOwYIFc77++msbJCGJpEuBYNJglSpVLJCCJJI+nTx5Mmfx4sV+y1133ZVTu3Zt9TkrK8tGCUkiXJs6dOigJqMSc9CQJSHBRbt48eI5P//8c862bdt8y+HDh33r3HnnnerJ9KeffsqZP39+TsuWLdWiwQU/IyNDzRo3bgMzQzUffvhhTnJycs748eP91sEFhHiDWOnSuHHjcr799lt1Q8Lyxhtv5BQtWjTn4YcfjrnMxP36FAizFniPWOnSc889pxw1q1atUusPGDAg56yzzsr58ccfYy6z16AhS0KCJ85gy9tvv+1b58iRIyrNSFpaWk7hwoXV0yVOYOOFP9g2jB6ytm3bBl3n1ltvjbnMxN269OKLL+bUr19f/b5YsWI5TZs2zXn55ZeVd414h1jpUyA0ZL1HrHTp2Wefzalevbp685ienp7Trl07ZRgT8+TDP/GO0yWEEEIIISRamEeWEEIIIYS4EhqyhBBCCCHEldCQJYQQQgghroSGLCGEEEIIcSU0ZAkhhBBCiCuhIUsIIYQQQlwJDVlCCCGEEOJKaMgSQgghhBBXQkOWEEIIIYS4EhqyhBDiMFBwsUOHDnLJJZec8d3LL78sJUqUkM2bN8elb4QQ4iRoyBJCiMPIly+fvP322zJ37lyZMGGCr33dunXywAMPyEsvvSQVK1a0dJ/Hjx+3dHuEEBILaMgSQogDqVSpkrzwwgsyZMgQZcDCS9unTx/p1KmTNG3aVC699FJJTU2VMmXKyC233CK7d+/2/XbKlCnSpk0b5bktWbKkXH755bJmzRrf9+vXr1fG8qeffipt27aVggULyocffhgnSQkhJO/ky8HVkRBCiCPp2rWr7N+/X7p16yYjR46UpUuXSv369aVv377Ss2dPOXLkiAwdOlROnDghP/30k/rNxIkTlaHaqFEjycrKkscee0wZrwsXLpSzzjpLfa5ataqcffbZMmbMGGUYw5gtV65cvMUlhJCooCFLCCEOZufOncpw3bt3rzJQlyxZIr/99ptMnTrVtw7iZeHBXbFihdSqVeuMbcBbm5GRIYsXL5YGDRr4DNnnn39eBgwYEGOJCCHEOhhaQAghDqZ06dLSr18/qVu3rvLO/v333zJjxgwVVqCXOnXqqHV1+MCqVavkxhtvlGrVqkmxYsWU5xVs3LjRb9vNmzePg0SEEGIdyRZuixBCiA0kJyerBSBU4IorrpBnn332jPV0aAC+r1Klirz++utSvnx5OXXqlPLEZmdn+61fpEiRGElACCH2QEOWEEJcRLNmzVSIAbys2rg1smfPHhViACP2ggsuUG0zZ86MQ08JIcR+GFpACCEu4p577lHxsggdmDdvngonQLxs79695eTJk5KWlqYyFbz22muyevVqNQFs8ODB8e42IYTYAg1ZQghxEQgVmDVrljJakYqrYcOGMnDgQJVqCxkJsHzyySeyYMECFU4waNAg+c9//hPvbhNCiC0wawEhhBBCCHEl9MgSQgghhBBXQkOWEEIIIYS4EhqyhBBCCCHEldCQJYQQQgghroSGLCGEEEIIcSU0ZAkhhBBCiCuhIUsIIYQQQlwJDVlCCCGEEOJKaMgSQgghhBBXQkOWEEIIIYS4EhqyhBBCCCFE3Mj/ARNNCO/lsjv+AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "\n",
    "# All Model Cards\n",
    "plt.bar(all_cards_per_year.index, all_cards_per_year.values, \n",
    "        color=\"lightgray\", alpha=0.6, label=\"All Model Cards\")\n",
    "\n",
    "# Model Cards with Ethical Sections\n",
    "plt.plot(bias_cards_per_year.index, bias_cards_per_year.values, \n",
    "         color=\"teal\", linewidth=3, marker=\"o\", label=\"Model Cards with Ethical Sections\")\n",
    "\n",
    "plt.yscale(\"log\")  # log scale\n",
    "\n",
    "plt.yticks([1e3, 5e3, 1e4, 5e4], [\"1k\", \"5k\", \"10k\", \"50k\"])\n",
    "\n",
    "plt.xticks(all_cards_per_year.index, labels=[str(year) for year in all_cards_per_year.index])\n",
    "for x, y in zip(bias_cards_per_year.index, bias_cards_per_year.values):\n",
    "    plt.text(x, y*1.15, f\"{y}\", ha=\"center\", fontsize=8)\n",
    "\n",
    "for x, y in zip(all_cards_per_year.index, all_cards_per_year.values):\n",
    "    plt.text(x, y*1.05, f\"{y}\", ha=\"center\", fontsize=8)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Model Cards (log scale)\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4, which=\"both\", linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"growth_mcs_ethics.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66954a5",
   "metadata": {},
   "source": [
    "###  **Metadata Analysis:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6967bb",
   "metadata": {},
   "source": [
    "**Pipeline tag or Task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a614d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline_tag\n",
       "text-generation                   54.073449\n",
       "image-text-to-text                 8.062474\n",
       "text-classification                7.112706\n",
       "text-to-image                      5.223723\n",
       "automatic-speech-recognition       4.041790\n",
       "image-classification               2.849304\n",
       "fill-mask                          2.184466\n",
       "sentence-similarity                2.015618\n",
       "image-to-text                      1.720135\n",
       "token-classification               1.688476\n",
       "feature-extraction                 1.424652\n",
       "translation                        1.002533\n",
       "image-segmentation                 0.949768\n",
       "object-detection                   0.612073\n",
       "audio-classification               0.601520\n",
       "image-to-image                     0.569861\n",
       "video-classification               0.559308\n",
       "image-feature-extraction           0.527649\n",
       "zero-shot-image-classification     0.485437\n",
       "text-to-speech                     0.453778\n",
       "question-answering                 0.432672\n",
       "text-to-audio                      0.390460\n",
       "summarization                      0.369354\n",
       "zero-shot-classification           0.295483\n",
       "image-to-video                     0.263824\n",
       "visual-document-retrieval          0.242718\n",
       "depth-estimation                   0.221612\n",
       "text-ranking                       0.179401\n",
       "text-to-video                      0.158295\n",
       "unconditional-image-generation     0.147742\n",
       "audio-to-audio                     0.137189\n",
       "visual-question-answering          0.105530\n",
       "reinforcement-learning             0.094977\n",
       "table-question-answering           0.094977\n",
       "time-series-forecasting            0.094977\n",
       "robotics                           0.084424\n",
       "keypoint-detection                 0.073871\n",
       "voice-activity-detection           0.052765\n",
       "video-to-video                     0.052765\n",
       "tabular-classification             0.052765\n",
       "text-to-3d                         0.042212\n",
       "image-to-3d                        0.042212\n",
       "graph-ml                           0.031659\n",
       "document-question-answering        0.031659\n",
       "audio-text-to-text                 0.031659\n",
       "zero-shot-object-detection         0.021106\n",
       "mask-generation                    0.021106\n",
       "video-text-to-text                 0.021106\n",
       "any-to-any                         0.021106\n",
       "tabular-regression                 0.010553\n",
       "other                              0.010553\n",
       "multiple-choice                    0.010553\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final[\"pipeline_tag\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b24c6",
   "metadata": {},
   "source": [
    "**Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64b35f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "library_name\n",
       "transformers                74.466519\n",
       "peft                        12.233260\n",
       "diffusers                    5.463576\n",
       "sentence-transformers        2.078734\n",
       "cosmos                       0.993377\n",
       "                              ...    \n",
       "Electricity-Meter-OCR-7B     0.009198\n",
       "wham                         0.009198\n",
       "fairseq                      0.009198\n",
       "DiffusionRenderer            0.009198\n",
       "sklearn                      0.009198\n",
       "Name: proportion, Length: 62, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final[\"library_name\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e6c548",
   "metadata": {},
   "source": [
    "**Author**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dfa7c196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "RichardErkhov        857\n",
       "google               565\n",
       "unsloth              442\n",
       "nvidia               377\n",
       "TheBloke             255\n",
       "EleutherAI           239\n",
       "allenai              228\n",
       "facebook             213\n",
       "QuantFactory         204\n",
       "CodeAtCMU            165\n",
       "giovannidemuri       152\n",
       "Mungert              152\n",
       "microsoft            145\n",
       "stabilityai          144\n",
       "meta-llama           134\n",
       "Salesforce           116\n",
       "GaetanMichelet        92\n",
       "clembench-playpen     88\n",
       "mav23                 84\n",
       "mini1013              78\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final[\"author\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4595c81",
   "metadata": {},
   "source": [
    "**Word count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1241c29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10329.000000\n",
       "mean        82.509343\n",
       "std        159.503901\n",
       "min          0.000000\n",
       "25%         14.000000\n",
       "50%         24.000000\n",
       "75%         80.000000\n",
       "max       6033.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final.groupby(\"model_id\")[\"word_count\"].sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1296b938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     10329.000000\n",
       "mean      10031.687675\n",
       "std       18788.187836\n",
       "min         475.000000\n",
       "25%        3806.000000\n",
       "50%        5178.000000\n",
       "75%       10331.000000\n",
       "max      651816.000000\n",
       "Name: card_length, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_models = data_bias_final.drop_duplicates(subset=\"model_id\")\n",
    "unique_models[\"card_length\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00abe8eb",
   "metadata": {},
   "source": [
    "**Correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "83bbdf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>card_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.623233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card_length</th>\n",
       "      <td>0.623233</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word_count  card_length\n",
       "word_count     1.000000     0.623233\n",
       "card_length    0.623233     1.000000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data_bias_final.groupby(\"model_id\")[[\"word_count\", \"card_length\"]].sum().corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e5226c",
   "metadata": {},
   "source": [
    "### **Content Analysis of Ethical Sections:**\n",
    "\n",
    "1. Preprocessing and normalization of text within sections.\n",
    "2. Computation of basic metrics.\n",
    "3. Thematic analysis (Topic Modeling) applying Latent Dirichlet Allocation (LDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "16161a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_id         object\n",
       "header           object\n",
       "section_text     object\n",
       "word_count        int64\n",
       "author           object\n",
       "created_at       object\n",
       "last_modified    object\n",
       "downloads         int64\n",
       "likes             int64\n",
       "has_card           bool\n",
       "card_length       int64\n",
       "library_name     object\n",
       "tags             object\n",
       "pipeline_tag     object\n",
       "year              int32\n",
       "category         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffada139",
   "metadata": {},
   "source": [
    "**1. Preprocessing and normalization of text within sections**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6d843302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>header</th>\n",
       "      <th>section_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>author</th>\n",
       "      <th>created_at</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>downloads</th>\n",
       "      <th>likes</th>\n",
       "      <th>has_card</th>\n",
       "      <th>card_length</th>\n",
       "      <th>library_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>pipeline_tag</th>\n",
       "      <th>year</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Falconsai</td>\n",
       "      <td>2023-10-13T23:50:01+00:00</td>\n",
       "      <td>2025-04-06T13:42:07+00:00</td>\n",
       "      <td>98988953</td>\n",
       "      <td>824</td>\n",
       "      <td>True</td>\n",
       "      <td>9142</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, safetensors, vit, image...</td>\n",
       "      <td>image-classification</td>\n",
       "      <td>2023</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Falconsai/nsfw_image_detection</td>\n",
       "      <td>limitations</td>\n",
       "      <td>- **Specialized Task Fine-Tuning**: While the ...</td>\n",
       "      <td>44</td>\n",
       "      <td>Falconsai</td>\n",
       "      <td>2023-10-13T23:50:01+00:00</td>\n",
       "      <td>2025-04-06T13:42:07+00:00</td>\n",
       "      <td>98988953</td>\n",
       "      <td>824</td>\n",
       "      <td>True</td>\n",
       "      <td>9142</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, safetensors, vit, image...</td>\n",
       "      <td>image-classification</td>\n",
       "      <td>2023</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td>\\nYou can use the raw model for either masked ...</td>\n",
       "      <td>95</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>2022-03-02T23:29:04+00:00</td>\n",
       "      <td>2024-02-19T11:06:12+00:00</td>\n",
       "      <td>55171860</td>\n",
       "      <td>2417</td>\n",
       "      <td>True</td>\n",
       "      <td>10516</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, tf, jax, rust, coreml, ...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>google-bert/bert-base-uncased</td>\n",
       "      <td>limitations and bias</td>\n",
       "      <td>\\nEven if the training data used for this mode...</td>\n",
       "      <td>220</td>\n",
       "      <td>google-bert</td>\n",
       "      <td>2022-03-02T23:29:04+00:00</td>\n",
       "      <td>2024-02-19T11:06:12+00:00</td>\n",
       "      <td>55171860</td>\n",
       "      <td>2417</td>\n",
       "      <td>True</td>\n",
       "      <td>10516</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, tf, jax, rust, coreml, ...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022</td>\n",
       "      <td>bias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FacebookAI/roberta-large</td>\n",
       "      <td>intended uses and limitations</td>\n",
       "      <td>\\n\\n\\nYou can use the raw model for masked lan...</td>\n",
       "      <td>90</td>\n",
       "      <td>FacebookAI</td>\n",
       "      <td>2022-03-02T23:29:04+00:00</td>\n",
       "      <td>2024-02-19T12:47:04+00:00</td>\n",
       "      <td>13086830</td>\n",
       "      <td>247</td>\n",
       "      <td>True</td>\n",
       "      <td>9278</td>\n",
       "      <td>transformers</td>\n",
       "      <td>transformers, pytorch, tf, jax, onnx, safetens...</td>\n",
       "      <td>fill-mask</td>\n",
       "      <td>2022</td>\n",
       "      <td>limitation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model_id                         header  \\\n",
       "0  Falconsai/nsfw_image_detection  intended uses and limitations   \n",
       "1  Falconsai/nsfw_image_detection                    limitations   \n",
       "2   google-bert/bert-base-uncased  intended uses and limitations   \n",
       "3   google-bert/bert-base-uncased           limitations and bias   \n",
       "4        FacebookAI/roberta-large  intended uses and limitations   \n",
       "\n",
       "                                        section_text  word_count       author  \\\n",
       "0                                                              0    Falconsai   \n",
       "1  - **Specialized Task Fine-Tuning**: While the ...          44    Falconsai   \n",
       "2  \\nYou can use the raw model for either masked ...          95  google-bert   \n",
       "3  \\nEven if the training data used for this mode...         220  google-bert   \n",
       "4  \\n\\n\\nYou can use the raw model for masked lan...          90   FacebookAI   \n",
       "\n",
       "                  created_at              last_modified  downloads  likes  \\\n",
       "0  2023-10-13T23:50:01+00:00  2025-04-06T13:42:07+00:00   98988953    824   \n",
       "1  2023-10-13T23:50:01+00:00  2025-04-06T13:42:07+00:00   98988953    824   \n",
       "2  2022-03-02T23:29:04+00:00  2024-02-19T11:06:12+00:00   55171860   2417   \n",
       "3  2022-03-02T23:29:04+00:00  2024-02-19T11:06:12+00:00   55171860   2417   \n",
       "4  2022-03-02T23:29:04+00:00  2024-02-19T12:47:04+00:00   13086830    247   \n",
       "\n",
       "   has_card  card_length  library_name  \\\n",
       "0      True         9142  transformers   \n",
       "1      True         9142  transformers   \n",
       "2      True        10516  transformers   \n",
       "3      True        10516  transformers   \n",
       "4      True         9278  transformers   \n",
       "\n",
       "                                                tags          pipeline_tag  \\\n",
       "0  transformers, pytorch, safetensors, vit, image...  image-classification   \n",
       "1  transformers, pytorch, safetensors, vit, image...  image-classification   \n",
       "2  transformers, pytorch, tf, jax, rust, coreml, ...             fill-mask   \n",
       "3  transformers, pytorch, tf, jax, rust, coreml, ...             fill-mask   \n",
       "4  transformers, pytorch, tf, jax, onnx, safetens...             fill-mask   \n",
       "\n",
       "   year    category  \n",
       "0  2023  limitation  \n",
       "1  2023  limitation  \n",
       "2  2022  limitation  \n",
       "3  2022        bias  \n",
       "4  2022  limitation  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main text cleaning\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str) or text.strip() == \"\":\n",
    "        return \"\"\n",
    "    \n",
    "    # HTML comments / tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text(separator=\" \")\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # URLs / emails\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)\n",
    "    \n",
    "    # Markdown code / inline code\n",
    "    text = re.sub(r'`{1,3}.*?`{1,3}', ' ', text)\n",
    "    # Markdown links [text](url) -> keep text\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^\\)]+\\)', r'\\1', text)\n",
    "    # Images\n",
    "    text = re.sub(r'!\\[.*?\\]\\(.*?\\)', ' ', text)\n",
    "    # Headers\n",
    "    text = re.sub(r'#+', ' ', text)\n",
    "    \n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, replace=' ')\n",
    "   \n",
    "    # Only letters/numbers/spaces\n",
    "    text = re.sub(r'[^a-z√°√©√≠√≥√∫√º√±0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Normalize spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Filter placeholders\n",
    "    placeholders = [\"todo\", \"tbd\", \"more information needed\", \"n/a\", \"none\"]\n",
    "    if any(p in text for p in placeholders):\n",
    "        return \"\"\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aebcd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bias_final[\"cleaned_text\"] = data_bias_final[\"section_text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data_bias_final['preprocessed_text'].tolist()\n",
    "\n",
    "custom_stopwords = {\n",
    "    \"datum\", \"llama\", \"s\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494439f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing using spaCy: tokenization, lemmatization, and custom stopword removal\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "def preprocess_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [\n",
    "        token.lemma_.lower()\n",
    "        for token in doc\n",
    "        if not token.is_stop\n",
    "        and token.is_alpha\n",
    "        and token.lemma_.lower() not in custom_stopwords\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# data_bias_final[\"preprocessed_text\"] = data_bias_final[\"cleaned_text\"].apply(preprocess_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d964a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13071/13071 [03:28<00:00, 62.61it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "texts = data_bias_final[\"cleaned_text\"].tolist()\n",
    "preprocessed_texts = []\n",
    "\n",
    "for doc in tqdm(nlp.pipe(texts, batch_size=50), total=len(texts)):\n",
    "    preprocessed_texts.append(preprocess_spacy(doc.text))\n",
    "\n",
    "data_bias_final[\"preprocessed_text\"] = preprocessed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6239ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where section_text is empty or contains only whitespace\n",
    "data_bias_final = data_bias_final[data_bias_final['preprocessed_text'].str.strip() != \"\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f48a8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>specialized task fine tuning while the model i...</td>\n",
       "      <td>specialized task fine tuning model adept nsfw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you can use the raw model for either masked la...</td>\n",
       "      <td>use raw model mask language modeling sentence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even if the training data used for this model ...</td>\n",
       "      <td>training datum model characterize fairly neutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you can use the raw model for masked language ...</td>\n",
       "      <td>use raw model masked language modeling s inten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the training data used for this model contains...</td>\n",
       "      <td>training datum model contain lot unfiltered co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>clip and our analysis of it have a number of l...</td>\n",
       "      <td>clip analysis number limitation clip currently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we find that the performance of clip and the s...</td>\n",
       "      <td>find performance clip specific bias exhibit de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you can use the raw model for either masked la...</td>\n",
       "      <td>use raw model mask language modeling sentence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>even if the training data used for this model ...</td>\n",
       "      <td>training datum model characterize fairly neutr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>you can use the raw model for text generation ...</td>\n",
       "      <td>use raw model text generation fine tune downst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_text  \\\n",
       "1   specialized task fine tuning while the model i...   \n",
       "2   you can use the raw model for either masked la...   \n",
       "3   even if the training data used for this model ...   \n",
       "4   you can use the raw model for masked language ...   \n",
       "5   the training data used for this model contains...   \n",
       "7   clip and our analysis of it have a number of l...   \n",
       "8   we find that the performance of clip and the s...   \n",
       "9   you can use the raw model for either masked la...   \n",
       "10  even if the training data used for this model ...   \n",
       "11  you can use the raw model for text generation ...   \n",
       "\n",
       "                                    preprocessed_text  \n",
       "1   specialized task fine tuning model adept nsfw ...  \n",
       "2   use raw model mask language modeling sentence ...  \n",
       "3   training datum model characterize fairly neutr...  \n",
       "4   use raw model masked language modeling s inten...  \n",
       "5   training datum model contain lot unfiltered co...  \n",
       "7   clip analysis number limitation clip currently...  \n",
       "8   find performance clip specific bias exhibit de...  \n",
       "9   use raw model mask language modeling sentence ...  \n",
       "10  training datum model characterize fairly neutr...  \n",
       "11  use raw model text generation fine tune downst...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final[[\"cleaned_text\", \"preprocessed_text\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3f30ee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13017</th>\n",
       "      <td>\\nWhile the model is designed to improve inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13019</th>\n",
       "      <td>- **Limited Scope**: The model has been specif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13023</th>\n",
       "      <td>The model was trained on a dataset that includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13024</th>\n",
       "      <td>- The model may produce biased or offensive ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13039</th>\n",
       "      <td>\\nLike any base or fine-tuned language model, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13046</th>\n",
       "      <td>\\nThese models are intended to be used for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13047</th>\n",
       "      <td>\\nLarge Language Models may generate text that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13048</th>\n",
       "      <td>\\nYou can use the raw model for object detecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13053</th>\n",
       "      <td>NVIDIA believes Trustworthy AI is a shared res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13054</th>\n",
       "      <td>\\nNVIDIA believes Trustworthy AI is a shared r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            section_text\n",
       "13017  \\nWhile the model is designed to improve inter...\n",
       "13019  - **Limited Scope**: The model has been specif...\n",
       "13023  The model was trained on a dataset that includ...\n",
       "13024  - The model may produce biased or offensive ou...\n",
       "13039  \\nLike any base or fine-tuned language model, ...\n",
       "13046  \\nThese models are intended to be used for res...\n",
       "13047  \\nLarge Language Models may generate text that...\n",
       "13048  \\nYou can use the raw model for object detecti...\n",
       "13053  NVIDIA believes Trustworthy AI is a shared res...\n",
       "13054  \\nNVIDIA believes Trustworthy AI is a shared r..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias_final[[\"section_text\"]].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ac0bb",
   "metadata": {},
   "source": [
    "**2. Computation of basic metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165d4214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(40.49136836760599)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique words\n",
    "unique_words = data_bias_final['preprocessed_text'].apply(\n",
    "    lambda x: len(set(re.findall(r'\\b\\w+\\b', x))) if isinstance(x, str) else 0\n",
    ")\n",
    "\n",
    "unique_words.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea271da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8515027983080293)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relative lexical variety (Type-Token Ratio, TTR)\n",
    "type_token_ratio = data_bias_final['preprocessed_text'].apply(\n",
    "    lambda x: (len(set(re.findall(r'\\b\\w+\\b', x))) / len(re.findall(r'\\b\\w+\\b', x)))\n",
    "    if isinstance(x, str) and len(re.findall(r'\\b\\w+\\b', x)) > 0 else 0\n",
    ")\n",
    "\n",
    "type_token_ratio.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08659186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.578409351868531)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexical complexity (average word length)\n",
    "avg_word_length = data_bias_final['preprocessed_text'].apply(\n",
    "    lambda x: np.mean([len(w) for w in re.findall(r'\\b\\w+\\b', x)]) if isinstance(x, str) and len(re.findall(r'\\b\\w+\\b', x)) > 0 else 0\n",
    ")\n",
    "\n",
    "avg_word_length.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23caba27",
   "metadata": {},
   "source": [
    "**3. Thematic analysis (Topic Modeling): LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LdaModel, CoherenceModel\n",
    "\n",
    "\n",
    "# Tokenize preprocessed text into lists of words for LDA\n",
    "tokenized_texts = [t.split() for t in data_bias_final[\"preprocessed_text\"] if t.strip()]\n",
    "\n",
    "# Create a dictionary\n",
    "dictionary = corpora.Dictionary(tokenized_texts)\n",
    "dictionary.filter_extremes(no_below=3, no_above=0.6)\n",
    "\n",
    "# Convert each document to bag-of-words format\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee39e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model', 22405),\n",
       " ('use', 6969),\n",
       " ('language', 4745),\n",
       " ('safety', 4177),\n",
       " ('bias', 3915),\n",
       " ('content', 3814),\n",
       " ('training', 3719),\n",
       " ('generate', 3636),\n",
       " ('user', 3525),\n",
       " ('developer', 3164),\n",
       " ('case', 3159),\n",
       " ('application', 2997),\n",
       " ('risk', 2992),\n",
       " ('text', 2903),\n",
       " ('output', 2809),\n",
       " ('ai', 2331),\n",
       " ('train', 2305),\n",
       " ('limitation', 2275),\n",
       " ('llm', 2223),\n",
       " ('prompt', 2214),\n",
       " ('information', 2166),\n",
       " ('task', 2101),\n",
       " ('dataset', 2034),\n",
       " ('response', 2010),\n",
       " ('responsible', 1997),\n",
       " ('produce', 1989),\n",
       " ('misuse', 1966),\n",
       " ('fine', 1942),\n",
       " ('base', 1921),\n",
       " ('specific', 1878),\n",
       " ('performance', 1728),\n",
       " ('provide', 1726),\n",
       " ('include', 1626),\n",
       " ('context', 1586),\n",
       " ('work', 1579),\n",
       " ('english', 1559),\n",
       " ('image', 1521),\n",
       " ('harmful', 1436),\n",
       " ('perform', 1408),\n",
       " ('technology', 1403),\n",
       " ('deploy', 1390),\n",
       " ('evaluation', 1385),\n",
       " ('testing', 1371),\n",
       " ('capability', 1364),\n",
       " ('generation', 1282),\n",
       " ('tuning', 1268),\n",
       " ('code', 1221),\n",
       " ('like', 1204),\n",
       " ('development', 1197),\n",
       " ('potential', 1188)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten all tokenized texts into a single list of words\n",
    "all_words = [token for doc in tokenized_texts for token in doc]\n",
    "\n",
    "freq = Counter(all_words)\n",
    "freq.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12c1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherencia: 0.45296126256487507\n"
     ]
    }
   ],
   "source": [
    "# LDA Model training\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=3,\n",
    "    random_state=42,\n",
    "    passes=30,\n",
    "    alpha='auto',\n",
    "    eta='auto'\n",
    ")\n",
    "\n",
    "# Coherence\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                     texts=tokenized_texts, \n",
    "                                     dictionary=dictionary, \n",
    "                                     coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherencia:', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfb6cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: ['use', 'developer', 'misuse', 'ai', 'safety', 'bias']\n",
      "Topic 1: ['language', 'generate', 'bias', 'content', 'text', 'output']\n",
      "Topic 2: ['safety', 'use', 'user', 'risk', 'llm', 'testing']\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.show_topics(num_words=6, formatted=False):\n",
    "    print(f\"Topic {idx}: {[word for word, _ in topic]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e599dd3",
   "metadata": {},
   "source": [
    "**Topic Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee478d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1802817329381520168548228869\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1802817329381520168548228869_data = {\"mdsDat\": {\"x\": [-0.06298186886409028, -0.17572459373900706, 0.23870646260309736], \"y\": [-0.19814760001034978, 0.1442430964488432, 0.05390450356150664], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [49.53768025786074, 25.929410611524332, 24.53290913061493]}, \"tinfo\": {\"Term\": [\"use\", \"misuse\", \"testing\", \"policy\", \"safety\", \"privacy\", \"cover\", \"developer\", \"attack\", \"conduct\", \"llm\", \"response\", \"ai\", \"report\", \"assess\", \"responsible\", \"new\", \"technology\", \"guide\", \"vlm\", \"evaluation\", \"product\", \"text\", \"prohibit\", \"risk\", \"cyber\", \"user\", \"tailor\", \"nuance\", \"image\", \"token\", \"example\", \"issue\", \"inappropriate\", \"domain\", \"e\", \"g\", \"stereotype\", \"sequence\", \"limit\", \"set\", \"primarily\", \"man\", \"factually\", \"hallucination\", \"group\", \"representation\", \"non\", \"verify\", \"accurate\", \"exhibit\", \"standard\", \"likely\", \"prediction\", \"bad\", \"speech\", \"foreseeable\", \"python\", \"phi\", \"weakness\", \"additionally\", \"present\", \"source\", \"tune\", \"contain\", \"offensive\", \"performance\", \"intend\", \"know\", \"generate\", \"text\", \"language\", \"include\", \"english\", \"bias\", \"like\", \"system\", \"output\", \"content\", \"produce\", \"train\", \"prompt\", \"information\", \"dataset\", \"generation\", \"training\", \"base\", \"code\", \"case\", \"use\", \"fine\", \"work\", \"user\", \"specific\", \"limitation\", \"risk\", \"cover\", \"attack\", \"cyber\", \"nuance\", \"objectionable\", \"serve\", \"date\", \"sense\", \"instance\", \"reason\", \"guide\", \"effectively\", \"uplift\", \"cbrne\", \"helpfulness\", \"biological\", \"weapon\", \"chemical\", \"statistical\", \"situation\", \"generally\", \"teaming\", \"objective\", \"subtle\", \"expression\", \"sarcasm\", \"grasp\", \"inherently\", \"autonomy\", \"figurative\", \"power\", \"testing\", \"tailor\", \"conduct\", \"new\", \"advance\", \"learn\", \"value\", \"assess\", \"determine\", \"technology\", \"influence\", \"llm\", \"complex\", \"response\", \"safety\", \"risk\", \"user\", \"certain\", \"design\", \"common\", \"capability\", \"training\", \"perform\", \"use\", \"application\", \"context\", \"language\", \"output\", \"task\", \"prompt\", \"potential\", \"deploy\", \"case\", \"responsible\", \"limitation\", \"policy\", \"report\", \"prohibit\", \"vlm\", \"gemma\", \"guideline\", \"nvidia\", \"enable\", \"share\", \"toolkit\", \"hub\", \"generative\", \"responsibility\", \"interest\", \"adhere\", \"embed\", \"de\", \"meet\", \"carefully\", \"exploration\", \"education\", \"describe\", \"raise\", \"vulnerability\", \"essential\", \"preserve\", \"trustworthy\", \"establish\", \"accordance\", \"careful\", \"scale\", \"product\", \"privacy\", \"raw\", \"help\", \"misuse\", \"develop\", \"security\", \"concern\", \"encourage\", \"use\", \"developer\", \"ai\", \"ethical\", \"outline\", \"responsible\", \"malicious\", \"card\", \"mechanism\", \"development\", \"technique\", \"evaluation\", \"safety\", \"provide\", \"case\", \"application\", \"bias\", \"open\", \"image\", \"content\", \"user\", \"fine\", \"text\", \"train\", \"limitation\", \"harmful\", \"training\", \"llm\"], \"Freq\": [6849.0, 1920.0, 1365.0, 1097.0, 4105.0, 1027.0, 960.0, 3050.0, 910.0, 1007.0, 2292.0, 1991.0, 2306.0, 758.0, 1136.0, 1972.0, 835.0, 1414.0, 730.0, 662.0, 1340.0, 661.0, 2812.0, 642.0, 2993.0, 649.0, 3559.0, 662.0, 610.0, 1489.0, 836.9778953347571, 679.9198977406987, 596.0305979592019, 575.853331581369, 580.132124683374, 542.7354782795397, 514.7350328661903, 499.98350684922735, 482.6213057712467, 676.8773537569415, 508.1434144907268, 410.19550742881336, 404.07569833221737, 385.714811428086, 388.7372746569351, 381.92414874715377, 368.94163108383356, 372.6083592377772, 359.048940062854, 343.3029964859268, 348.7077051310284, 347.1388850961402, 304.3779348260781, 305.69466177154044, 301.8766423793511, 306.7844629173187, 298.15013638342845, 298.58835241702553, 297.23533415129407, 292.1269714486705, 305.1104843035886, 520.9247265283258, 684.5744309593231, 947.5049357323194, 721.6227160731638, 978.7771288121008, 1430.1724183937074, 668.3849194295391, 598.7598556279486, 2590.258506349067, 2046.7949016657851, 3045.5612277590894, 1249.6395317738393, 1172.792517354061, 2464.9473418808693, 969.4302008633953, 662.7204657773925, 1824.6914908498627, 2289.799636035416, 1370.4876378868435, 1464.2989978991416, 1391.8664764845803, 1338.0438610273075, 1282.4995198749752, 874.5334185483497, 1631.2561442018812, 1123.3253910979356, 847.9627759613498, 1225.8543641231815, 1700.0349412993776, 980.8695965504214, 876.1426212467427, 1042.9078946094123, 847.9077529236719, 879.2103767509794, 893.5173396234877, 959.3894891551108, 909.4182247947788, 648.4131072075112, 609.4230672934282, 501.7297506098089, 488.6399703051135, 496.1080308300682, 459.04494556057006, 488.9452011061781, 449.51236353575706, 729.7516982149272, 366.23790451464134, 345.59324515465204, 326.4375351657843, 308.4697573396459, 288.4191913948659, 283.85193475721303, 284.33365026675114, 274.9651668400833, 276.2520489757913, 274.94252456737087, 280.30406657539106, 250.75136297043696, 257.80744062942193, 261.6551452876234, 255.28252625107677, 241.22630521825334, 245.94763580774818, 239.22954847527578, 239.43265753305334, 351.5005863234048, 1327.6637859657806, 643.1023598276414, 954.5369120993512, 796.0495229038651, 433.54502355828265, 544.8114668281505, 512.5650736218719, 909.2885757894722, 324.7659196068291, 1064.9831401977904, 453.1648075313236, 1434.190817240235, 689.7308097990086, 1173.0918893369849, 1960.7033919433375, 1553.1956392111217, 1598.6728060153666, 740.3950017894879, 644.5819791007025, 534.5959123646692, 751.8695407009284, 1276.132658858746, 767.3795901154001, 1648.2518821346464, 1065.5947130771078, 785.754187998904, 1189.1199328308724, 949.0559077935842, 829.3679281711643, 828.8866525421798, 666.9953287123702, 685.6982163985967, 775.881740367323, 665.8218663046973, 667.1189582995733, 1096.7951775724646, 757.3310060568515, 641.4688304861536, 662.2161422535796, 568.6236121938622, 528.3865820413372, 485.19784800364334, 493.661872913381, 443.8884069124303, 386.9675206808706, 385.2618882989947, 374.54557698993966, 348.74121175278145, 322.9742159559885, 323.8944986629434, 317.66705447330753, 313.2004863517148, 303.8123673149615, 333.42964213330254, 282.37258185570283, 269.7648642938823, 281.7108185714857, 265.1613698113732, 281.55474749141393, 265.31562280026657, 258.7470784199111, 251.9872401809919, 273.24729747014686, 246.02175445403364, 258.60456635718174, 449.12678759631467, 655.9185372682286, 980.2352054646769, 370.1100916560833, 489.2114923746897, 1593.0148200125568, 376.41720328687296, 547.0201766238364, 548.3410746267116, 760.7352613124457, 3500.9142702352588, 1736.9883651927855, 1385.1420727544619, 579.5147231125976, 457.46061089202476, 1105.4379011307954, 546.4696673769082, 596.5268432205381, 592.1331520790715, 728.564641719418, 549.0912234278536, 754.6249854326069, 1358.2481670930554, 846.9268898028047, 1160.1714703417733, 1104.870481445437, 1215.9157230102267, 650.6107186441579, 758.6620240371292, 966.0301743267285, 917.5744958594081, 712.8319320879448, 765.7475853582473, 734.4172305556128, 703.4706463246074, 650.9413483820671, 742.7684023840129, 607.8125894485469], \"Total\": [6849.0, 1920.0, 1365.0, 1097.0, 4105.0, 1027.0, 960.0, 3050.0, 910.0, 1007.0, 2292.0, 1991.0, 2306.0, 758.0, 1136.0, 1972.0, 835.0, 1414.0, 730.0, 662.0, 1340.0, 661.0, 2812.0, 642.0, 2993.0, 649.0, 3559.0, 662.0, 610.0, 1489.0, 837.6722318231027, 680.6460077967399, 596.7284099431189, 576.5687486580395, 580.8653014650338, 543.4391394160041, 515.4364508712302, 500.6790230081979, 483.3164945157841, 677.9667941108262, 508.9762272539072, 410.88972586897137, 404.77134232579795, 386.41059072747566, 389.4399811372133, 382.6201652106246, 369.6342680450979, 373.30831603928823, 359.7628981479565, 344.00059772104123, 349.4170002116496, 347.90548635509606, 305.07417243795913, 306.39746979404606, 302.57293526861787, 307.49458307679373, 298.84058766777974, 299.2823347348177, 297.9270797318805, 292.8175908312669, 305.85336748019336, 526.8827856958031, 716.3153851937517, 1041.383136511505, 780.9672446724646, 1107.3475572202565, 1709.038204382454, 738.7075140339789, 653.8715788685488, 3623.578779824591, 2812.8910313411843, 4632.762869786684, 1616.3366660998445, 1514.8002714577615, 3927.104564060336, 1237.6274667060432, 768.2995239964773, 2833.7357058827365, 3808.181617035708, 2026.791191291228, 2331.705188926675, 2221.120530189257, 2105.1974204684607, 2066.5783452194205, 1259.8297312336742, 3650.15720544464, 1963.8604133600738, 1248.047999299449, 3161.907574832278, 6849.201093669282, 1952.160548125886, 1509.6021720692993, 3559.155196484187, 1839.3600953798193, 2249.7999813751603, 2993.6137309632104, 960.1212029093946, 910.1184232640511, 649.0983588100503, 610.125517536263, 502.4542417452109, 489.35245540789913, 496.8460799508572, 459.73931292466074, 489.6866230631594, 450.21176942720433, 730.9847595408153, 366.94440927587385, 346.2786743162145, 327.1225857386289, 309.2079309067688, 289.11352694362176, 284.5394408629517, 285.02245910141323, 275.6966188993305, 276.98723042586715, 275.6749903587696, 281.05189780667416, 251.4451303527, 258.52468096047403, 262.38632082545774, 255.99835496869778, 241.92097749200985, 246.65709334639354, 239.9197580981525, 240.1252758467294, 352.91703757734155, 1365.3461992311939, 662.8107650331543, 1007.1399008506042, 835.6883384561937, 449.14236470849454, 584.7384943389088, 566.4389661206893, 1136.1090567084466, 336.4875510494953, 1414.265113824343, 509.0171015441486, 2292.50387994286, 927.6239549201761, 1991.7298692789261, 4105.474390358131, 2993.6137309632104, 3559.155196484187, 1112.4356727126144, 951.6916329329761, 709.6213504741523, 1344.8893695170977, 3650.15720544464, 1416.7386161321617, 6849.201093669282, 2947.108825198297, 1546.4821992659963, 4632.762869786684, 2833.7357058827365, 2025.9758155363957, 2221.120530189257, 1191.8973819087448, 1392.8706730689835, 3161.907574832278, 1972.1395674275777, 2249.7999813751603, 1097.495177400723, 758.081267241934, 642.1530148950725, 662.9758762548735, 569.337644379677, 529.078293721112, 485.8816684852151, 494.3593739187156, 444.6084917758015, 387.65035599286796, 385.95815886767014, 375.24840813834703, 349.4478187529979, 323.66419118140635, 324.6032772885878, 318.38209523060596, 313.92771919345364, 304.522425907459, 334.2357901957556, 283.06585537259093, 270.45415013771196, 282.43321030951785, 265.8505076512098, 282.29153391918055, 266.021599514173, 259.44519989345065, 252.67373453294005, 273.9986448239929, 246.7039182664736, 259.32798283419504, 450.98717988357976, 661.4881459723903, 1027.4348698401243, 376.3771098199657, 518.4109188083363, 1920.5163320403358, 398.239846010052, 628.7099189380557, 635.8001922249039, 979.732604975798, 6849.201093669282, 3050.8792579867204, 2306.915527238274, 724.2988528212608, 535.5202854814383, 1972.1395674275777, 702.3998837171532, 809.8074952119542, 812.408994850131, 1192.3802120323512, 748.0304488327541, 1340.2779758739343, 4105.474390358131, 1705.2654145778788, 3161.907574832278, 2947.108825198297, 3927.104564060336, 1043.0437395945228, 1489.214447073904, 3808.181617035708, 3559.155196484187, 1952.160548125886, 2812.8910313411843, 2331.705188926675, 2249.7999813751603, 1446.1866621245808, 3650.15720544464, 2292.50387994286], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.4248, -5.6326, -5.7643, -5.7988, -5.7914, -5.858, -5.911, -5.94, -5.9754, -5.6371, -5.9239, -6.138, -6.153, -6.1995, -6.1917, -6.2094, -6.244, -6.2341, -6.2712, -6.316, -6.3004, -6.3049, -6.4363, -6.432, -6.4446, -6.4285, -6.457, -6.4556, -6.4601, -6.4774, -6.4339, -5.899, -5.6258, -5.3008, -5.5731, -5.2683, -4.8891, -5.6498, -5.7598, -4.2951, -4.5306, -4.1332, -5.024, -5.0875, -4.3447, -5.2779, -5.6583, -4.6455, -4.4184, -4.9317, -4.8655, -4.9162, -4.9557, -4.9981, -5.3809, -4.7575, -5.1306, -5.4118, -5.0432, -4.7162, -5.2662, -5.3791, -5.2049, -5.4118, -5.3756, -5.3595, -4.641, -4.6945, -5.0327, -5.0948, -5.2892, -5.3156, -5.3005, -5.3781, -5.315, -5.3991, -4.9146, -5.604, -5.662, -5.719, -5.7756, -5.8428, -5.8588, -5.8571, -5.8906, -5.8859, -5.8907, -5.8714, -5.9828, -5.9551, -5.9402, -5.9649, -6.0215, -6.0021, -6.0298, -6.029, -5.6451, -4.3161, -5.041, -4.646, -4.8276, -5.4353, -5.2068, -5.2678, -4.6946, -5.7242, -4.5365, -5.391, -4.2389, -4.971, -4.4399, -3.9262, -4.1592, -4.1303, -4.9001, -5.0387, -5.2258, -4.8847, -4.3557, -4.8643, -4.0998, -4.536, -4.8406, -4.4263, -4.6518, -4.7866, -4.7872, -5.0045, -4.9768, -4.8533, -5.0062, -5.0043, -4.4518, -4.8221, -4.9881, -4.9563, -5.1087, -5.1821, -5.2673, -5.2501, -5.3563, -5.4936, -5.498, -5.5262, -5.5976, -5.6743, -5.6715, -5.6909, -5.7051, -5.7355, -5.6425, -5.8087, -5.8544, -5.811, -5.8716, -5.8116, -5.871, -5.896, -5.9225, -5.8415, -5.9465, -5.8966, -5.3446, -4.9659, -4.5641, -5.5381, -5.2591, -4.0785, -5.5212, -5.1474, -5.145, -4.8176, -3.2911, -3.992, -4.2183, -5.0897, -5.3262, -4.4439, -5.1484, -5.0608, -5.0682, -4.8608, -5.1436, -4.8257, -4.238, -4.7103, -4.3956, -4.4444, -4.3486, -4.974, -4.8203, -4.5787, -4.6302, -4.8827, -4.811, -4.8528, -4.8959, -4.9735, -4.8415, -5.042], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.7016, 0.7014, 0.7013, 0.7012, 0.7012, 0.7011, 0.7011, 0.701, 0.701, 0.7008, 0.7008, 0.7007, 0.7007, 0.7006, 0.7006, 0.7006, 0.7006, 0.7006, 0.7005, 0.7004, 0.7004, 0.7002, 0.7002, 0.7001, 0.7001, 0.7001, 0.7001, 0.7001, 0.7001, 0.7001, 0.7, 0.6911, 0.6571, 0.608, 0.6234, 0.579, 0.5243, 0.6024, 0.6144, 0.3667, 0.3845, 0.283, 0.4451, 0.4465, 0.2367, 0.4582, 0.5546, 0.2623, 0.1937, 0.3111, 0.2372, 0.2351, 0.2492, 0.2254, 0.3374, -0.103, 0.1438, 0.3159, -0.2451, -0.691, 0.0142, 0.1584, -0.5251, -0.072, -0.2371, -0.5066, 1.349, 1.349, 1.3487, 1.3486, 1.3483, 1.3483, 1.3483, 1.3483, 1.3483, 1.3482, 1.3481, 1.3479, 1.3478, 1.3477, 1.3474, 1.3474, 1.3474, 1.3474, 1.3471, 1.3471, 1.3471, 1.3471, 1.347, 1.347, 1.347, 1.347, 1.3469, 1.3469, 1.3469, 1.3469, 1.3458, 1.3218, 1.3196, 1.2961, 1.3012, 1.3144, 1.2791, 1.2499, 1.1271, 1.3143, 1.0661, 1.2336, 0.8807, 1.0535, 0.8204, 0.6108, 0.6936, 0.5494, 0.9427, 0.9602, 1.0666, 0.7683, 0.2989, 0.7367, -0.0746, 0.3325, 0.6727, -0.0101, 0.2559, 0.4566, 0.3641, 0.7693, 0.6411, -0.0551, 0.2639, 0.1342, 1.4045, 1.4042, 1.4041, 1.404, 1.4039, 1.4038, 1.4037, 1.4037, 1.4035, 1.4034, 1.4033, 1.4033, 1.4031, 1.403, 1.403, 1.4029, 1.4028, 1.4028, 1.4027, 1.4027, 1.4026, 1.4026, 1.4026, 1.4025, 1.4025, 1.4025, 1.4024, 1.4024, 1.4024, 1.4024, 1.401, 1.3967, 1.3581, 1.3884, 1.3472, 1.2182, 1.3488, 1.266, 1.2572, 1.1522, 0.734, 0.8419, 0.895, 1.1821, 1.2476, 0.8263, 1.1541, 1.0995, 1.0889, 0.9125, 1.096, 0.8307, 0.299, 0.7053, 0.4025, 0.4241, 0.2327, 0.9332, 0.7307, 0.0334, 0.0496, 0.3977, 0.104, 0.2499, 0.2426, 0.6069, -0.187, 0.0776]}, \"token.table\": {\"Topic\": [3, 1, 1, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 2, 2, 1, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 3, 3, 3, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 2, 2, 3, 1, 2, 1, 3, 1, 2, 3, 1, 2, 2, 2, 1, 2, 3, 2, 3, 1, 2, 3, 3, 1, 2, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 1, 3, 2, 3, 3, 1, 2, 3, 1, 2, 3, 3, 3, 1, 3, 1, 2, 3, 1, 1, 3, 2, 1, 2, 1, 2, 3, 1, 1, 3, 2, 1, 2, 3, 1, 3, 3, 2, 1, 1, 2, 3, 1, 1, 3, 2, 3, 2, 3, 1, 3, 1, 1, 2, 3, 1, 2, 1, 2, 3, 2, 2, 1, 3, 3, 1, 1, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 1, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 1, 3, 3, 1, 2, 3, 1, 2, 1, 2, 3, 2, 2, 1, 2, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 3, 1, 2, 1, 2, 1, 1, 2, 3, 1, 1, 3, 1, 2, 1, 3, 3, 1, 2, 1, 2, 3, 1, 3, 1, 3, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 1, 2, 3, 2, 1, 2, 1, 3, 2, 1, 2, 1, 2, 3, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 2, 1, 3, 1, 2, 3, 1, 2, 1, 3, 1, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 3, 3, 1, 2, 1, 2, 3], \"Freq\": [0.9971467082022051, 0.9970912907487078, 0.9972098803841072, 0.9981414935375054, 0.03339698318090168, 0.9662860467007552, 0.1790269280013141, 0.2206409354786171, 0.6003687537090072, 0.26364822138786115, 0.3617104298577349, 0.3749437382671642, 0.19892456508952655, 0.8000992463114144, 0.9987711233665175, 0.9961663928579979, 0.9981064556613127, 0.5718329023591852, 0.25256377521830436, 0.17516519894172722, 0.6276889142598668, 0.06264157115940253, 0.3096428883326564, 0.9961484785738203, 0.2119133413199135, 0.5591537988511401, 0.2290151197422223, 0.2630254736580953, 0.7372122430698728, 0.9987352586072258, 0.9963026395376993, 0.3877406189094672, 0.24542146841251758, 0.36686714350324795, 0.9965683025643303, 0.13933389930047899, 0.6652070031119641, 0.19506745902067057, 0.9964127068981276, 0.6794610467514047, 0.2507916363598935, 0.07051010862514577, 0.24661039282861077, 0.7539232009331815, 0.2565694845822307, 0.7438359006795765, 0.136835441486034, 0.8619059992453636, 0.05163135722860563, 0.9482297337176611, 0.9244945993897665, 0.07554734260941305, 0.6013368663290114, 0.144951069962277, 0.2536643724339847, 0.49143792302343814, 0.5082502730216084, 0.9988322277375012, 0.9983078699935957, 0.6203490919981951, 0.2937222299866649, 0.08564882159413457, 0.9982970984677169, 0.9970448000073484, 0.3467658622862532, 0.49250803629062057, 0.16081895062550874, 0.9984661495401228, 0.3225834812205613, 0.6777405387207233, 0.9658603980632687, 0.03269065962675679, 0.052732041282152205, 0.9441546439090109, 0.25173070943056736, 0.17896480123579397, 0.569344065469916, 0.1358627041653763, 0.2532749176416274, 0.6113821687441934, 0.9985103233695465, 0.9991919253065283, 0.9983207869523144, 0.997426287873584, 0.9987998846784107, 0.9992730512706436, 0.10002729265340808, 0.12350308582716711, 0.7767425480535056, 0.7743595126710457, 0.18418269738723084, 0.04158964134550373, 0.9961597121585665, 0.9963552928349906, 0.19881296158222092, 0.8007744285950564, 0.002984455517439792, 0.43423827778748975, 0.5633159789167608, 0.9990508901993989, 0.9988065829327221, 0.9962346028234738, 0.998527664002291, 0.9989374237214806, 0.9953137967556249, 0.5025201441253282, 0.1321612611461108, 0.3652363534774302, 0.9971871703427574, 0.9991532401899546, 0.9994069523014855, 0.9975514994744675, 0.7147629891257328, 0.15316349766979986, 0.13191378718227809, 0.6945383001424851, 0.30559685206269344, 0.999338016809773, 0.9961930647703329, 0.9983791622423163, 0.001368017577586943, 0.9986528316384683, 0.9979619392178648, 0.9988702209364111, 0.5497215683292723, 0.4501493597262343, 0.055940179783755095, 0.9432671694571119, 0.9960934672560743, 0.997517454040922, 0.49019132297188417, 0.5096646768981645, 0.9990135631538074, 0.7733537363946583, 0.18869831168029663, 0.038358345325175056, 0.11001595001448679, 0.8899504527957592, 0.6355698458447951, 0.13157910859417657, 0.2332322827427462, 0.9973360046634834, 0.9985978316931259, 0.9042821242634246, 0.09476010284197564, 0.9979479003253897, 0.9987793275282665, 0.9160820249084722, 0.08411437624368276, 0.6574910233081396, 0.25665030423945434, 0.08590985793717647, 0.06840664739410227, 0.9320405707446434, 0.7829496565545708, 0.2019993953959161, 0.01454395646850596, 0.9964789794253147, 0.9985739801429446, 0.0014749984935641723, 0.390701398914015, 0.29647079985853014, 0.3124722223396502, 0.1094872738039842, 0.6255169348004516, 0.26521220108694177, 0.2220957087498879, 0.7773349806246077, 0.9980943751566851, 0.27079956203658784, 0.7286970032984545, 0.9982844419227838, 0.09736964840144485, 0.07341775628130333, 0.8294644379866398, 0.04666811561837339, 0.9525082059544927, 0.9991740981220044, 0.9981552688685962, 0.9981854255008966, 0.9990959540044221, 0.9982297117781695, 0.8840946039178126, 0.11559153146218593, 0.06519381442856328, 0.31158808366592744, 0.6241348998969808, 0.14565274577764534, 0.853375702825435, 0.6440261864264065, 0.3348936169417314, 0.021173463663333912, 0.25269304861427144, 0.541384268958509, 0.2054013328121592, 0.836727930559468, 0.16324971512314096, 0.9968882327423381, 0.9995488113197037, 0.44047416159203845, 0.5596119348226469, 0.0028335271282584383, 0.9974015491469703, 0.998702764111227, 0.9888347354373435, 0.011387732077973245, 0.9982840311031637, 0.9978346358817083, 0.04574499209600849, 0.9538317500869856, 0.6759453099493691, 0.32366432359619424, 0.007558714438714514, 0.9917033343593441, 0.9982044545952012, 0.6267106989828196, 0.3732350355292798, 0.24688238933422238, 0.2562650929668769, 0.4966968735536493, 0.9990566274649392, 0.9968008048631389, 0.015941458296627044, 0.9830565949586676, 0.99952962263187, 0.998573678985806, 0.9982840658999168, 0.4106982641657846, 0.5889352859003244, 0.9987184960701831, 0.1019197643613939, 0.3377042938541708, 0.5603051722355237, 0.2986357226896975, 0.5187710037327743, 0.1827223045987299, 0.1916952647051704, 0.47765490989433185, 0.3307778519309039, 0.9961001508434698, 0.004434715861582342, 0.9955937109252357, 0.03658284895337575, 0.09384296035865952, 0.870035581630284, 0.9983918866542921, 0.9993451609465529, 0.9992797514265963, 0.9980819786826307, 0.9986313986640896, 0.9964358269355981, 0.956282685195598, 0.04327702662928984, 0.4610298995449784, 0.35175276533679367, 0.18702156302296294, 0.9983915714161696, 0.9973973208511813, 0.9974732410498482, 0.9986437957713544, 0.9979704801935169, 0.8629446970775942, 0.1366654497634199, 0.028665798750341063, 0.9701109787615423, 0.30405101348009345, 0.40918553599837254, 0.28677538771417904, 0.9962572826766759, 0.2660319513871724, 0.733927343274159, 0.06010188554404045, 0.7530412718165068, 0.18737646669612612, 0.02709935401060489, 0.9726470844887378, 0.727721044716045, 0.27231769430996117, 0.9991975001706339, 0.9983223129224215, 0.6278666818397848, 0.05703980101413346, 0.314791082288526, 0.4468300701041509, 0.34957398494966063, 0.20355287681629927, 0.9973335790750653, 0.9103277811619592, 0.05665542097948902, 0.03264888666614622, 0.9991952310757664, 0.2482041301972153, 0.24061200386177106, 0.5111545057767357, 0.2930470694366738, 0.4492639156560321, 0.2579263755923936, 0.09533242455021075, 0.9056580332270022, 0.9978794418438258, 0.9985280365548349, 0.9989672594316483, 0.9972078493339629, 0.9981041613727935, 0.5802853335850835, 0.17951749475063658, 0.23979827712077653], \"Term\": [\"accordance\", \"accurate\", \"additionally\", \"adhere\", \"advance\", \"advance\", \"ai\", \"ai\", \"ai\", \"application\", \"application\", \"application\", \"assess\", \"assess\", \"attack\", \"autonomy\", \"bad\", \"base\", \"base\", \"base\", \"bias\", \"bias\", \"bias\", \"biological\", \"capability\", \"capability\", \"capability\", \"card\", \"card\", \"careful\", \"carefully\", \"case\", \"case\", \"case\", \"cbrne\", \"certain\", \"certain\", \"certain\", \"chemical\", \"code\", \"code\", \"code\", \"common\", \"common\", \"complex\", \"complex\", \"concern\", \"concern\", \"conduct\", \"conduct\", \"contain\", \"contain\", \"content\", \"content\", \"content\", \"context\", \"context\", \"cover\", \"cyber\", \"dataset\", \"dataset\", \"dataset\", \"date\", \"de\", \"deploy\", \"deploy\", \"deploy\", \"describe\", \"design\", \"design\", \"determine\", \"determine\", \"develop\", \"develop\", \"developer\", \"developer\", \"developer\", \"development\", \"development\", \"development\", \"domain\", \"e\", \"education\", \"effectively\", \"embed\", \"enable\", \"encourage\", \"encourage\", \"encourage\", \"english\", \"english\", \"english\", \"essential\", \"establish\", \"ethical\", \"ethical\", \"evaluation\", \"evaluation\", \"evaluation\", \"example\", \"exhibit\", \"exploration\", \"expression\", \"factually\", \"figurative\", \"fine\", \"fine\", \"fine\", \"foreseeable\", \"g\", \"gemma\", \"generally\", \"generate\", \"generate\", \"generate\", \"generation\", \"generation\", \"generative\", \"grasp\", \"group\", \"guide\", \"guide\", \"guideline\", \"hallucination\", \"harmful\", \"harmful\", \"help\", \"help\", \"helpfulness\", \"hub\", \"image\", \"image\", \"inappropriate\", \"include\", \"include\", \"include\", \"influence\", \"influence\", \"information\", \"information\", \"information\", \"inherently\", \"instance\", \"intend\", \"intend\", \"interest\", \"issue\", \"know\", \"know\", \"language\", \"language\", \"language\", \"learn\", \"learn\", \"like\", \"like\", \"like\", \"likely\", \"limit\", \"limit\", \"limitation\", \"limitation\", \"limitation\", \"llm\", \"llm\", \"llm\", \"malicious\", \"malicious\", \"man\", \"mechanism\", \"mechanism\", \"meet\", \"misuse\", \"misuse\", \"misuse\", \"new\", \"new\", \"non\", \"nuance\", \"nvidia\", \"objectionable\", \"objective\", \"offensive\", \"offensive\", \"open\", \"open\", \"open\", \"outline\", \"outline\", \"output\", \"output\", \"output\", \"perform\", \"perform\", \"perform\", \"performance\", \"performance\", \"phi\", \"policy\", \"potential\", \"potential\", \"power\", \"power\", \"prediction\", \"present\", \"present\", \"preserve\", \"primarily\", \"privacy\", \"privacy\", \"produce\", \"produce\", \"product\", \"product\", \"prohibit\", \"prompt\", \"prompt\", \"provide\", \"provide\", \"provide\", \"python\", \"raise\", \"raw\", \"raw\", \"reason\", \"report\", \"representation\", \"response\", \"response\", \"responsibility\", \"responsible\", \"responsible\", \"responsible\", \"risk\", \"risk\", \"risk\", \"safety\", \"safety\", \"safety\", \"sarcasm\", \"scale\", \"scale\", \"security\", \"security\", \"security\", \"sense\", \"sequence\", \"serve\", \"set\", \"share\", \"situation\", \"source\", \"source\", \"specific\", \"specific\", \"specific\", \"speech\", \"standard\", \"statistical\", \"stereotype\", \"subtle\", \"system\", \"system\", \"tailor\", \"tailor\", \"task\", \"task\", \"task\", \"teaming\", \"technique\", \"technique\", \"technology\", \"technology\", \"technology\", \"testing\", \"testing\", \"text\", \"text\", \"token\", \"toolkit\", \"train\", \"train\", \"train\", \"training\", \"training\", \"training\", \"trustworthy\", \"tune\", \"tune\", \"tune\", \"uplift\", \"use\", \"use\", \"use\", \"user\", \"user\", \"user\", \"value\", \"value\", \"verify\", \"vlm\", \"vulnerability\", \"weakness\", \"weapon\", \"work\", \"work\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1802817329381520168548228869\", ldavis_el1802817329381520168548228869_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1802817329381520168548228869\", ldavis_el1802817329381520168548228869_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1802817329381520168548228869\", ldavis_el1802817329381520168548228869_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis_data = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c8e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAGGCAYAAADmRxfNAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUxlJREFUeJzt3Qd4lFX6/vGThBJaQolLEcUGKCjFjr3XxbKubVkXe197b1hWRXfX3nUtq66uuuLacO1dsVEUXIgNURANAgHpyfu/7vPfd36TmITEN/PMycz3c11DSGYy8849k5nznDYFURRFDgAAAAASKEzyywAAAAAgFBYAAAAAEqOwAAAAAJAYhQUAAACAxCgsAAAAACRGYQEAAAAgMQoLAAAAAIlRWAAAAABIrFXyqwCA5lVdXe1mzpzpOnXq5AoKCrJ9OAAA5K0oityCBQtcr169XGFhw2MSFBYAgqOiYrXVVsv2YQAAgP+ZMWOG6927t2sIhQWA4GikQr766ivXpUuXbB9OTquqqnKTJk1ygwYNckVFRdk+nJxH3rbI2w5Z27LMu7Ky0nf2xe/NDaGwABCcePpTSUmJPyGzb04dO3b0OdMYyDzytkXedsjaVjbybszUZBZvAwgW6ytsMi4rKyNrI+Rti7ztkLWtUPMuiLQiAwAComHX0tJSN3/+fEYsAABoIe/JjFgACHp3KGQ+4+nTp5O1EfK2Rd52yNpWqHlTWAAIFgOqNhlXVFSQtRHytkXedsjaVqh5U1gAAAAASIzCAgAAAEBiFBYAghXabhe5mnHPnj3J2gh52yJvO2RtK9S82RUKQHDYFQoAgDCwKxSAnBDabhe5mnF5eTlZGyFvW+Rth6xthZo3hQWAYDGgapOxeqPI2gZ52yJvO2RtK9S8KSwAAAAAJEZhAQAAACCxVsmvAgAyY+OBA11hIf0fmVZSWuoq5893LU33nj3dm++/71oSPZ/79OnD89oIedsha1uh5k1hASBYtw7Z2HVo3Trbh4FAHfrhONfSaGvIsrKybB9G3iBvO2RtK9S8wypzACBNWHtd5G7GszuXkrWRqqoqN3nyZP8VmUfedsjaVqh5U1gACFdgH/yTkwoK3PKiIrI2tGTJkmwfQl4hbztkbSvEvCksAAAAACRGYQEAAAAgMQoLAMEqCOyDf3I147LKBWRtRDu49O3bN7idXHIVedsha1uh5s2uUACCxax/m4yLly/P9mHk1U4uJSUl2T6MvEHedsjaVqh5h1XmAECaahYUm2Q8s2sXsjaiHVzGjx8f3E4uuYq87ZC1rVDzprAAgDxHUWGruprNfS2Rtx2ythVi3hQWAAAAABKjsAAAAACQGIUFgGCxU5FNxt3nzSdrI9rBZcCAAcHt5JKryNsOWdsKNe+wjgYA0jDz3ybjoupqsjbcyaVNmzb+KzKPvO2Qta1Q86awABAsFhVnHrtC2dIOLhMmTAhuJ5dcRd52yNpWqHlTWAAAAABIjMICAAAAQGIUFgAAAAASo7AAEKxCdioyybjXj3PJ2khRUZEbMmSI/4rMI287ZG0r1LwpLAAEi6auTcZVhYVkbSSKIrds2TL/FZlH3nbI2laoeVNYAAhWxE5FJhnP7lxK1kaqq6vdlClT/FdkHnnbIWtboeZNYQEAAAAgMQoLAAAAAIlRWABAnmPhtq3CQt56LZG3HbK2FWLerbJ9AABQHxq8drtCwYZ2cBk6dGi2DyNvkLcdsrYVat7hlToA8D+UFTYZL2ndmqyNaAeXysrK4HZyyVXkbYesbYWaN4VFAl999ZUrKChwEyZMaNbLZtqrr77qj2XevHkZv62LL77Yde/e3d/eE0884fLRGmus4a677roGL5PtfLbbbjt3yimnuNCwU5FNxhUlncjaiHZwKS8vD24nl1xF3nbI2laoeVNY1OPQQw/1jT2dWrdu7dZcc0131llnuSVLlqQus9pqq7lZs2a59ddf3+WaiRMnur322sv96le/csXFxb5xfOCBB7rvv/++0dfx6aefuksuucTdfvvtPqfdd9/dvAAbP36823///X1xo/vRt29fd9RRR7lp06Y5K++//747+uijXQjqKyoff/xxd9lll2XtuICkTjrpJP86Vd/rxz333POzAl5/m1tuuaUbPHiw/6Cpl19+OXWe3rC33357//N1113XnX766cG9gQNAaCgsGrDbbrv5BvEXX3zhrr32Wt9AHjVqVI35bT169HCtWuXWUpUffvjB7bjjjq5r167uP//5jy8Q9Kbcq1cv99NPPzX6ej7//HP/de+99/Y5tW3b1ll6+umn3eabb+6WLl3qHnzwQX8/HnjgAVdaWuouvPBCs+NYZZVVXPv27TN6G/qQnCT0WHfq1KnZjgew9tvf/ta9+eabrk+fPnV2WNx5553+9SCm6QP77ruv7/xQR8ojjzziO5QWL17szz/zzDP9+SpSdHr++efdc889Z3qfAKClobBogBrCahBrZGKfffZxO+20k3vhhRfq7V2fO3euGzFihG9ItmvXzveOq0Fel6qqKnf44Yf7nrCvv/66zsuoN23nnXd2ZWVlvjG87bbbuo8++qjGZXT7d911l38DVONVt/nkk0/WuMyzzz7r+vXr549JPXA67oa89dZbbv78+f56tTBIozX6PRVX+n98/EcccYT/Xtfbv39/d/3119eYAjV8+PDUrgU6zpiud7311vMjCLr/t9xyS+q8+Pp1u/odTdF5/fXX/ajRd999V+M4NXVn6623rvM+LFq0yB122GFujz328HnosdN1b7bZZu4vf/mLLxJjr732mtt00039492zZ093zjnnuBUrVqTO1zGoN1QjVmqA6zmh+5feQNH3q6++ur8OFWC6fH1TodQTus022/j7P2DAgBrPqdiMGTPcAQcc4Dp37uxvU8VZ+uOmBpCek5dffrm/PeUv999/v9t44419kaDj/N3vfpcaZdLv63GULl26+Hx1PXVNhdJz+Q9/+IO/nJ5XGm3Sccfuvfdef2wqPPVYduzYMVWIp4+OKNcOHTr4y6pnePr06a5JAps7mpOiyLWuqmrxWetvqnfv3j/7uUYZjjzySHfjjTfW6NyYM2eO70TRa4PoNVLP07Fjx/rv9feh10FRsbF8+XL/+tAc9LcPO+Rth6xthZg3hUUjffLJJ+7tt992bdq0qfcy6gXXpyDqjUm947feeqsvCmpTD7qm56ggeeONN3yDtC4LFixwI0eO9L1w7777ri8a1FDWz9Opx02N0EmTJvnzVdz8+OOPqQbqb37zG9/I1+3pDVYN54aoQaqG9ZgxY+pdFKQ3a72JP/roo/4+X3TRRe68887zvX5yxhlnpIoqNTbjBqdGDnRZNYiV0RVXXOFzu++++/z57733nv/64osv+t/RFB01GNZaay3faI7pTV7XpeKsLmrwVlRU+GKgLmpAyLfffusz22STTXyvpR6zv/3tb+5Pf/pTjcvr+NRAHjdunLv66qvdpZdemioI/vWvf6VGtNT41lSLDTbYoN7c9HjoeaTruu2229zZZ59d4zK6b7vuuqsvDvT8UKEXN9zTRyZeeuklN3XqVH8cGp2Jf1dTmnRfdBwqJuLiQQWyjlX0e8o3vRhMp9/54IMPfFH2zjvv+OeBctL1pxdvKtL0uKj4U4Gsx130/FHho2JYz0tdh6aDpReYjcELVOYp4+7z5uds1tdcc40vajfaaKMaP9drswqF+DVLHTn6u4gLeHUG6PVNhbtOKrSbYwcWjXQPHDjQf0XmkbcdsrYVat65NYenmamxpgadGkkqBtTzftNNN9V7eTWs9MajHuO4p7q2hQsXuj333NNf3yuvvOJHIuqzww471Pj+jjvu8A1i9bD/+te/rtEIPPjgg/3/1VC/4YYbfANdDVE1lNdee23317/+1Z+vnu2PP/7YXXXVVfXerqYLqEhQb/exxx7re511LHpj1VoF0QiCCpqYRgPUeNSbtIoc5RY33lWoxDSVTMeixnX8eypM1ChXEaXRHunWrVuN39PoiAoVTU+Qp556yq930W3VJe5d14hIQzRaoga3Hlc1enX5mTNn+sa+CqB4j+hBgwalpsGpwNPl1bDXiJIedx2rej6ViwpFZVYXFUz//e9/feGjxkr8mKWvP/nnP//pCxCN7MQNcd135alRgF122cX/TIWOLpNe7KYXWirG9FxQ0aTnnR4TjX6I1s7Ej09d2amgUEGzxRZb+J+piFNOKlZUFIuKDBVGen7JiSee6Asu0U4V6u3V8zQ+XyMb9dHfg04x/b607D70lkEZL2rb1rVfutQV5GCHkIppFb51+fe//+3/1q+88kr/Br3VVlulprbqtUGvq+eee64f9dNon/6W9DefhIp0jZboNa6phTaajrztkLWtUPPO1U6qZqE3EvXyq2dZjV5Nrdlvv/3qvfxxxx3nHn74Yb/YTz3lGuGoTW9UWqeg+boNFRUye/Zsv9BYDVldtqSkxDcQa0+dUqM3psamLhdPf9GogKb/pBs2bNhK77tGFDT1SA1HveHqqxrdKkpiN998s+8FVDGgRqsKn/qmdYnut9ZdqEjQ5eOTRgfi9Rj1UfH02Wef+ZGbeCqOigrd37o0dvs15aM80v8o1bupnL/55ps6Mxb1dMYZq6GtqRJqyOvx0khP+lSq2renBnpcVNT1eGi0QfdVIxZxRioIVEil56RRkdojaB9++KEfnVJxo9/XiIE09LjUdYxqXKU/b/TCpaJU58U0RSouGmpnouPVY6aRFx2PRkbSp0nVpoadnuPxSRkJOxVlnjKe27FDTmatET+NQOg1VB09ev3QyJk6XESLtrVuQps8aP2VOhX0ehe/vul1Py7ENWKnwj4pdRpoSiALwW2Qtx2ythVq3hQWDVCjdZ111vFvPnfffbcvMDRNpj7qddaDfOqpp/o3KC2AjqeGxPTmFE8NWRm9qamwUaNMRYr+rwZe7YW66iVPp0ZyczzRdFtqNGu6ixqUagzr/6ICSvdNRYKKJB2bCq+GFhGrsS5aRBkviNRJvYpxwVAfvbGrgaqeexVcmm5W3zSoeL60aHSgOTSUsRrBmkKhHk6tNzn++OP99K30aUNNoZxUsKVnpJN2stIoUqx2UaXCTQ15FZYaYdDUDhU5zbG4u7GZpBd0eqz0PNeoh0Zh9JjU9zirV1gjHPFJU/iApNTZo4JWxYVOGo1VB4h+LunFrl6X9DcVjxSroyBerK2/LY0w5+IOgADQnCgsGklTYjQ96IILLkjtGlIX9d6rIFDvl+bo6k0snd7QRo8e7bdy1ZSmhmgqihYBqxhRL5oWHmrdQFNo+km8biG2skZ8XdQzrt7peFeoeJqMGtGa/qUCbGWjDppGpeJEu2zp8umneNF23AOvxeG1aX2IGqjKVMeikYX6aLqQ5lBrPURd4u1WlU+8hiCm+6be/roWgtZHBYUKH009Uq+mrjN9dCem21OjOb1BU/vx2HDDDf10JBVTtXNqaJRLRZSGRfX80qJ2jTDV3h64oXzTj1EjLiqkY7peFU9abN4Uem6oaFBhrEbZP/7xjzovp+e2CqL0E9AUxxxzjP+b1UijCmz9vayMXktU8GpEQ9MrVYjHo5daV6WOJHUsaXqrOooOOuggg3sCAC0XhUUTqPdei2Q0RF4XzcnXnF1NY5k8ebJfo1HXvPI//vGPfvqP5p9rYXZ99GanhbEaLVAjT4uy1YBtCq2RUCNVaxPUMFTDTtOIGqLj/v3vf++/qpdcv6eRCu0upd2J4mPT4l6tFdBltABbPeQro3UZmvaiBrh+T41v9WxrgaWoMa37qJ5CjUzEu7JI3Buv7DQ60pB4/cEzzzzjizitbVCPpY5Z09SUi6gwUkNfj4ka5nr8tJbitNNOS62vWBnlqQaIRl5UNKmo1H2oa9tLrcNQQ0bFp6Y8aarG+eefX+MyepxVFClrnf/ll1/6YkVFZvr0rNo0/UmFg3a/0XFonUTtz6bQManhpMdWO+LEo0jp9NjqtjWtS89PHaeeD6uuumrq8V8ZHbMKChVYGsXTqJaehw2ts6hTC9+pqEWIIles0bUWnrXWaenvQ0WxXjv0Olyb/o60qUBMf+t6HYrXFcVT8OKiWJ0Mev7rNVjr0ppjHrOuQ69jIc2JzmXkbYesbYWaN4VFE2jeuRaoqhe8rs9zUKNOjSnNx9dUGBUhmjJUF23tqUa2RiPqWoshaqxq20/1YB9yyCG+YamGd1OosanFi1p0q543rZXQYuGGqFda8+f1gVBaL6LpA1qUrYa6jiPuHdQCbH1onubiq0dbjfSV0aiDrkfFhNYIaA2AGubxiIUyVtGhRoJGN9Ibsmroa96+etu1kHxl9LvKVlN2NIVIPfha46JiJd71SY1lFUwa1VE+Kjg0vUsjU42lRdCaRqERFD32KmLU+6mpZLXpPqhXVKNeWuCtPLSeJZ2y12JTPXbKWI1xHZPWWDTUk6/RMmWpnWz0GGrkIp66FtP91fNOO4NpBEnP57ro8dF0LBW/WgOiER3lVHv6U310H1SoaU2SCinNaz/hhBP886YpeIHKPGVcVrmArI3oNUDFe2M7LpAMedsha1uh5l0QNXaVKxAANbDV0177szqQW7QrlKZ9Pbf7cNexkcUMfhm9ASxo1851Wry4xe0KdeiH41x5A6N4IdLaLG2MoZ3kQmsQ5CLytkPWtizzjt+T1TG7sqnKPPJoEfRk1rQcTeXStCXkh1zcqSjEjCvbtyNrI+rL0xor+vRskLcdsrYVat58jgVaBE1r0nQlTVVKuo88AAAAmh+FBVqE5tg/HgAAAJnDVCgA4QpsiDcnRZHroE89J2sT2sFFu76FtpNLriJvO2RtK9S8GbEAECx6Pmwy7rLw57vcITO0yLKuraiRGeRth6xthZo379sAgpX88+PRmIznduxA1oY7ueizXfQVmUfedsjaVqh5U1gACFdgQ7w5qaDA/dS2LVkb0Q4uFRUVwe3kkqvI2w5Z2wo1bwoLAAAAAIlRWAAAAABIjMICQLAKAhvizUXKuGTRYrI2oh1cevbsGdxOLrmKvO2Qta1Q82ZXKADBCuvlMnczLlm8ONuHkVc7ufTq1Svbh5E3yNsOWdsKNW9GLAAEK6y9LnI344qSTmRtRDu4lJeXB7eTS64ibztkbSvUvCksAIQrsCHenFRQ4Ja0bk3WRrSDS2VlZXA7ueQq8rZD1rZCzZvCAgAAAEBiFBYAAAAAEqOwABAsdiqyybjLwp/I2nDBZZ8+ffxXZB552yFrW6Hmza5QAILFrH+bjDssXZrtw8gb2hqyrKws24eRN8jbDlnbCjXvsMocAEgT1l4XuZvx7M6lZG2kqqrKTZ482X9F5pG3HbK2FWreFBYAwsVORZlXUOCWFxWRtaElS5Zk+xDyCnnbIWtbIeZNYQEAAAAgMQoLAAAAAIlRWAAIFjsV2WRcVrmArI1oB5e+ffsGt5NLriJvO2RtK9S82RUKQLCY9W+TcfHy5dk+jLzayaWkpCTbh5E3yNsOWdsKNe+wyhwASFPNgmKTjGd27ULWRrSDy/jx44PbySVXkbcdsrYVat4UFgCQ5ygqbFVXs7mvJfK2Q9a2QsybwgIAAABAYqyxABCsEyd+yDqLDNPCv7X69XNfTJsWZO9XQ7r37JntQwAApCmIIrYCARCWyspKV1pa6ubNm+e/InP0FqAPWSouLvaLAZFZ5G2LvO2QtS3LvOP35Pnz5690wThToQAEizcnm4zbtGlD1kbI2xZ52yFrW6HmTWEBIFih7XaRqxlPmDCBrI2Qty3ytkPWtkLNm8ICAAAAQGIUFgAAAAASo7AAAAAAkBi7QgEITlN2oEBymqNbVFSU7cPIG+Rti7ztkHVu5s2uUAByAv0eNhkvW7aMrI2Qty3ytkPWtkLNm8ICQLBa2ge2tdSMp0yZQtZGyNsWedsha1uh5k1hAQAAACAxCgsAAAAAiVFYAECeKyzkrcASedsibztkbSvEvNkVCkBw2BUKAIAwsCsUgJxAv4dNxnrTIGsb5G2LvO2Qta1Q86awABCs0Ha7yNWMy8vLydoIedsibztkbSvUvCksAAAAACRGYQEAAAAgMQoLAMhzxcXF2T6EvELetsjbDlnbCjFvdoUCEBx2hQIAIAzsCgUgJ9DvYZNxRUUFWRshb1vkbYesbYWaN4UFgGCFtttFrmY8ffp0sjZC3rbI2w5Z2wo1bwoLAAAAAIlRWAAAAABIjMICQLAKCgqyfQh5kbEW45G1DfK2Rd52yNpWqHmzKxSA4LArFAAAYWBXKAA5IbRFabma8cyZM8naCHnbIm87ZG0r1LwpLAAEiwFVm4xnzZpF1kbI2xZ52yFrW6HmTWEBAAAAIDEKCwAAAACJUVgACFZou13kasZlZWVkbYS8bZG3HbK2FWre7AoFIDjsCgUAQBjYFQpATghtt4tczXj69OlkbYS8bZG3HbK2FWreFBYAgsWAqk3GFRUVZG2EvG2Rtx2ythVq3hQWAAAAABKjsAAAAACQGIUFgGCFtttFrmbcs2dPsjZC3rbI2w5Z2wo1b3aFAhAcdoUCACAM7AoFICeEtttFrmZcXl5O1kbI2xZ52yFrW6HmTWEBIFgMqNpkrN4osrZB3rbI2w5Z2wo1bwoLAAAAAIlRWAAAAABIjMICQLAKC3mJssi4T58+ZG2EvG2Rtx2ythVq3q2yfQAAUJ/QttHL1YzLysqyfRh5g7xtkbcdsrYVat5hlTkAkKaqqirbh5AXGU+ePJmsjZC3LfK2Q9a2Qs2bwgIA8tySJUuyfQh5hbxtkbcdsrYVYt4UFgAAAAASo7AAAAAAkBiFBYBghbbbRa5m3LdvX7I2Qt62yNsOWdsKNW92hQIQLHaFssm4pKQk24eRN8jbFnnbIWtboeYdVpkDAGlC2+0iVzMeP348WRshb1vkbYesbYWaN4UFAOS56urqbB9CXiFvW+Rth6xthZg3U6EABGuDjQdn+xBynubn9lu7r5v2eXmQb1K5hrxtkbcdsk6mZ4+e7v23xrmWjsICQLA2PX9n16pDm2wfRk4riJzrPL+d61a6jotY0pJx5G2LvO2QdTJvn/eMywVMhQIQrCjbB5AnGc/vtISsjZC3LfK2Q9a2NEI0YMCA4HaFCutoACAdvV6ZV+BcVBiRtRXytkXedsjafFeoNm3aBLd7IoUFgKCH1mEzfYGsbZC3LfK2Q9a2tBvUhAkT2BUKAAAAQO6hsAAAAACQGIUFAAAAgMQoLAAEiy0LbTKeV7qYrI2Qty3ytkPWtoqKityQIUP815BQWAAIF4sAM0+buFRrO5dsH0ieIG9b5G2HrE1FUeSWLVvmv4aEwgJAsOj4ssm4dEExWRshb1vkbYesbenTzadMmRLcp5xTWAAAAABIjMICAAAAQGIUFgCQ58KaoZv7yNsWedsha1uFheE141tl+wAAoD7sLmK0k0vnxdk+jLxB3rbI2w5Z29JuUEOHDnWhCa/UAYAY3V+ZFznXankhWVshb1vkbYesTWk3qMrKSnaFAoDGYsDCJuNOP7UlayPkbYu87ZC1Le0GVV5ezq5QAAAAAHIPhQUAAACAxCgsAAQrrJmjuZtxVWE1WRshb1vkbYes7RUXF7vQsCsUgHAxWTfzCpyrLFma7aPIH+Rti7ztkLX5rlADBw50oWHEAkC46PrKvMi5NkuLyNoKedsibztkbUq7QVVUVLArFAA0FgMWNhl3WNyGrI2Qty3ytkPWtrQb1PTp09kVCgAAAEDuobAAAAAAkBiFBYBghTVzNHczXt6qiqyNkLct8rZD1rYKCgpcSUmJ/xoSdoUCEK6wXi9zU4FzCzsuy/ZR5A/ytkXedsjaVGFhoevbt6/L+RGLr776yldPEyZMcC3Ndttt50455ZSMXHdLzWWNNdZw1113XbYPIyfp+fDEE09k+zDCRtdX5kXOFS9pRdZWyNsWedsh64y45557arQX3nvvPbf55pu7oUOH+sLiqquuqnH5W265xa233npugw02cIMHD3ZLlizxP993333dkCFDUicVJk8++WR2C4tDDz3U37n41K1bN7fbbru5SZMmpS6z2mqruVmzZrn111/f5Zp77723xv2PT3fddddKf7el5vL++++7o48+OvH1fPbZZ+7www93q6++umvbtq1bddVV3Y477ugefPBBt2LFCtdSWBcD3333nfvjH//o1lprLZ+bnkfDhw93L730UospqpNkxoBF5injdktak7UR8rZF3nbIuvmpU/rOO+/0hURMbbLzzjvPffDBB+722293f/3rX92UKVP8ef/+9799u+rdd991H3/8sXvxxRdd69at/Xljxozxnds6qd3atWtX34bP+lQoHYSqp7jRc8EFF7hf//rX7uuvv059YEePHj1crtJ8tqlTp9b4WWlp6Up/b2W5aB/iqqoq16pVWLPTVllllcTXoep6p5128h/kcvPNN7t1113X/1x/FPpexZaq6mxR7mr8qnoP7QVlyy23dJ07d3Z//vOffe/D8uXL3X/+8x93wgknuP/+97/ZPkQAAJAB1dXV7sgjj3Q33nijO/3001M/V3tl3rx5/v+LFy92bdq08UWCqK0watSoVLu0vjbc3/72N/f73//e/25za3JLSr2maiDrpKGUc845x82YMcP98MMPdU75UaPtiCOOcGuuuaZr166d69+/v7v++utrXOerr77qNt10U9ehQwffiFJjSnvz1ufss892/fr1c+3bt/c9uRdeeKFvcMUuvvhif2z333+/n8qjgA866CC3YMGC1GV++ukn94c//MF17NjR9ezZ01d8jaH7Ft//+KT79dxzz7mtttrKH79GclRsff7556nfq52L7rO+Hzt2rNtoo418rm+++abvOT7ppJPcWWed5Z8oun7dn3R6QunJpieMCp0ddtjBTZw4MXW+/r/99tu7Tp06+fN1/WrEi3JVj3eXLl183mrsP/vss42eChWP0GhITflrGK6hoTQVTBrp0uP11ltv+dvW7+h08MEH+/s8aNCg1OX1XDrggAN8jrr/e++9t88upuvaZ5993F/+8hf/uClrNbLTH/+lS5e6M844w4+K6D5uttlmPu/0kSddv457wIABPnsVxhqd2XnnnV1ZWZl/zmy77bbuo48+qpGF6L4rh/j7uJdgww03dMXFxf45eckll9QYiSkvL3fbbLONP1+3+cILL7iVOf744/3tqDDbb7/9fIZ6vE477TTfGxHTsSsnPZf1eCu/2bNnN/rvQZm+9tpr/u8yHoWLM//kk0/c7rvv7q+7e/fu7pBDDvEfyBNb2fO1ocwAAEDdrrnmGt8eVhsunTr31e5Vu1ptgz/96U+pjmuNXKi9p9/beOON3Q033PCz61Ux8tBDD/m2eSYk6qJduHChe+CBB9w666zjG3j1VVy9e/d2jz76qL/DF110kR/CeeSRR/z5anypoahGnKZUvfPOO36Yp6FV7mowq3Go61NjSMNE1157bY3LqFGv6RdPP/20P6nhNHr06NT5Z555pv+ZGoTPP/+8b3imNyKbSoWKGnx6QDVNRb3fakyt7INLVJjpuD799NNUA/u+++7zDeJx48a5q6++2l166aU1GqL777+/+/77731R8uGHH/oGraYV/fjjj/78ESNG+MzVUNb5uo14KEyNcDW8X3/9dT9Mprl5ajQ2hRrNarzq8dpjjz387cW3XZsKKd03NfTrGxGIH2sVB7vuuqt/fN944w1fiOjYNEq2bNn/LQh75ZVX/OOrr8pKzwWdYieeeKJ/Hj388MP+GJWXrkON+9iiRYv8fVeRNHnyZPerX/3KN7RHjhzpix013FX86P7FDXDlGf9Ra1pb/L2OVUXqySef7J+TGprU8Vx++eX+fD0HfvOb3/ieAT2mt912my+OG6I8Vazq8dJzoTYVRvF1q6jQ5fV81vPkiy++cAceeGCj/x70NzRs2DB31FFH+fulk6ZcqYBV0ap5nHpe63hUsOixT9fQ87W+zGrTc7KysrLGSZiqm3nKeGmbFWRthLxtkbcdsm4+6tT717/+5WcF1ab37iuvvNJ3AOq9VkVGPBVKbeovv/zSt/H0nq32iN7z0z322GO+o1KzIDKhyfNudIBxQ1SNafUa62f1NRrVoFVDNKYKS40+FRZqoKgBMX/+fN/Dv/baa/vLaNFJQ9KDVg+oGq1qRKrXNKYGlxp3aqSKelrV4FdjTwWRhoFUFKlBHjeO1BhfGR1rekNc/9eUMFWN6e6++24/oqAHu6F1FWqEqZc8nQoMDWWJGrc33XSTP3ZdTo1e9WCrsFBPu6j3Xo1GPVlUlKkHW4VTPOUofdcAnadjjZ9Q6l1vKvVwa7RBrrjiCl8R65jqmqs3bdo0/1UjVTEde/rtqjGq3vl//vOf/nFTYz8uNtQgVSNahd8uu+zif6bRFmWi6WW6j3vuuafPRw1j3T/9jr726tXLX17PD/2B6ec63riI0QKn9ClYakSnu+OOO/xtqxGu52c8pKifpU9r0/NbxZuKkjjTyy67zD8f9ThqjqOmLWkKU3xMOg6NBDS0JkWjPfFjWB/dbxWIeiFRMSB///vf/ciGGvGbbLLJSv8eNIKhokcjUOn3SxmrqIgzi5/Xuh09rnphWtnztb7MatOLZPrrRAqTdTOvwLlF7f9vxA8ZRt62yNsOWTcbdViqcIjbb2pnqn2n93utlVCbV7beemu//kIdsZoNoXWsap+pfaTZF+ocVUep2jAxtX8zNVrxi0YsNMUmXvyhxqR6mNVAamjqkubRayhHjQw1xNVgi9dkaPqEGqq6Hk2TUe+pejYbogaohnnUUNH1qdCIry+94IgbUaICSA3auPdWPeCaIhPTcaQ3fuuj64zvv05vv/22/7l6w/VgqlGp6SjxlI/ax1WbhqpqS58aVPvYNc1JhZFGiHTf45MalvHUK42caKqU1jWosk2fkqVpKxo2U35qDKYvvG+s9ONTT7Xub3x8jaFjj/NTgzMejdB9U4NaGcf3S4+LdjRIvw9qNOuPpq589Een6Xdq9Kbno+Ig/TrUkK6ds3rjVZzoD1mNbd0vZb2yx1DHrQIx/fbi3n+NjGjERo3xuKgQjRA0REVFY8TXHRcVohcX5arzGvP30ND90qhQ+v2KC530LBt6vjbWueee64v2+KQpcR5dX5kXOdd+UWuytkLetsjbDlk3m+OOO863IVRc6KTiQW1nzfhRu+vll1/2HYbjx4/3swXiDuzf/e53viM1nvKkTtn0DlS1sTQDIe4cDmLEQndIU59i6l1WI0zTkdRgrU1VlXqMtYZBjSk1brS4REHE1JOsBq/CUNGgQkHDO+mr4GMa7dDUG/VuqhjRbes2aq+RiKf+xNQDvrJpSY2hkZn0+x9TUdSnTx+fgxqQui090OlTeOpS1zSXho5dDV013NLXDNSeHqM57npyPfPMM366lAoIZaSpWSo4lJvO0xQw9RQrO+081FhNyTautrXgXb3foqIgzjB9sbrumwpQ7WhQW/oCpJXlo+vXFLD04kPSR5q0Lqb2dDuNOMyZM8cXt3osNSKk5+zKHkPdpp6Pmu5Um9ZU/BLKTcfXXAu0f8nfg+6Xnte1t7ITPQeTXHdtyjoegatxXU26FvwSyrjtslZucbvltAcMkLct8rZD1pmndo1m/GhWiqY9aaq22s9xZ6U6lo855hjfwaj3Ys1Q0XTw9FkH+pk6TjMl8RZE8W46qozqouGZLbbYwk91iaX3dsbU6NRJPZcK6B//+EedhYVGCNToO//881M/a2i0pC6acqXGkIobDRvJ3Llz/fQOrfVoKjVG1XBWUaFhKdGUpUzQegoNialB3tBCWPXY63Tqqaf6ylTFmwoLUe/2scce60/KW8fdlMKiKfSYqpdb07U09a2hnZd031RYar3DL33S6/Y0YqEe8/ixaCw9VzU9SkOHol7z9IXKoueNrr/2cevxr6vgjKf26brU+xA3yNMXX9dFIzUqADXapxeN2gWo1j+okIyvW6d41ELT73S+XlgaSyM4dd0vzfHU8yzJbmV1ZQYAABonvTNZs1HUear3Vc380OYs6Z2Zmtpfn/SpzcFMhdIiSzVsddJUCzVI457N+npeNeyi+eVquGuRSfoCTk3hUeNWIxEqENSLrmlF9a2z0PVpaop64FWgaH6/5ps1hXquNb9MFZ+Gk7RIRtOxful2o5rzr+k9GqbSMJOuU1VjJugJpcJLC96VlYbIVGyp0FLOKvC0eFlPQuWpxrLyjvPUZxXosVDuWqyuqS4rW9OStPBUUaOGt6ZfaScmPb5q/GoRs3YTi0cWNBKlOYFajKz5hTpG3Q81rL/55ptG3Z6KKV2PFlM//vjj/jo0ZU8jMxqlaYieW9o5Sc9rFZ26Ho1spFMjW+sH9PxXMSrakEDrGjRqoYXg+n09P+O1QHrMdFwaEdH0It239MK4Pioq9MKhHdPUwFduum495+PeCV231svoWPV46r7qvqtArmuaXX10v3Sf9XxSMaURBy0c16JwFaZ6DunvTc+dww47rEmFQl2ZAQCA3NPklrSmK6nXVSetUVCDQzs+advJumhIRlNEtEuNLq/e/fTRCy0Y1XSPeDtNLU5Rg0a/V5e99trL98Kr8awqTY1qFStNpelY6tFWQaTGmbaKrb2lV2OpIFFDUhWkpj/p+HT9mWqoa3tYbV2qBp4y09ahKiK0Haga6cpYjUudp1ECrYGJF8aqQah8VUxosbUuo176TNLIk7LRGhbdtnrSNYql7c60m5fmEsbPBe1koFEkPWd0jCoAtcaiKSMYKmR0/7Xvs25TRZiep/HoVH20oEkNX/XUa3GzChqNnqTTtDFN09PoQDy1SyML2sBAhZ4WS+v+6n5pZC1+fqj4VdGnIkHT0eIdoxqi9ToqFrSuSfdFzy0tiFYj/dZbb009H7SzmYpbPSf0XNbvaeSnKTRdUc8dPTaadhYvfldhqueMFs6rgFFhqpGSphThdWXWWAynZ54yXlzM1AUr5G2LvO2QtS29/6st3tAuqtlQEDV2lSgAGNFucVo/tc/dh7vW7Zv/A3wAAAjJ2+c94775vOHNYrL9nqzNVVbW0RvWRw0DQDq6PTIvcq7jwjZkbYW8bZG3HbI2pSnLmiLdHBsTNScKCwDBCmuAN3czbr2iiKyNkLct8rZD1rY04UgjCaFNPKKwAAAAAJAYhQUAAACAxCgsAAQrrAHe3M34p3bLyNoIedsibztkbUu7M2r3yV/6UQnBfkAeAGQMk3Uzr8C5ZW35AEMz5G2LvO2QtSltM6vP/gpNWGUOAKSj6yvzIudKKtuStRXytkXedsjalD5jSh/K25QPrLVAYQEgWAxY2GRcVF1I1kbI2xZ52yFre/oA4dBQWAAAAABIjMICAAAAQGIUFgCCxVRdm4wXdFhK1kbI2xZ52yFrW9oNqm/fvuwKBQCNxmTdzCtwbkXr6mwfRf4gb1vkbYeszXeFKikpcaEJq8wBgDQFdH2ZZNx5XjuyNkLetsjbDlnb0m5Q48ePZ1coAEBYGBiyRd62yNsOWduqrg5vhIjCAgAAAEBiFBYAAAAAEqOwABAspuraZDy/0xKyNkLetsjbDlnb0m5QAwYMCG5XqLCOBgDSMWE38wqciwojsrZC3rbI2w5Zm+8K1aZNG/81JBQWAILF7iJGO7nMZycXK+Rti7ztkLUt7QY1YcIEdoUCAAAAkHsoLAAAAAAkRmEBAAAAIDEKCwDBisJak5azGc8rXUzWRsjbFnnbIWtbRUVFbsiQIf5rSCgsAISLRYCZp01cqrWdS7YPJE+Qty3ytkPWpqIocsuWLfNfQ0JhASBYdHzZZFy6oJisjZC3LfK2Q9a2qqur3ZQpU/zXkLTK9gEAQH3eu/yFbB9CztOHK/Vbu6+b9nl5cG9QuYi8bZG3HbJOpmePni4XUFgACNbHH0x0Xbp0yfZh5MVe6CHO1c1F5G2LvO2QNYSpUACQ59TTCDvkbYu87ZC1rRDzLohCW/UBIO9VVla60tJSN3/+fFdSUpLtwwEAIG9VNuE9ObxSBwD+h34Pm4z1pkHWNsjbFnnbIWtboeZNYQEgWCwAtMm4vJzFllbI2xZ52yFrW6HmTWEBAAAAIDEKCwAAAACJUVgAQJ4rLi7O9iHkFfK2Rd52yNpWiHmzKxSA4LArFAAAYWBXKAA5gX4Pm4wrKirI2gh52yJvO2RtK9S8KSwABCu03S5yNePp06eTtRHytkXedsjaVqh5U1gAAAAASIzCAgAAAEBiFBYAglVQUJDtQ8iLjLUYj6xtkLct8rZD1rZCzZtdoQAEh12hAAAIA7tCAcgJoS1Ky9WMZ86cSdZGyNsWedsha1uh5k1hASBYDKjaZDxr1iyyNkLetsjbDlnbCjVvCgsAAAAAiVFYAAAAAEiMwgJAsELb7SJXMy4rKyNrI+Rti7ztkLWtUPNmVygAwWFXKAAAwsCuUAByQmi7XeRqxtOnTydrI+Rti7ztkLWtUPOmsAAQLAZUbTKuqKggayPkbYu87ZC1rVDzprAAAAAAkBiFBQAAAIDEKCwABCu03S5yNeOePXuStRHytkXedsjaVqh5sysUgOCwKxQAAGFgVygAOSG03S5yNePy8nKyNkLetsjbDlnbCjVvCgsAwWJA1SZj9UaRtQ3ytkXedsjaVqh5U1gAAAAASIzCAgAAAEBiFBYAglVYyEuURcZ9+vQhayPkbYu87ZC1rVDzbpXtAwCA+oS2jV6uZlxWVpbtw8gb5G2LvO2Qta1Q8w6rzAGANFVVVdk+hLzIePLkyWRthLxtkbcdsrYVat4UFgCQ55YsWZLtQ8gr5G2LvO2Qta0Q86awAAAAAJAYhQUAAACAxCgsAAQrtN0ucjXjvn37krUR8rZF3nbI2laoebMrFIBgsSuUTcYlJSXZPoy8Qd62yNsOWdsKNe+wyhwASBPabhe5mvH48ePJ2gh52yJvO2RtK9S8KSwAIM9VV1dn+xDyCnnbIm87ZG0rxLwpLAAAAAAkRmEBAAAAILGCKIqi5FcDAM2nsrLSlZaWunnz5vmvyBy9BehDloqLi1ksb4C8bZG3HbK2ZZl3/J48f/78lS4YZ8QCQLB4c7LJuE2bNmRthLxtkbcdsrYVat4UFgCCFdpuF7ma8YQJE8jaCHnbIm87ZG0r1LwpLAAAAAAkRmEBAAAAIDEKCwAAAACJsSsUgOA0ZQcKJKc5ukVFRdk+jLxB3rbI2w5Z52be7AoFICfQ72GT8bJly8jaCHnbIm87ZG0r1LwpLAAEq7q6OtuHkBcZT5kyhayNkLct8rZD1rZCzbtVtg8AAOqz/pCNNWMz24eR0woLC12/vmu7aeWfB/cG1Ri9enR37497K9uHAQCgsAAQskHDL3Wt2nbM9mHktAJX7bq1/tF12KCri1rgIPZHj52e7UMAAPxPy3sXAQA0q4hRIfNRItghbztkbSvEvBmxABCsltiD3hIznrO8W7YPI29oB5ehQ4dm+zDyBnnbIWtboebNuzaAgIW120VuilzrgmVkbUQ7uGjrxtB2cslV5G2HrG2FmjeFBYBgFdDYNcm4tFUlWRvRAvny8vIWuVC+JSJvO2RtK9S8KSwAAAAAJEZhAQAAACAxCgsAAWO3oswrcFWR9vEgayvFxcXZPoS8Qt52yNpWiHmzKxSAYLENqk3Gc1d0zvZh5NVOLgMHDsz2YeQN8rZD1rZCzZsRCwABY0Fx5kWuuHAJWRvRDi4VFRXB7eSSq8jbDlnbCjVvCgsAwWKnIpuMOxYtJGsj2sFl+vTpwe3kkqvI2w5Z2wo1bwoLAAAAAIlRWAAAAABIjMICQLBYvG2T8fKoDVkbKSgocCUlJf4rMo+87ZC1rVDzZlcoAAEL6wUzNxW4+StKsn0QeaOwsND17ds324eRN8jbDlnbCjVvRiwABIwFxZkXufaFi8jaiBZazpw5M7gFl7mKvO2Qta1Q86awABAsdiqyybh90SKyNqKtIWfNmhXcFpG5irztkLWtUPOmsAAAAACQGIUFAAAAgMQoLAAEi52KbDJeUl1M1ka0g0tZWVlwO7nkKvK2Q9a2Qs2bXaEABCysF8zcVOAWVnXM9kHk1U4uffr0yfZh5A3ytkPWtkLNmxELAAELa1Fabopcx6KFZG1EO7hMnz49uJ1cchV52yFrW6HmTWEBIFjsVGSTcXHhErI2oh1cKioqgtvJJVeRtx2ythVq3hQWAAAAABKjsAAAAACQGIUF0MzWWGMNd91116W+144NTzzxRL2X/+qrr/xlJkyYYHSELQc7FdlkvKiqPVkb0d96z549g9vJJVeRtx2ythVq3hQWMHPooYf6PwCdWrdu7dZcc0131llnuSVLlrhc8v7777ujjz46a7e/7rrrurZt27rvvvvuZ+dtt9127pRTTqn3dy+++GI3ZMiQgIqfsF4wc1OBW1TdPieyPumkk3xhX/u5qp/179/fP7d1+uc//7nS35FddtnFDRo0yP/O1ltv7caPH98sO7n06tXLf0XmkbcdsrYVat5hHQ1y3m677eY/gv6LL75w1157rbv99tvdqFGjXC5ZZZVVXPv2aqjZe/PNN93ixYvdb3/7W3ffffe5li+sRWm5KXKlrSpzIms97/U3UNcWjComVDjodOCBBzbqdx555BE3adIk/zunnXaa7xxJSju4lJeXB7eTS64ibztkbSvUvCksYEo96T169HCrrbaa22effdxOO+3kXnjhhdT5+gO58sor/WhGu3bt3ODBg91jjz2WOn/u3LluxIgRvvGu8/v27evuueeeGr3qDz/8sNtiiy1ccXGxW3/99d1rr71W4xj0/aabbuqPRcOI55xzjluxYkWNXn31Ymo0pWvXrv541ZMf0w4M+n711Vf316EeA12+vqlQomJq991398e81lpr1bhPdfnkk0/85Tt27Oi6d+/uDjnkEL/7w8r87W9/c7/73e/85e+++26XKdribvjw4a5Lly6uQ4cObuDAge7ZZ59NfPy1sVNR5inj1gXLciLrbbbZxvXu3bvZfqdz586p/8+fP79Zphzo9aOysjK4nVxyFXnbIWtboeZNYYGsUePz7bffdm3atEn9TEXF3//+d3fbbbe5yZMnu1NPPdX9/ve/TxUHF154oZsyZYobO3as+/TTT92tt97qP3ky3ZlnnulOP/10P21h2LBhvgE8Z84cf963337r9thjD7fJJpu4iRMn+t9XY/xPf/pTjetQb78azOPGjXNXX321u/TSS1MF0L/+9a/UaIt6C7R+YoMNNmjwvuq499tvP3+bKowOOuggf/x1mTdvntthhx3c0KFD3QcffOCee+45N3v2bHfAAQc0eBsLFixwjz76qM9r55139g2hN954w2XCCSec4JYuXepef/119/HHH7urrrrKFxFJjh/IpD/84Q/+7/SII45wP/zwQ5N+Tx0h+hu+//77M3qMANDS8cnbMPX000/7BqhGCNQw1dzAm266yZ+n76+44gr34osv+oJA1LuvaQpqxG+77bbu66+/9g3WjTfeODU6UNuJJ57oG/GiwkENWxUPGoG45ZZbfCNBt6neR61HmDlzpjv77LPdRRddlJqrqHnV8RQtjYro8i+99JJvsOsYNIqh0RatFdHIhUZAGrL//vu7I4880v//sssu80XKjTfe6I+nNt2W7qOyiGn0Qcc9bdo0169fvzpvQyM1OlaNHoiKF91vzQ1vbspAGccFlR6nJMevx16nmHphgOaiAlh/p8uXL3cXXHCBGzlyZI0RtoaooyPubNDrRGN/DwDyESMWMLX99tv7+coaCdCb+2GHHZYqAj777DO3aNEi33hX8RGf9Mb++eef+8scd9xxvgGtxZQqFDTiUVtclEirVq18ERKPDuirzk+f0rDlllu6hQsXum+++Sb1MxUW6TRl6vvvv08VCVrHoMb0UUcd5caMGVNjKlVd0o8p/r6+EQuNarzyyis1MlABJHEOdVHjXaMVMf1fIxgayWhumvqlUR5lpwJM89CTHL9GqkpLS1MnFSHCTkWZp4wXVnXM6axVVIg6ArR5wS8ZydPrlZ7X8ejnL6XOC63nCG3BZa4ibztkbSvUvMM6GuQ8TS9aZ511/NoJNYRVYKhXXdS4l2eeeSa1yFInTX2K1yRo3r7m92uKlEYadtxxR3fGGWc0+3GqAZJOhUi8QEqN3qlTp/rRBq2ZOP744/08bfWGNgfloOlb6RnopGlXup26KKN3333XF1sqpnTafPPNfaGmQqyxSkpK/BSq2jS9SdToF42+aAG+1k5oKpSKN43A/NLjP/fcc/3txqcZM2b875zcbeyGo8AtqS7O2ax/+umn1PNXHnroIT+itjL6Hb3GxDTlsVu3bn7dVRJ6LdH0zdC2iMxV5G2HrG2FmjeFBbJGVfZ5553npyZoBGDAgAF+MbSm2aj4SD/FPdiihdvqPXzggQf8Iuk77rijxvWqgR3TSMKHH37o1ltvPf+9vr7zzjs1Fju99dZbrlOnTk1a9KmCQo3nG264wb366qv+OtXArk/6McXfx8dU24YbbujXl2iaV+0cVJjVRcWZGu0aLUhvzGsnm7hwawxtyamRG62JSPfRRx/5xfBxz6/oMTn22GPd448/7te03Hnnnb/4+PW4q6hJP0kuLCgOnTLu0mpeTmR9zDHH+L9jPYd33XVX/5zTc1kjpRqF1NQ9rdeKpzfV9zuiAlcbTOh31BGiKX6aypn0Tbyqqsr/fegrMo+87ZC1rVDzZo0FskrTirTY+uabb/YjDzppNEKjA1tttZV/c1fDXw1NFRNaB7HRRhv5dQSak683+toNdF2X1hro51pkrZ2kDj/8cH+eRhdUjPzxj3/0azE08qCpPGqAN3Y48d577/V/yJtttpnfVlYFjgqNurarjGlKknr1dZ8efPBB995779Xb4NfCaDXSDz744NTOVJomppGHu+66yxUVFdW4vEZKtKhUC8y1C1Y6jSxcc801/sUnXnvREDWsVFzotjXVSWtJVFSo+Dv55JNTt63pJBo90noJ5aspIvHj0NTjb1jLb+yGL3JFBSv+l3VYPV9NpbVYdWno8yfq+x39PevvNBNy7bN7QkfedsjaVoh5M2KBrNKUHTXwtfOSpixoYbN2X9GcezVU9bkXmhql7WdFO0hp2ox6H9VDr0Zq7ak+o0eP9if1Mmrh95NPPpnaOWrVVVf1iy/VYND56nHXLjFqODeWtqBUw1nrC3QcWmz+1FNP+WkS9bnkkkv8cery6i3VdAyN0NRF29eqmFLxog/oUo+pGvK63bqKH90/zfved999f3aeMtSpsaMWejyef/55PzKhwkCFigovFRV6bGI6NhUQ8WOkAiNeiN7U4wcAALmhIAptA1zgF9LnWKgAUe9kXZ8ejZZDu0JpPcduJzzgWrX9/9vYIjMKXLXr1vpHN2d5Vxe1wL6mjx473X07/TPXUqjg1jRFvUY1bfQOvwR52yFrW5Z5x+/JmkUST1WuT8t7FwGQN3J5p6KQMp6/ooSsjWjUTlM1Gb2zQd52yNpWqHmzxgJAwGjsZl6BWx7934dUIrO0+HtlPX5oPuRth6xthZp3WGUOkIB2IdLMPqZB5dY0HVhMhZpD1obTFzRdM7SdXHIVedsha1uh5k1hAQB5Lhe2mm1J4s/EgQ3ytkPWtkLMm8ICAAAAQGIUFgAAAAASo7AAECx2KrLJeO7yzmRtRDu46DNsQtvJJVeRtx2ythVq3mEdDQDUQGM387RsW28FZG21k4s+6FNfkXnkbYesbYWaN4UFgGCxU5HdB+SRte2HWoW2k0uuIm87ZG0r1LwpLAAAAAAkRmEBAAAAIDEKCwAAAACJUVgACFbES5RJxnOWdyVrI0VFRW7IkCH+KzKPvO2Qta1Q8+adBEDA+ETozFNJoYXbZG0hiiK3bNky/xWZR952yNpWqHlTWAAIVgGNXZOMu7SeR9ZGqqur3ZQpU/xXZB552yFrW6HmTWEBAAAAIDEKCwAAAACJUVgAQJ6L+NRtU4WFvPVaIm87ZG0rxLxbZfsAAKA+7FRktStUt2wfRt7QDi5Dhw7N9mHkDfK2Q9a2Qs2bd20AAWNBceZFrnXBMrI2oh1cKisrg9vJJVeRtx2ythVq3hQWAILFTkU2GZe2qiRrI9rBpby8PLidXHIVedsha1uh5k1hAQAAACAxCgsAAAAAiVFYAAgYuxVlXoGrirSPB1lbKS4uzvYh5BXytkPWtkLMm12hAASLbVBtMp67onO2DyOvdnIZOHBgtg8jb5C3HbK2FWrejFgACBgLijMvcsWFS8jaiHZwqaioCG4nl1xF3nbI2laoeTNiASBYHz91IVN0DD5gqV/ftd208s+D212kMXr16O5aEmU8ffp016VLF9/jiMwibztkbSvUvCksAATrkwkf+BdNZE5VVZWbMGGCGzJkSFBvTgCAloepUAAAAAASo7AAEKyCAqZBWWRcUlJC1kbI2xZ52yFrW6HmXRCFtuoDQN6rrKx0paWlbv78+f6FEwAAhP+ezIgFgGC1xMXELTHjmTNnkrUR8rZF3nbI2laoeVNYAAgWA6o2Gc+aNYusjZC3LfK2Q9a2Qs2bwgIAAABAYhQWAAAAABKjsAAQrNB2u8jVjMvKysjaCHnbIm87ZG0r1LzZFQpAcNgVCgCAMLArFICcENpuF7ma8fTp08naCHnbIm87ZG0r1LwpLAAEiwFVm4wrKirI2gh52yJvO2RtK9S8KSwAAAAAJNYq+VUAQPOKe2A0r7OoqCjbh5PTqqqq3MKFC8naCHnbIm87ZG3LMm/dhjRmdITCAkBw5syZ47+uscYa2T4UAADgnFuwYIFfxN0QCgsAwenatav/+vXXX6/0RQzJe6JWW201N2PGDHbgMkDetsjbDlnbssxbIxUqKnr16rXSy1JYAAhOYeH/X/6looI3KBvKmaztkLct8rZD1rmZd2M7+Vi8DQAAACAxCgsAAAAAiVFYAAhO27Zt3ahRo/xXZBZZ2yJvW+Rth6xthZp3QRTaJ2sAAAAAaHEYsQAAAACQGIUFAAAAgMQoLAAAAAAkRmEBICg333yz/8Tt4uJit9lmm7n33nsv24cUvNdff90NHz7cf3hRQUGBe+KJJ2qcr6V0F110kevZs6dr166d22mnnVx5eXmNy/z4449uxIgRfj/0zp07uyOOOMItXLiwxmUmTZrktt56a//Y6IOZrr76apePrrzySrfJJpu4Tp06uV/96ldun332cVOnTq1xmSVLlrgTTjjBdevWzXXs2NHtt99+bvbs2TUuow+A3HPPPV379u399Zx55pluxYoVNS7z6quvug033NAv0FxnnXXcvffe6/LJrbfe6gYNGpTaq3/YsGFu7NixqfPJOXNGjx7tX09OOeWU1M/Iu/lcfPHFPt/007rrrtvys9bibQAIwcMPPxy1adMmuvvuu6PJkydHRx11VNS5c+do9uzZ2T60oD377LPR+eefHz3++OPajCMaM2ZMjfNHjx4dlZaWRk888UQ0ceLEaK+99orWXHPNaPHixanL7LbbbtHgwYOjd999N3rjjTeiddZZJzr44INT58+fPz/q3r17NGLEiOiTTz6JHnrooahdu3bR7bffHuWbXXfdNbrnnnt8DhMmTIj22GOPaPXVV48WLlyYusyxxx4brbbaatFLL70UffDBB9Hmm28ebbHFFqnzV6xYEa2//vrRTjvtFI0fP94/hmVlZdG5556buswXX3wRtW/fPjrttNOiKVOmRDfeeGNUVFQUPffcc1G+ePLJJ6NnnnkmmjZtWjR16tTovPPOi1q3bu2zF3LOjPfeey9aY401okGDBkUnn3xy6ufk3XxGjRoVDRw4MJo1a1bq9MMPP7T4rCksAARj0003jU444YTU91VVVVGvXr2iK6+8MqvH1ZLULiyqq6ujHj16RH/+859TP5s3b17Utm1bXxyI3nD0e++//37qMmPHjo0KCgqib7/91n9/yy23RF26dImWLl2auszZZ58d9e/fP8p333//vc/vtddeS+Wrxu+jjz6ausynn37qL/POO+/479UIKCwsjL777rvUZW699daopKQklfFZZ53lGx7pDjzwQF/Y5DM9D++66y5yzpAFCxZEffv2jV544YVo2223TRUW5N38hcXgwYPrPK8lZ81UKABBWLZsmfvwww/9NJ1YYWGh//6dd97J6rG1ZF9++aX77rvvauRaWlrqp5nFueqrpj9tvPHGqcvo8sp/3Lhxqctss802rk2bNqnL7Lrrrn4K0Ny5c10+mz9/vv/atWtX/1XP4+XLl9fIXFMcVl999RqZb7DBBq579+418qysrHSTJ09OXSb9OuLL5OvfQ1VVlXv44YfdTz/95KdEkXNmaPqNptfUzoS8m195ebmfwrrWWmv5qaia2tTSs6awABCEiooK33BIf5EUfa+GMX6ZOLuGctVXzc9N16pVK99QTr9MXdeRfhv5qLq62s9B33LLLd3666+fykMFmIq1hjJfWZ71XUYNh8WLF7t88fHHH/s55pojfuyxx7oxY8a4AQMGkHMGqHD76KOP/Dqi2si7eW222WZ+vcNzzz3n1xKpE0hr2BYsWNCis26VkWsFACBPenc/+eQT9+abb2b7UHJW//793YQJE/zI0GOPPeZGjhzpXnvttWwfVs6ZMWOGO/nkk90LL7zgN2hAZu2+++6p/2uDAhUaffr0cY888ojfZKOlYsQCQBDKyspcUVHRz3a90Pc9evTI2nG1dHF2DeWqr99//32N87WziHaKSr9MXdeRfhv55sQTT3RPP/20e+WVV1zv3r1TP1cemto3b968BjNfWZ71XUa7I7XkhkdTqedWu9lstNFGvid98ODB7vrrryfnZqbpN3od0A5CGrHUSQXcDTfc4P+vnm7yzpzOnTu7fv36uc8++6xFP7cpLAAE03hQw+Gll16qMc1E32s+NX6ZNddc07+5pOeqYXCtnYhz1Ve9galhEXv55Zd9/upFiy+jbW017zemnk31Jnfp0sXlE62RV1GhKTnKSRmn0/O4devWNTLXWhTNn07PXFN80gs65ak3fE3ziS+Tfh3xZfL970HPy6VLl5JzM9txxx19Vhodik9ad6W5//H/yTtzFi5c6D7//HO/LXiLfm5nbFk4APyC7Wa1W9G9997rdyo6+uij/Xaz6bteoO5dXLTdoE56Wb/mmmv8/6dPn57ablY5/vvf/44mTZoU7b333nVuNzt06NBo3Lhx0Ztvvul3hUnfbla7lGi72UMOOcRv9anHStsY5uN2s8cdd5zfvvfVV1+tsVXkokWLamwVqS1oX375Zb9V5LBhw/yp9laRu+yyi9+yVts/rrLKKnVuFXnmmWf6HWFuvvnmvNuW85xzzvG7bX355Zf+uavvtVvZ888/788n58xK3xVKyLv5nH766f41RM/tt956y28bq+1itctcS86awgJAULTPtl5M9XkW2n5Wn6uAhr3yyiu+oKh9GjlyZGrL2QsvvNAXBircdtxxR/+ZAOnmzJnjC4mOHTv67QoPO+wwX7Ck02dgbLXVVv46Vl11VV+w5KO6stZJn20RU9F2/PHH+61R9ca+7777+uIj3VdffRXtvvvu/vNA1KBQQ2P58uU/e2yHDBni/x7WWmutGreRDw4//PCoT58+/v6r0aTnblxUCDnbFhbk3XwOPPDAqGfPnj4DvZ7q+88++6zFZ12gfzI3HgIAAAAgH7DGAgAAAEBiFBYAAAAAEqOwAAAAAJAYhQUAAACAxCgsAAAAACRGYQEAAAAgMQoLAAAAAIlRWAAAAABIjMICAIAc8tVXX7mCggI3YcIEF4r//ve/bvPNN3fFxcVuyJAhLiT33nuv69y5c7YPA8gJFBYAADSjQw891DfsR48eXePnTzzxhP95Pho1apTr0KGDmzp1qnvppZfqvMwPP/zgjjvuOLf66qu7tm3buh49erhdd93VvfXWW812HGussYa77rrravzswAMPdNOmTWu22wDyWatsHwAAALlGPfNXXXWVO+aYY1yXLl1cLli2bJlr06bNL/rdzz//3O25556uT58+9V5mv/3287dx3333ubXWWsvNnj3bFyFz5sxxmdSuXTt/ApAcIxYAADSznXbayfe4X3nllfVe5uKLL/7ZtCD1pqtXPX30Y5999nFXXHGF6969u5+yc+mll7oVK1a4M88803Xt2tX17t3b3XPPPXVOP9piiy18kbP++uu71157rcb5n3zyidt9991dx44d/XUfcsghrqKiInX+dttt50488UR3yimnuLKyMj96UJfq6mp/TDoOjTToPj333HOp8zVK8+GHH/rL6P+637XNmzfPvfHGG74Y23777X0Bsummm7pzzz3X7bXXXjUud+SRR7pVVlnFlZSUuB122MFNnDixxnU99dRTbpNNNvH3W8e97777pu7P9OnT3amnnuqPIx49qmsq1K233urWXnttX0j179/f3X///TXO1+/edddd/rrbt2/v+vbt65588snU+XPnznUjRozwx6miRefX9RgBuYbCAgCAZlZUVOSLgRtvvNF98803ia7r5ZdfdjNnznSvv/66u+aaa/y0ol//+td+JGTcuHHu2GOP9SMjtW9Hhcfpp5/uxo8f74YNG+aGDx+e6v1XA12N8qFDh7oPPvjAFwIaITjggANqXIdGD9S41nSk2267rc7ju/76691f//pX95e//MVNmjTJFyAqBsrLy/35s2bNcgMHDvTHov+fccYZP7sOFTc6abrY0qVL681i//33d99//70bO3asL1Y23HBDt+OOO7off/zRn//MM8/4xv4ee+zh77dGPFSgyOOPP+6LHxU4Og6d6jJmzBh38skn++NV8aVsDzvsMPfKK6/UuNwll1zi89J91u2pkIiP48ILL3RTpkzxx/npp5/6QkVFDpDzIgAA0GxGjhwZ7b333v7/m2++eXT44Yf7/48ZMyZKf9sdNWpUNHjw4Bq/e+2110Z9+vSpcV36vqqqKvWz/v37R1tvvXXq+xUrVkQdOnSIHnroIf/9l19+6W9n9OjRqcssX7486t27d3TVVVf57y+77LJol112qXHbM2bM8L83depU//22224bDR06dKX3t1evXtHll19e42ebbLJJdPzxx6e+1/3U/W3IY489FnXp0iUqLi6Otthii+jcc8+NJk6cmDr/jTfeiEpKSqIlS5bU+L211147uv322/3/hw0bFo0YMaLe21CWyjjdPffcE5WWlqa+120fddRRNS6z//77R3vssUfqe+V0wQUXpL5fuHCh/9nYsWP998OHD48OO+ywBu8vkIsYsQAAIEM0tUe9/uq1/qXU219Y+H9v15q2tMEGG9QYHenWrZvvyU+nUYpYq1at3MYbb5w6Dk0fUg98PFKg07rrrptaDxHbaKONGjy2yspKP5qy5ZZb1vi5vm/qfdYaC12XphTttttu7tVXX/UjEpqqFB/zwoUL/X1NP+4vv/wydczaCUsjGEnouBtzfwYNGpT6vxama2pW/BhoEfrDDz/sp4WdddZZ7u233050TEBLweJtAAAyZJtttvFTg7RWQOsl0qlY+P+d3/9n+fLlP7uO1q1b/2x+f10/01qHxlIDXVOjVPjU1rNnzxoNZktaF7Hzzjv7k6YTaT2Fpn4pOx2zjk0FR23xGgnLRdgNPQZau6L1HM8++6x74YUXfLFzwgkn+OliQC5jxAIAgAzStrNaUPzOO+/U+LkW9n733Xc1iovm/OyJd999N/V/LfbWmoT11lvPf6+RgMmTJ/uF4uuss06NU1OKCfXS9+rV62dbwur7AQMGJL4Puo6ffvopdczKS6MvtY85Xr+gUYT6trMVrRepqqpq8DaVUXPcHz2+I0eOdA888IBflH/HHXc06feBlogRCwAAMkjTlrSw94Ybbqjxc+1SpM9uuPrqq91vf/tbv4Bai33VWG8ON998s9+NSA3la6+91u9UdPjhh/vz1Ht+5513uoMPPthP1dHuUp999pmfvqPdjjS9qrG0SFyjCtpFSVN/tPuRCqQHH3yw0dehReVamK3jU3HQqVMnv6hc2ey9996pnbY0vUu7ZOnn/fr181On4gXbmuql49DogI7loIMO8gWVRg3OPvtsfx0qpLQIXudpB6u6FlTr/mhRtha26zZVFGrh94svvtjo+3PRRRf5aWSaxqbF6E8//XSqqANyGSMWAABkmHYiqj1VSQ3NW265xRcAgwcPdu+9916dOyYlGSnRSdf95ptv+rULcUM6HmVQ7/0uu+ziix9tK6spRenrORrjpJNOcqeddprfRUnXowJJt6WiprG0VmKzzTbzBZCmj2l7XE2FOuqoo9xNN92UmmqkIkHna5cmFRYqEDTlSOtO4mLt0Ucf9bevIkc7XynX9MdBn0yuwkMjCnVR4aKdrjRtSYXB7bff7oslXXdjaWRE099UJOl4VaipaANyXYFWcGf7IAAAAAC0bIxYAAAAAEiMwgIAAABAYhQWAAAAABKjsAAAAACQGIUFAAAAgMQoLAAAAAAkRmEBAAAAIDEKCwAAAACJUVgAAAAASIzCAgAAAEBiFBYAAAAAEqOwAAAAAOCS+n/d6/OqoQ8pqwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_bias_final[\"dominant_topic\"] = [max(lda_model[corpus[i]], key=lambda x: x[1])[0] for i in range(len(corpus))]\n",
    "topic_counts = data_bias_final[\"dominant_topic\"].value_counts().sort_index()\n",
    "\n",
    "topic_labels = [\"Responsible AI Use\", \"Bias and Fairness in Generated Content\", \"Risk and Safety Considerations\"]\n",
    "\n",
    "colors = [\"#4c72b0\", \"#55a868\", \"#c44e52\"]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "bars = plt.barh(topic_labels, topic_counts, color=colors, edgecolor=\"black\", height=0.55, linewidth=0.6)\n",
    "\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    plt.text(width + 20, bar.get_y() + bar.get_height()/2, int(width), va='center', fontsize=8)\n",
    "\n",
    "plt.xlabel(\"Number of Sections\", fontsize=10)\n",
    "plt.yticks(fontsize=10) \n",
    "plt.xlim(0, 5300) \n",
    "\n",
    "plt.grid(axis='x', linestyle='--', color='gray', alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lda_topics.pdf\", format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed06b117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dominant_topic\n",
       "0    1512\n",
       "1    4868\n",
       "2    1498\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
